-- This file and its contents are licensed under the Timescale License.
-- Please see the included NOTICE for copyright information and
-- LICENSE-TIMESCALE for a copy of the license.
-- Disable background workers since we are testing manual refresh
\c :TEST_DBNAME :ROLE_SUPERUSER
SELECT _timescaledb_internal.stop_background_workers();
 stop_background_workers 
-------------------------
 t
(1 row)

SET ROLE :ROLE_DEFAULT_PERM_USER;
SET datestyle TO 'ISO, YMD';
SET timezone TO 'UTC';
CREATE TABLE conditions (time bigint NOT NULL, device int, temp float);
SELECT create_hypertable('conditions', 'time', chunk_time_interval => 10);
    create_hypertable    
-------------------------
 (1,public,conditions,t)
(1 row)

CREATE TABLE measurements (time int NOT NULL, device int, temp float);
SELECT create_hypertable('measurements', 'time', chunk_time_interval => 10);
     create_hypertable     
---------------------------
 (2,public,measurements,t)
(1 row)

CREATE OR REPLACE FUNCTION bigint_now()
RETURNS bigint LANGUAGE SQL STABLE AS
$$
    SELECT coalesce(max(time), 0)
    FROM conditions
$$;
CREATE OR REPLACE FUNCTION int_now()
RETURNS int LANGUAGE SQL STABLE AS
$$
    SELECT coalesce(max(time), 0)
    FROM measurements
$$;
SELECT set_integer_now_func('conditions', 'bigint_now');
 set_integer_now_func 
----------------------
 
(1 row)

SELECT set_integer_now_func('measurements', 'int_now');
 set_integer_now_func 
----------------------
 
(1 row)

INSERT INTO conditions
SELECT t, ceil(abs(timestamp_hash(to_timestamp(t)::timestamp))%4)::int,
       abs(timestamp_hash(to_timestamp(t)::timestamp))%40
FROM generate_series(1, 100, 1) t;
INSERT INTO measurements
SELECT * FROM conditions;
-- Show the most recent data
SELECT * FROM conditions
ORDER BY time DESC, device
LIMIT 10;
 time | device | temp 
------+--------+------
  100 |      0 |    8
   99 |      1 |    5
   98 |      2 |   26
   97 |      2 |   10
   96 |      2 |   34
   95 |      2 |   30
   94 |      3 |   31
   93 |      0 |    4
   92 |      0 |   32
   91 |      3 |   15
(10 rows)

-- Create two continuous aggregates on the same hypertable to test
-- that invalidations are handled correctly across both of them.
CREATE MATERIALIZED VIEW cond_10
WITH (timescaledb.continuous,
      timescaledb.materialized_only=true)
AS
SELECT time_bucket(BIGINT '10', time) AS bucket, device, avg(temp) AS avg_temp
FROM conditions
GROUP BY 1,2 WITH NO DATA;
CREATE MATERIALIZED VIEW cond_20
WITH (timescaledb.continuous,
      timescaledb.materialized_only=true)
AS
SELECT time_bucket(BIGINT '20', time) AS bucket, device, avg(temp) AS avg_temp
FROM conditions
GROUP BY 1,2 WITH NO DATA;
CREATE MATERIALIZED VIEW measure_10
WITH (timescaledb.continuous,
      timescaledb.materialized_only=true)
AS
SELECT time_bucket(10, time) AS bucket, device, avg(temp) AS avg_temp
FROM measurements
GROUP BY 1,2 WITH NO DATA;
-- There should be three continuous aggregates, two on one hypertable
-- and one on the other:
SELECT mat_hypertable_id, raw_hypertable_id, user_view_name
FROM _timescaledb_catalog.continuous_agg;
 mat_hypertable_id | raw_hypertable_id | user_view_name 
-------------------+-------------------+----------------
                 3 |                 1 | cond_10
                 4 |                 1 | cond_20
                 5 |                 2 | measure_10
(3 rows)

-- The continuous aggregates should be empty
SELECT * FROM cond_10
ORDER BY 1 DESC, 2;
 bucket | device | avg_temp 
--------+--------+----------
(0 rows)

SELECT * FROM cond_20
ORDER BY 1 DESC, 2;
 bucket | device | avg_temp 
--------+--------+----------
(0 rows)

SELECT * FROM measure_10
ORDER BY 1 DESC, 2;
 bucket | device | avg_temp 
--------+--------+----------
(0 rows)

CREATE VIEW hyper_invals AS
SELECT hypertable_id AS hyper_id,
       lowest_modified_value AS start,
       greatest_modified_value AS end
       FROM _timescaledb_catalog.continuous_aggs_hypertable_invalidation_log
       ORDER BY 1,2,3;
CREATE VIEW cagg_invals AS
SELECT materialization_id AS cagg_id,
       lowest_modified_value AS start,
       greatest_modified_value AS end
       FROM _timescaledb_catalog.continuous_aggs_materialization_invalidation_log
       ORDER BY 1,2,3;
-- Must refresh to move the invalidation threshold, or no
-- invalidations will be generated. Initially, there is no threshold
-- set:
SELECT * FROM _timescaledb_catalog.continuous_aggs_invalidation_threshold
ORDER BY 1,2;
 hypertable_id | watermark 
---------------+-----------
(0 rows)

-- There should be only "infinite" invalidations in the cagg
-- invalidation log:
SELECT * FROM cagg_invals;
 cagg_id |        start         |         end         
---------+----------------------+---------------------
       3 | -9223372036854775808 | 9223372036854775807
       4 | -9223372036854775808 | 9223372036854775807
       5 | -9223372036854775808 | 9223372036854775807
(3 rows)

-- Now refresh up to 50 without the first bucket, and the threshold should be updated accordingly:
CALL refresh_continuous_aggregate('cond_10', 1, 50);
SELECT * FROM _timescaledb_catalog.continuous_aggs_invalidation_threshold
ORDER BY 1,2;
 hypertable_id | watermark 
---------------+-----------
             1 |        50
(1 row)

-- Invalidations should be cleared inside the refresh window:
SELECT * FROM cagg_invals;
 cagg_id |        start         |         end         
---------+----------------------+---------------------
       3 | -9223372036854775808 |                   9
       3 |                   50 | 9223372036854775807
       4 | -9223372036854775808 | 9223372036854775807
       5 | -9223372036854775808 | 9223372036854775807
(4 rows)

-- Refresh up to 50 from the beginning
CALL refresh_continuous_aggregate('cond_10', 0, 50);
SELECT * FROM cagg_invals;
 cagg_id |        start         |         end         
---------+----------------------+---------------------
       3 | -9223372036854775808 |                  -1
       3 |                   50 | 9223372036854775807
       4 | -9223372036854775808 | 9223372036854775807
       5 | -9223372036854775808 | 9223372036854775807
(4 rows)

-- Refreshing below the threshold does not move it:
CALL refresh_continuous_aggregate('cond_10', 20, 49);
NOTICE:  continuous aggregate "cond_10" is already up-to-date
SELECT * FROM _timescaledb_catalog.continuous_aggs_invalidation_threshold
ORDER BY 1,2;
 hypertable_id | watermark 
---------------+-----------
             1 |        50
(1 row)

-- Nothing changes with invalidations either since the region was
-- already refreshed and no new invalidations have been generated:
SELECT * FROM cagg_invals;
 cagg_id |        start         |         end         
---------+----------------------+---------------------
       3 | -9223372036854775808 |                  -1
       3 |                   50 | 9223372036854775807
       4 | -9223372036854775808 | 9223372036854775807
       5 | -9223372036854775808 | 9223372036854775807
(4 rows)

-- Refreshing measure_10 moves the threshold only for the other hypertable:
CALL refresh_continuous_aggregate('measure_10', 0, 30);
SELECT * FROM _timescaledb_catalog.continuous_aggs_invalidation_threshold
ORDER BY 1,2;
 hypertable_id | watermark 
---------------+-----------
             1 |        50
             2 |        30
(2 rows)

SELECT * FROM cagg_invals;
 cagg_id |        start         |         end         
---------+----------------------+---------------------
       3 | -9223372036854775808 |                  -1
       3 |                   50 | 9223372036854775807
       4 | -9223372036854775808 | 9223372036854775807
       5 | -9223372036854775808 |                  -1
       5 |                   30 | 9223372036854775807
(5 rows)

-- Refresh on the second continuous aggregate, cond_20, on the first
-- hypertable moves the same threshold as when refreshing cond_10:
CALL refresh_continuous_aggregate('cond_20', 60, 100);
SELECT * FROM _timescaledb_catalog.continuous_aggs_invalidation_threshold
ORDER BY 1,2;
 hypertable_id | watermark 
---------------+-----------
             1 |       100
             2 |        30
(2 rows)

SELECT * FROM cagg_invals;
 cagg_id |        start         |         end         
---------+----------------------+---------------------
       3 | -9223372036854775808 |                  -1
       3 |                   50 | 9223372036854775807
       4 | -9223372036854775808 |                  59
       4 |                  100 | 9223372036854775807
       5 | -9223372036854775808 |                  -1
       5 |                   30 | 9223372036854775807
(6 rows)

	  
-- There should be no hypertable invalidations initially:
SELECT * FROM hyper_invals;
 hyper_id | start | end 
----------+-------+-----
(0 rows)

SELECT * FROM cagg_invals;
 cagg_id |        start         |         end         
---------+----------------------+---------------------
       3 | -9223372036854775808 |                  -1
       3 |                   50 | 9223372036854775807
       4 | -9223372036854775808 |                  59
       4 |                  100 | 9223372036854775807
       5 | -9223372036854775808 |                  -1
       5 |                   30 | 9223372036854775807
(6 rows)

-- Create invalidations across different ranges. Some of these should
-- be deleted and others cut in different ways when a refresh is
-- run. Note that the refresh window is inclusive in the start of the
-- window but exclusive at the end.
-- Entries that should be left unmodified:
INSERT INTO conditions VALUES (10, 4, 23.7);
INSERT INTO conditions VALUES (10, 5, 23.8), (19, 3, 23.6);
INSERT INTO conditions VALUES (60, 3, 23.7), (70, 4, 23.7);
-- Should see some invaliations in the hypertable invalidation log:
SELECT * FROM hyper_invals;
 hyper_id | start | end 
----------+-------+-----
        1 |    10 |  10
        1 |    10 |  19
        1 |    60 |  70
(3 rows)

-- Generate some invalidations for the other hypertable
INSERT INTO measurements VALUES (20, 4, 23.7);
INSERT INTO measurements VALUES (30, 5, 23.8), (80, 3, 23.6);
-- Should now see invalidations for both hypertables
SELECT * FROM hyper_invals;
 hyper_id | start | end 
----------+-------+-----
        1 |    10 |  10
        1 |    10 |  19
        1 |    60 |  70
        2 |    20 |  20
(4 rows)

-- First refresh a window where we don't have any invalidations. This
-- allows us to see only the copying of the invalidations to the per
-- cagg log without additional processing.
CALL refresh_continuous_aggregate('cond_10', 20, 60);
-- Invalidation threshold remains at 100:
SELECT * FROM _timescaledb_catalog.continuous_aggs_invalidation_threshold
ORDER BY 1,2;
 hypertable_id | watermark 
---------------+-----------
             1 |       100
             2 |        30
(2 rows)

-- Invalidations should be moved from the hypertable invalidation log
-- to the continuous aggregate log, but only for the hypertable that
-- the refreshed aggregate belongs to:
SELECT * FROM hyper_invals;
 hyper_id | start | end 
----------+-------+-----
        2 |    20 |  20
(1 row)

SELECT * FROM cagg_invals;
 cagg_id |        start         |         end         
---------+----------------------+---------------------
       3 | -9223372036854775808 |                  -1
       3 |                   10 |                  19
       3 |                   60 | 9223372036854775807
       4 | -9223372036854775808 |                  59
       4 |                   10 |                  19
       4 |                   60 |                  70
       4 |                  100 | 9223372036854775807
       5 | -9223372036854775808 |                  -1
       5 |                   30 | 9223372036854775807
(9 rows)

-- Now add more invalidations to test a refresh that overlaps with them.
-- Entries that should be deleted:
INSERT INTO conditions VALUES (30, 1, 23.4), (59, 1, 23.4);
INSERT INTO conditions VALUES (20, 1, 23.4), (30, 1, 23.4);
-- Entries that should be cut to the right, leaving an invalidation to
-- the left of the refresh window:
INSERT INTO conditions VALUES (1, 4, 23.7), (25, 1, 23.4);
INSERT INTO conditions VALUES (19, 4, 23.7), (59, 1, 23.4);
-- Entries that should be cut to the left and right, leaving two
-- invalidation entries on each side of the refresh window:
INSERT INTO conditions VALUES (2, 2, 23.5), (60, 1, 23.4);
INSERT INTO conditions VALUES (3, 2, 23.5), (80, 1, 23.4);
-- Entries that should be cut to the left, leaving an invalidation to
-- the right of the refresh window:
INSERT INTO conditions VALUES (60, 3, 23.6), (90, 3, 23.6);
INSERT INTO conditions VALUES (20, 5, 23.8), (100, 3, 23.6);
-- New invalidations in the hypertable invalidation log:
SELECT * FROM hyper_invals;
 hyper_id | start | end 
----------+-------+-----
        1 |     1 |  25
        1 |     2 |  60
        1 |     3 |  80
        1 |    19 |  59
        1 |    20 |  30
        1 |    20 | 100
        1 |    30 |  59
        1 |    60 |  90
        2 |    20 |  20
(9 rows)

-- But nothing has yet changed in the cagg invalidation log:
SELECT * FROM cagg_invals;
 cagg_id |        start         |         end         
---------+----------------------+---------------------
       3 | -9223372036854775808 |                  -1
       3 |                   10 |                  19
       3 |                   60 | 9223372036854775807
       4 | -9223372036854775808 |                  59
       4 |                   10 |                  19
       4 |                   60 |                  70
       4 |                  100 | 9223372036854775807
       5 | -9223372036854775808 |                  -1
       5 |                   30 | 9223372036854775807
(9 rows)

-- Refresh to process invalidations for daily temperature:
CALL refresh_continuous_aggregate('cond_10', 20, 60);
-- Invalidations should be moved from the hypertable invalidation log
-- to the continuous aggregate log.
SELECT * FROM hyper_invals;
 hyper_id | start | end 
----------+-------+-----
        2 |    20 |  20
(1 row)

-- Only the cond_10 cagg should have its entries cut:
SELECT * FROM cagg_invals;
 cagg_id |        start         |         end         
---------+----------------------+---------------------
       3 | -9223372036854775808 |                  -1
       3 |                    1 |                  19
       3 |                   60 | 9223372036854775807
       4 | -9223372036854775808 |                  59
       4 |                    1 |                 100
       4 |                   10 |                  19
       4 |                   60 |                  70
       4 |                  100 | 9223372036854775807
       5 | -9223372036854775808 |                  -1
       5 |                   30 | 9223372036854775807
(10 rows)

-- Refresh also cond_20:
CALL refresh_continuous_aggregate('cond_20', 20, 60);
-- The cond_20 cagg should also have its entries cut:
SELECT * FROM cagg_invals;
 cagg_id |        start         |         end         
---------+----------------------+---------------------
       3 | -9223372036854775808 |                  -1
       3 |                    1 |                  19
       3 |                   60 | 9223372036854775807
       4 | -9223372036854775808 |                  19
       4 |                   60 | 9223372036854775807
       5 | -9223372036854775808 |                  -1
       5 |                   30 | 9223372036854775807
(7 rows)

-- Refresh cond_10 to completely remove an invalidation:
CALL refresh_continuous_aggregate('cond_10', 0, 20);
-- The 1-19 invalidation should be deleted:
SELECT * FROM cagg_invals;
 cagg_id |        start         |         end         
---------+----------------------+---------------------
       3 | -9223372036854775808 |                  -1
       3 |                   60 | 9223372036854775807
       4 | -9223372036854775808 |                  19
       4 |                   60 | 9223372036854775807
       5 | -9223372036854775808 |                  -1
       5 |                   30 | 9223372036854775807
(6 rows)

-- Clear everything between 0 and 100 to make way for new
-- invalidations
CALL refresh_continuous_aggregate('cond_10', 0, 100);
-- Test refreshing with non-overlapping invalidations
INSERT INTO conditions VALUES (20, 1, 23.4), (25, 1, 23.4);
INSERT INTO conditions VALUES (30, 1, 23.4), (46, 1, 23.4);
CALL refresh_continuous_aggregate('cond_10', 1, 40);
SELECT * FROM cagg_invals;
 cagg_id |        start         |         end         
---------+----------------------+---------------------
       3 | -9223372036854775808 |                  -1
       3 |                   40 |                  46
       3 |                  100 | 9223372036854775807
       4 | -9223372036854775808 |                  19
       4 |                   20 |                  25
       4 |                   30 |                  46
       4 |                   60 | 9223372036854775807
       5 | -9223372036854775808 |                  -1
       5 |                   30 | 9223372036854775807
(9 rows)

-- Refresh whithout cutting (in area where there are no
-- invalidations). Merging of overlapping entries should still happen:
INSERT INTO conditions VALUES (15, 1, 23.4), (42, 1, 23.4);
CALL refresh_continuous_aggregate('cond_10', 90, 100);
NOTICE:  continuous aggregate "cond_10" is already up-to-date
SELECT * FROM cagg_invals;
 cagg_id |        start         |         end         
---------+----------------------+---------------------
       3 | -9223372036854775808 |                  -1
       3 |                   15 |                  46
       3 |                  100 | 9223372036854775807
       4 | -9223372036854775808 |                  19
       4 |                   15 |                  42
       4 |                   20 |                  25
       4 |                   30 |                  46
       4 |                   60 | 9223372036854775807
       5 | -9223372036854775808 |                  -1
       5 |                   30 | 9223372036854775807
(10 rows)

-- Test max refresh window
CALL refresh_continuous_aggregate('cond_10', NULL, NULL);
SELECT * FROM cagg_invals;
 cagg_id |        start         |         end          
---------+----------------------+----------------------
       3 | -9223372036854775808 | -9223372036854775801
       3 |                  110 |  9223372036854775807
       4 | -9223372036854775808 |                   19
       4 |                   15 |                   42
       4 |                   20 |                   25
       4 |                   30 |                   46
       4 |                   60 |  9223372036854775807
       5 | -9223372036854775808 |                   -1
       5 |                   30 |  9223372036854775807
(9 rows)

SELECT * FROM hyper_invals;
 hyper_id | start | end 
----------+-------+-----
        2 |    20 |  20
(1 row)

-- TRUNCATE the hypertable to invalidate all its continuous aggregates
TRUNCATE conditions;
-- Now empty
SELECT * FROM conditions;
 time | device | temp 
------+--------+------
(0 rows)

-- Should see an infinite invalidation entry for conditions
SELECT * FROM hyper_invals;
 hyper_id |        start         |         end         
----------+----------------------+---------------------
        1 | -9223372036854775808 | 9223372036854775807
        2 |                   20 |                  20
(2 rows)

-- Aggregates still hold data
SELECT * FROM cond_10
ORDER BY 1,2
LIMIT 5;
 bucket | device | avg_temp 
--------+--------+----------
      0 |      0 |       18
      0 |      1 |       25
      0 |      2 |    20.75
      0 |      3 |       21
      0 |      4 |     23.7
(5 rows)

SELECT * FROM cond_20
ORDER BY 1,2
LIMIT 5;
 bucket | device |     avg_temp     
--------+--------+------------------
     20 |      0 | 18.2857142857143
     20 |      1 | 23.5142857142857
     20 |      2 |               26
     20 |      3 |               23
     20 |      5 |             23.8
(5 rows)

CALL refresh_continuous_aggregate('cond_10', NULL, NULL);
CALL refresh_continuous_aggregate('cond_20', NULL, NULL);
-- Both should now be empty after refresh
SELECT * FROM cond_10
ORDER BY 1,2;
 bucket | device | avg_temp 
--------+--------+----------
(0 rows)

SELECT * FROM cond_20
ORDER BY 1,2;
 bucket | device | avg_temp 
--------+--------+----------
(0 rows)

-- Insert new data again and refresh
INSERT INTO conditions VALUES
       (1, 1, 23.4), (4, 3, 14.3), (5, 1, 13.6),
       (6, 2, 17.9), (12, 1, 18.3), (19, 3, 28.2),
       (10, 3, 22.3), (11, 2, 34.9), (15, 2, 45.6),
       (21, 1, 15.3), (22, 2, 12.3), (29, 3, 16.3);
CALL refresh_continuous_aggregate('cond_10', NULL, NULL);
CALL refresh_continuous_aggregate('cond_20', NULL, NULL);
-- Should now hold data again
SELECT * FROM cond_10
ORDER BY 1,2;
 bucket | device | avg_temp 
--------+--------+----------
      0 |      1 |     18.5
      0 |      2 |     17.9
      0 |      3 |     14.3
     10 |      1 |     18.3
     10 |      2 |    40.25
     10 |      3 |    25.25
     20 |      1 |     15.3
     20 |      2 |     12.3
     20 |      3 |     16.3
(9 rows)

SELECT * FROM cond_20
ORDER BY 1,2;
 bucket | device |     avg_temp     
--------+--------+------------------
      0 |      1 | 18.4333333333333
      0 |      2 |             32.8
      0 |      3 |             21.6
     20 |      1 |             15.3
     20 |      2 |             12.3
     20 |      3 |             16.3
(6 rows)

-- Truncate one of the aggregates, but first test that we block
-- TRUNCATE ONLY
\set ON_ERROR_STOP 0
TRUNCATE ONLY cond_20;
ERROR:  cannot truncate only a continuous aggregate
\set ON_ERROR_STOP 1
TRUNCATE cond_20;
-- Should now be empty
SELECT * FROM cond_20
ORDER BY 1,2;
 bucket | device | avg_temp 
--------+--------+----------
(0 rows)

-- Other aggregate is not affected
SELECT * FROM cond_10
ORDER BY 1,2;
 bucket | device | avg_temp 
--------+--------+----------
      0 |      1 |     18.5
      0 |      2 |     17.9
      0 |      3 |     14.3
     10 |      1 |     18.3
     10 |      2 |    40.25
     10 |      3 |    25.25
     20 |      1 |     15.3
     20 |      2 |     12.3
     20 |      3 |     16.3
(9 rows)

-- Refresh again to bring data back
CALL refresh_continuous_aggregate('cond_20', NULL, NULL);
-- The aggregate should be populated again
SELECT * FROM cond_20
ORDER BY 1,2;
 bucket | device |     avg_temp     
--------+--------+------------------
      0 |      1 | 18.4333333333333
      0 |      2 |             32.8
      0 |      3 |             21.6
     20 |      1 |             15.3
     20 |      2 |             12.3
     20 |      3 |             16.3
(6 rows)

-------------------------------------------------------
-- Test corner cases against a minimal bucket aggregate
-------------------------------------------------------
-- First, clear the table and aggregate
TRUNCATE conditions;
SELECT * FROM conditions;
 time | device | temp 
------+--------+------
(0 rows)

CALL refresh_continuous_aggregate('cond_10', NULL, NULL);
SELECT * FROM cond_10
ORDER BY 1,2;
 bucket | device | avg_temp 
--------+--------+----------
(0 rows)

CREATE MATERIALIZED VIEW cond_1
WITH (timescaledb.continuous,
      timescaledb.materialized_only=true)
AS
SELECT time_bucket(BIGINT '1', time) AS bucket, device, avg(temp) AS avg_temp
FROM conditions
GROUP BY 1,2 WITH NO DATA;
SELECT mat_hypertable_id AS cond_1_id
FROM _timescaledb_catalog.continuous_agg
WHERE user_view_name = 'cond_1' \gset
-- Test invalidations with bucket size 1
INSERT INTO conditions VALUES (0, 1, 1.0);
SELECT * FROM hyper_invals;
 hyper_id | start | end 
----------+-------+-----
        1 |     0 |   0
        2 |    20 |  20
(2 rows)

-- Refreshing around the bucket should not update the aggregate
CALL refresh_continuous_aggregate('cond_1', -1, 0);
SELECT * FROM cond_1
ORDER BY 1,2;
 bucket | device | avg_temp 
--------+--------+----------
(0 rows)

CALL refresh_continuous_aggregate('cond_1', 1, 2);
SELECT * FROM cond_1
ORDER BY 1,2;
 bucket | device | avg_temp 
--------+--------+----------
(0 rows)

-- Refresh only the invalidated bucket
CALL refresh_continuous_aggregate('cond_1', 0, 1);
SELECT * FROM cagg_invals
WHERE cagg_id = :cond_1_id;
 cagg_id |        start         |         end         
---------+----------------------+---------------------
       6 | -9223372036854775808 |                  -2
       6 |                    2 | 9223372036854775807
(2 rows)

SELECT * FROM cond_1
ORDER BY 1,2;
 bucket | device | avg_temp 
--------+--------+----------
      0 |      1 |        1
(1 row)

-- Refresh 1 extra bucket on the left
INSERT INTO conditions VALUES (0, 1, 2.0);
CALL refresh_continuous_aggregate('cond_1', -1, 1);
SELECT * FROM cond_1
ORDER BY 1,2;
 bucket | device | avg_temp 
--------+--------+----------
      0 |      1 |      1.5
(1 row)

-- Refresh 1 extra bucket on the right
INSERT INTO conditions VALUES (0, 1, 3.0);
CALL refresh_continuous_aggregate('cond_1', 0, 2);
SELECT * FROM cond_1
ORDER BY 1,2;
 bucket | device | avg_temp 
--------+--------+----------
      0 |      1 |        2
(1 row)

-- Refresh 1 extra bucket on each side
INSERT INTO conditions VALUES (0, 1, 4.0);
CALL refresh_continuous_aggregate('cond_1', -1, 2);
SELECT * FROM cond_1
ORDER BY 1,2;
 bucket | device | avg_temp 
--------+--------+----------
      0 |      1 |      2.5
(1 row)

-- Clear to reset aggregate
TRUNCATE conditions;
CALL refresh_continuous_aggregate('cond_1', NULL, NULL);
-- Test invalidation of size 2
INSERT INTO conditions VALUES (0, 1, 1.0), (1, 1, 2.0);
-- Refresh one bucket at a time
CALL refresh_continuous_aggregate('cond_1', 0, 1);
SELECT * FROM cond_1
ORDER BY 1,2;
 bucket | device | avg_temp 
--------+--------+----------
      0 |      1 |        1
(1 row)

CALL refresh_continuous_aggregate('cond_1', 1, 2);
SELECT * FROM cond_1
ORDER BY 1,2;
 bucket | device | avg_temp 
--------+--------+----------
      0 |      1 |        1
      1 |      1 |        2
(2 rows)

-- Repeat the same thing but refresh the whole invalidation at once
TRUNCATE conditions;
CALL refresh_continuous_aggregate('cond_1', NULL, NULL);
INSERT INTO conditions VALUES (0, 1, 1.0), (1, 1, 2.0);
CALL refresh_continuous_aggregate('cond_1', 0, 2);
SELECT * FROM cond_1
ORDER BY 1,2;
 bucket | device | avg_temp 
--------+--------+----------
      0 |      1 |        1
      1 |      1 |        2
(2 rows)

-- Test invalidation of size 3
TRUNCATE conditions;
CALL refresh_continuous_aggregate('cond_1', NULL, NULL);
INSERT INTO conditions VALUES (0, 1, 1.0), (1, 1, 2.0), (2, 1, 3.0);
-- Invalidation extends beyond the refresh window on both ends
CALL refresh_continuous_aggregate('cond_1', 1, 2);
SELECT * FROM cond_1
ORDER BY 1,2;
 bucket | device | avg_temp 
--------+--------+----------
      1 |      1 |        2
(1 row)

-- Should leave one invalidation on each side of the refresh window
SELECT * FROM cagg_invals
WHERE cagg_id = :cond_1_id;
 cagg_id | start |         end         
---------+-------+---------------------
       6 |     0 |                   0
       6 |     2 |                   2
       6 |   110 | 9223372036854775807
(3 rows)

-- Refresh the two remaining invalidations
CALL refresh_continuous_aggregate('cond_1', 0, 1);
SELECT * FROM cond_1
ORDER BY 1,2;
 bucket | device | avg_temp 
--------+--------+----------
      0 |      1 |        1
      1 |      1 |        2
(2 rows)

CALL refresh_continuous_aggregate('cond_1', 2, 3);
SELECT * FROM cond_1
ORDER BY 1,2;
 bucket | device | avg_temp 
--------+--------+----------
      0 |      1 |        1
      1 |      1 |        2
      2 |      1 |        3
(3 rows)

-- Clear and repeat but instead refresh the whole range in one go. The
-- result should be the same as the three partial refreshes. Use
-- DELETE instead of TRUNCATE to clear this time.
DELETE FROM conditions;
CALL refresh_continuous_aggregate('cond_1', NULL, NULL);
INSERT INTO conditions VALUES (0, 1, 1.0), (1, 1, 2.0), (2, 1, 3.0);
CALL refresh_continuous_aggregate('cond_1', 0, 3);
SELECT * FROM cond_1
ORDER BY 1,2;
 bucket | device | avg_temp 
--------+--------+----------
      0 |      1 |        1
      1 |      1 |        2
      2 |      1 |        3
(3 rows)

----------------------------------------------
-- Test that invalidation threshold is capped
----------------------------------------------
CREATE table threshold_test (time int, value int);
SELECT create_hypertable('threshold_test', 'time', chunk_time_interval => 4);
NOTICE:  adding not-null constraint to column "time"
      create_hypertable      
-----------------------------
 (7,public,threshold_test,t)
(1 row)

SELECT set_integer_now_func('threshold_test', 'int_now');
 set_integer_now_func 
----------------------
 
(1 row)

CREATE MATERIALIZED VIEW thresh_2
WITH (timescaledb.continuous,
      timescaledb.materialized_only=true)
AS
SELECT time_bucket(2, time) AS bucket, max(value) AS max
FROM threshold_test
GROUP BY 1 WITH NO DATA;
SELECT raw_hypertable_id AS thresh_hyper_id, mat_hypertable_id AS thresh_cagg_id
FROM _timescaledb_catalog.continuous_agg
WHERE user_view_name = 'thresh_2' \gset
-- There's no invalidation threshold initially
SELECT * FROM _timescaledb_catalog.continuous_aggs_invalidation_threshold
WHERE hypertable_id = :thresh_hyper_id
ORDER BY 1,2;
 hypertable_id | watermark 
---------------+-----------
(0 rows)

-- Test that threshold is initilized to min value when there's no data
-- and we specify an infinite end. Note that the min value may differ
-- depending on time type.
CALL refresh_continuous_aggregate('thresh_2', 0, NULL);
NOTICE:  continuous aggregate "thresh_2" is already up-to-date
SELECT * FROM _timescaledb_catalog.continuous_aggs_invalidation_threshold
WHERE hypertable_id = :thresh_hyper_id
ORDER BY 1,2;
 hypertable_id |  watermark  
---------------+-------------
             7 | -2147483648
(1 row)

INSERT INTO threshold_test
SELECT v, v FROM generate_series(1, 10) v;
CALL refresh_continuous_aggregate('thresh_2', 0, 5);
-- Threshold should move to end of the last refreshed bucket, which is
-- the last bucket fully included in the window, i.e., the window
-- shrinks to end of previous bucket.
SELECT * FROM _timescaledb_catalog.continuous_aggs_invalidation_threshold
WHERE hypertable_id = :thresh_hyper_id
ORDER BY 1,2;
 hypertable_id | watermark 
---------------+-----------
             7 |         4
(1 row)

-- Refresh where both the start and end of the window is above the
-- max data value
CALL refresh_continuous_aggregate('thresh_2', 14, NULL);
NOTICE:  continuous aggregate "thresh_2" is already up-to-date
SELECT watermark AS thresh_hyper_id_watermark
FROM _timescaledb_catalog.continuous_aggs_invalidation_threshold
WHERE hypertable_id = :thresh_hyper_id \gset
-- Refresh where we start from the current watermark to infinity
CALL refresh_continuous_aggregate('thresh_2', :thresh_hyper_id_watermark, NULL);
NOTICE:  continuous aggregate "thresh_2" is already up-to-date
-- Now refresh with max end of the window to test that the
-- invalidation threshold is capped at the last bucket of data
CALL refresh_continuous_aggregate('thresh_2', 0, NULL);
SELECT * FROM _timescaledb_catalog.continuous_aggs_invalidation_threshold
WHERE hypertable_id = :thresh_hyper_id
ORDER BY 1,2;
 hypertable_id | watermark 
---------------+-----------
             7 |        12
(1 row)

-- Should not have processed invalidations beyond the invalidation
-- threshold.
SELECT * FROM cagg_invals
WHERE cagg_id = :thresh_cagg_id;
 cagg_id |        start         |         end         
---------+----------------------+---------------------
       8 | -9223372036854775808 |                  -1
       8 |                   12 | 9223372036854775807
(2 rows)

-- Check that things are properly materialized
SELECT * FROM thresh_2
ORDER BY 1;
 bucket | max 
--------+-----
      0 |   1
      2 |   3
      4 |   5
      6 |   7
      8 |   9
     10 |  10
(6 rows)

-- Delete the last data
SELECT show_chunks AS chunk_to_drop
FROM show_chunks('threshold_test')
ORDER BY 1 DESC
LIMIT 1 \gset
DELETE FROM threshold_test
WHERE time > 6;
-- The last data in the hypertable is gone
SELECT time_bucket(2, time) AS bucket, max(value) AS max
FROM threshold_test
GROUP BY 1
ORDER BY 1;
 bucket | max 
--------+-----
      0 |   1
      2 |   3
      4 |   5
      6 |   6
(4 rows)

-- The aggregate still holds data
SELECT * FROM thresh_2
ORDER BY 1;
 bucket | max 
--------+-----
      0 |   1
      2 |   3
      4 |   5
      6 |   7
      8 |   9
     10 |  10
(6 rows)

-- Refresh the aggregate to bring it up-to-date
CALL refresh_continuous_aggregate('thresh_2', 0, NULL);
-- Data also gone from the aggregate
SELECT * FROM thresh_2
ORDER BY 1;
 bucket | max 
--------+-----
      0 |   1
      2 |   3
      4 |   5
      6 |   6
(4 rows)

-- The invalidation threshold remains the same
SELECT * FROM _timescaledb_catalog.continuous_aggs_invalidation_threshold
WHERE hypertable_id = :thresh_hyper_id
ORDER BY 1,2;
 hypertable_id | watermark 
---------------+-----------
             7 |        12
(1 row)

-- Insert new data beyond the invalidation threshold to move it
-- forward
INSERT INTO threshold_test
SELECT v, v FROM generate_series(7, 15) v;
CALL refresh_continuous_aggregate('thresh_2', 0, NULL);
-- Aggregate now updated to reflect newly aggregated data
SELECT * FROM thresh_2
ORDER BY 1;
 bucket | max 
--------+-----
      0 |   1
      2 |   3
      4 |   5
      6 |   7
      8 |   9
     10 |  11
     12 |  13
     14 |  15
(8 rows)

-- The invalidation threshold should have moved forward to the end of
-- the new data
SELECT * FROM _timescaledb_catalog.continuous_aggs_invalidation_threshold
WHERE hypertable_id = :thresh_hyper_id
ORDER BY 1,2;
 hypertable_id | watermark 
---------------+-----------
             7 |        16
(1 row)

-- The aggregate remains invalid beyond the invalidation threshold
SELECT * FROM cagg_invals
WHERE cagg_id = :thresh_cagg_id;
 cagg_id |        start         |         end         
---------+----------------------+---------------------
       8 | -9223372036854775808 |                  -1
       8 |                   16 | 9223372036854775807
(2 rows)

----------------------------------------------------------------------
-- Test that dropping a chunk invalidates the dropped region. First
-- create another chunk so that we have two chunks. One of the chunks
-- will be dropped.
---------------------------------------------------------------------
INSERT INTO conditions VALUES (10, 1, 10.0);
-- Chunks currently associated with the hypertable
SELECT show_chunks AS chunk_to_drop
FROM show_chunks('conditions');
              chunk_to_drop              
-----------------------------------------
 _timescaledb_internal._hyper_1_34_chunk
 _timescaledb_internal._hyper_1_40_chunk
(2 rows)

-- Pick the first one to drop
SELECT show_chunks AS chunk_to_drop
FROM show_chunks('conditions')
ORDER BY 1
LIMIT 1 \gset
-- Show the data before dropping one of the chunks
SELECT * FROM conditions
ORDER BY 1,2;
 time | device | temp 
------+--------+------
    0 |      1 |    1
    1 |      1 |    2
    2 |      1 |    3
   10 |      1 |   10
(4 rows)

-- Drop one chunk
DROP TABLE :chunk_to_drop;
-- The chunk's data no longer exists in the hypertable
SELECT * FROM conditions
ORDER BY 1,2;
 time | device | temp 
------+--------+------
   10 |      1 |   10
(1 row)

-- Aggregate still remains in continuous aggregate, however
SELECT * FROM cond_1
ORDER BY 1,2;
 bucket | device | avg_temp 
--------+--------+----------
      0 |      1 |        1
      1 |      1 |        2
      2 |      1 |        3
(3 rows)

-- Refresh the continuous aggregate to make the dropped data be
-- reflected in the aggregate
CALL refresh_continuous_aggregate('cond_1', NULL, NULL);
-- Aggregate now up-to-date with the source hypertable
SELECT * FROM cond_1
ORDER BY 1,2;
 bucket | device | avg_temp 
--------+--------+----------
     10 |      1 |       10
(1 row)

-- Test that adjacent invalidations are merged
INSERT INTO conditions VALUES(1, 1, 1.0), (2, 1, 2.0);
INSERT INTO conditions VALUES(3, 1, 1.0);
INSERT INTO conditions VALUES(4, 1, 1.0);
INSERT INTO conditions VALUES(6, 1, 1.0);
CALL refresh_continuous_aggregate('cond_1', 10, NULL);
NOTICE:  continuous aggregate "cond_1" is already up-to-date
SELECT * FROM cagg_invals
WHERE cagg_id = :cond_1_id;
 cagg_id | start |         end         
---------+-------+---------------------
       6 |     1 |                   4
       6 |     6 |                   6
       6 |   110 | 9223372036854775807
(3 rows)

