-- This file and its contents are licensed under the Timescale License.
-- Please see the included NOTICE for copyright information and
-- LICENSE-TIMESCALE for a copy of the license.
\c :TEST_DBNAME :ROLE_CLUSTER_SUPERUSER;
\set TEST_BASE_NAME dist_query
-- Run
SELECT format('include/%s_load.sql', :'TEST_BASE_NAME') AS "TEST_LOAD_NAME",
       format('include/%s_run.sql', :'TEST_BASE_NAME') AS "TEST_QUERY_NAME",
       format('%s/results/%s_results_reference.out', :'TEST_OUTPUT_DIR', :'TEST_BASE_NAME') AS "TEST_RESULTS_REFERENCE",
       format('%s/results/%s_results_repartitioning_reference.out', :'TEST_OUTPUT_DIR', :'TEST_BASE_NAME') AS "TEST_RESULTS_REPART_REFERENCE",
       format('%s/results/%s_results_optimized.out', :'TEST_OUTPUT_DIR', :'TEST_BASE_NAME') AS "TEST_RESULTS_OPTIMIZED",
       format('%s/results/%s_results_repartitioning_optimized.out', :'TEST_OUTPUT_DIR', :'TEST_BASE_NAME') AS "TEST_RESULTS_REPART_OPTIMIZED",
       format('%s/results/%s_results_unoptimized.out', :'TEST_OUTPUT_DIR', :'TEST_BASE_NAME') AS "TEST_RESULTS_UNOPTIMIZED",
       format('%s/results/%s_results_1dim.out', :'TEST_OUTPUT_DIR', :'TEST_BASE_NAME') AS "TEST_RESULTS_1DIM"
\gset
SELECT format('\! diff %s %s', :'TEST_RESULTS_UNOPTIMIZED', :'TEST_RESULTS_REFERENCE') AS "DIFF_CMD_UNOPT",
       format('\! diff %s %s', :'TEST_RESULTS_OPTIMIZED', :'TEST_RESULTS_REFERENCE') AS "DIFF_CMD_OPT",
       format('\! diff %s %s', :'TEST_RESULTS_REPART_OPTIMIZED', :'TEST_RESULTS_REPART_REFERENCE') AS "DIFF_CMD_REPART",
       format('\! diff %s %s', :'TEST_RESULTS_1DIM', :'TEST_RESULTS_REPART_REFERENCE') AS "DIFF_CMD_1DIM"
\gset
SET client_min_messages TO notice;
-- Load the data
\ir :TEST_LOAD_NAME
-- This file and its contents are licensed under the Timescale License.
-- Please see the included NOTICE for copyright information and
-- LICENSE-TIMESCALE for a copy of the license.
\ir debugsupport.sql
-- This file and its contents are licensed under the Timescale License.
-- Please see the included NOTICE for copyright information and
-- LICENSE-TIMESCALE for a copy of the license.
CREATE OR REPLACE FUNCTION test.tsl_override_current_timestamptz(new_value TIMESTAMPTZ)
RETURNS VOID AS :TSL_MODULE_PATHNAME, 'ts_test_override_current_timestamptz' LANGUAGE C VOLATILE STRICT;
-- Cleanup from other tests that might have created these databases
SET client_min_messages TO ERROR;
SET ROLE :ROLE_CLUSTER_SUPERUSER;
DROP DATABASE IF EXISTS data_node_1;
DROP DATABASE IF EXISTS data_node_2;
DROP DATABASE IF EXISTS data_node_3;
SELECT * FROM add_data_node('data_node_1', host => 'localhost',
                            database => 'data_node_1');
  node_name  |   host    | port  |  database   | node_created | database_created | extension_created 
-------------+-----------+-------+-------------+--------------+------------------+-------------------
 data_node_1 | localhost | 55432 | data_node_1 | t            | t                | t
(1 row)

SELECT * FROM add_data_node('data_node_2', host => 'localhost',
                            database => 'data_node_2');
  node_name  |   host    | port  |  database   | node_created | database_created | extension_created 
-------------+-----------+-------+-------------+--------------+------------------+-------------------
 data_node_2 | localhost | 55432 | data_node_2 | t            | t                | t
(1 row)

SELECT * FROM add_data_node('data_node_3', host => 'localhost',
                            database => 'data_node_3');
  node_name  |   host    | port  |  database   | node_created | database_created | extension_created 
-------------+-----------+-------+-------------+--------------+------------------+-------------------
 data_node_3 | localhost | 55432 | data_node_3 | t            | t                | t
(1 row)

GRANT USAGE ON FOREIGN SERVER data_node_1, data_node_2, data_node_3 TO :ROLE_1;
SET ROLE :ROLE_1;
-- Create a "normal" PG table as reference, one two-dimensional
-- distributed hypertable, and a one-dimensional distributed
-- hypertable
CREATE TABLE reference (time timestamptz, device int, location int, temp float);
CREATE TABLE hyper (LIKE reference);
CREATE TABLE hyper1d (LIKE reference);
SELECT create_distributed_hypertable('hyper', 'time', 'device', 3,
                                     chunk_time_interval => interval '18 hours');
 create_distributed_hypertable 
-------------------------------
 (1,public,hyper,t)
(1 row)

SELECT create_distributed_hypertable('hyper1d', 'time', chunk_time_interval => interval '36 hours');
 create_distributed_hypertable 
-------------------------------
 (2,public,hyper1d,t)
(1 row)

SELECT setseed(1);
 setseed 
---------
 
(1 row)

INSERT INTO reference
SELECT t, (abs(timestamp_hash(t::timestamp)) % 10) + 1, (random() * 20)::int, random() * 80
FROM generate_series('2019-01-01'::timestamptz, '2019-01-04'::timestamptz, '1 minute') as t;
-- Insert the same data into the hypertable but repartition the data
-- set so that we can test the "safeness" of some push-downs across
-- the repartitioning boundary.
INSERT INTO hyper
SELECT * FROM reference
WHERE time < '2019-01-02 05:10'::timestamptz;
SELECT * FROM set_number_partitions('hyper', 2);
 set_number_partitions 
-----------------------
 
(1 row)

INSERT INTO hyper
SELECT * FROM reference
WHERE time >= '2019-01-02 05:10'::timestamptz
AND time < '2019-01-03 01:22'::timestamptz;
SELECT * FROM set_number_partitions('hyper', 5);
 set_number_partitions 
-----------------------
 
(1 row)

INSERT INTO hyper
SELECT * FROM reference
WHERE time >= '2019-01-03 01:22'::timestamptz;
INSERT INTO hyper1d
SELECT * FROM reference;
SELECT d.hypertable_id, d.id, ds.range_start, ds.range_end
FROM _timescaledb_catalog.dimension d, _timescaledb_catalog.dimension_slice ds
WHERE num_slices IS NOT NULL
AND d.id = ds.dimension_id
ORDER BY 1, 2, 3;
 hypertable_id | id |     range_start      |      range_end      
---------------+----+----------------------+---------------------
             1 |  2 | -9223372036854775808 |          1073741823
             1 |  2 | -9223372036854775808 |           429496729
             1 |  2 | -9223372036854775808 |           715827882
             1 |  2 |            429496729 |           858993458
             1 |  2 |            715827882 |          1431655764
             1 |  2 |            858993458 |          1288490187
             1 |  2 |           1073741823 | 9223372036854775807
             1 |  2 |           1288490187 |          1717986916
             1 |  2 |           1431655764 | 9223372036854775807
             1 |  2 |           1717986916 | 9223372036854775807
(10 rows)

-- Set the max time we can query without hitting the repartitioned
-- chunks. Note that this is before the given repartitioning time
-- above because chunk boundaries do not align exactly with the given
-- timestamp
\set REPARTITIONED_TIME_RANGE 'time >= ''2019-01-01'''
\set CLEAN_PARTITIONING_TIME_RANGE 'time BETWEEN ''2019-01-01'' AND ''2019-01-01 15:00'''
-- Custom agg func for push down tests
CREATE AGGREGATE custom_sum(int4) (
    SFUNC = int4_sum,
    STYPE = int8
);
-- Set seed on all data nodes for ANALYZE to sample consistently
CALL distributed_exec($$ SELECT setseed(1); $$);
ANALYZE reference;
ANALYZE hyper;
ANALYZE hyper1d;
SELECT hypertable_schema, hypertable_name, num_dimensions, num_chunks
FROM timescaledb_information.hypertables
ORDER BY 1,2;
 hypertable_schema | hypertable_name | num_dimensions | num_chunks 
-------------------+-----------------+----------------+------------
 public            | hyper           |              2 |         18
 public            | hyper1d         |              1 |          3
(2 rows)

SELECT count(*) FROM hyper;
 count 
-------
  4321
(1 row)

SELECT count(*) FROM hyper WHERE :CLEAN_PARTITIONING_TIME_RANGE;
 count 
-------
   901
(1 row)

SET enable_partitionwise_aggregate = ON;
\set ECHO errors

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% RUNNING TESTS on table: hyper
%%% PREFIX: EXPLAIN (verbose, costs off)
%%% WHERE_CLAUSE: :CLEAN_PARTITIONING_TIME_RANGE
%%% ORDER_BY_1: 
%%% ORDER_BY_1_2: 
%%% LIMIT: 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
 setseed 
---------
 
(1 row)


######### Grouping on time only (partial aggregation)

EXPLAIN (verbose, costs off)
SELECT time, avg(temp)
FROM hyper
WHERE time BETWEEN '2019-01-01' AND '2019-01-01 15:00'
GROUP BY 1


                                                                                                                                                              QUERY PLAN                                                                                                                                                               
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Finalize HashAggregate
   Output: "time", avg(temp)
   Group Key: "time"
   ->  Custom Scan (AsyncAppend)
         Output: "time", (PARTIAL avg(temp))
         ->  Append
               ->  Custom Scan (DataNodeScan)
                     Output: hyper."time", (PARTIAL avg(hyper.temp))
                     Relations: Aggregate on (public.hyper)
                     Data node: data_node_1
                     Chunks: _dist_hyper_1_1_chunk
                     Remote SQL: SELECT "time", _timescaledb_internal.partialize_agg(avg(temp)) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) GROUP BY 1
               ->  Custom Scan (DataNodeScan)
                     Output: hyper_1."time", (PARTIAL avg(hyper_1.temp))
                     Relations: Aggregate on (public.hyper)
                     Data node: data_node_2
                     Chunks: _dist_hyper_1_2_chunk
                     Remote SQL: SELECT "time", _timescaledb_internal.partialize_agg(avg(temp)) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) GROUP BY 1
               ->  Partial GroupAggregate
                     Output: hyper_2."time", PARTIAL avg(hyper_2.temp)
                     Group Key: hyper_2."time"
                     ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                           Output: hyper_2."time", hyper_2.temp
                           Data node: data_node_3
                           Chunks: _dist_hyper_1_3_chunk
                           Remote SQL: SELECT "time", temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY "time" ASC NULLS LAST
(26 rows)


######### Grouping on time only (partial aggregation)

EXPLAIN (verbose, costs off)
SELECT time_bucket('2 days', time) AS time, avg(temp)
FROM hyper
WHERE time BETWEEN '2019-01-01' AND '2019-01-01 15:00'
GROUP BY 1


                                                                                                                                                                                   QUERY PLAN                                                                                                                                                                                    
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Finalize HashAggregate
   Output: (time_bucket('@ 2 days'::interval, "time")), avg(temp)
   Group Key: (time_bucket('@ 2 days'::interval, "time"))
   ->  Custom Scan (AsyncAppend)
         Output: (time_bucket('@ 2 days'::interval, "time")), (PARTIAL avg(temp))
         ->  Append
               ->  Custom Scan (DataNodeScan)
                     Output: (time_bucket('@ 2 days'::interval, hyper."time")), (PARTIAL avg(hyper.temp))
                     Relations: Aggregate on (public.hyper)
                     Data node: data_node_1
                     Chunks: _dist_hyper_1_1_chunk
                     Remote SQL: SELECT public.time_bucket('@ 2 days'::interval, "time"), _timescaledb_internal.partialize_agg(avg(temp)) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) GROUP BY 1
               ->  Custom Scan (DataNodeScan)
                     Output: (time_bucket('@ 2 days'::interval, hyper_1."time")), (PARTIAL avg(hyper_1.temp))
                     Relations: Aggregate on (public.hyper)
                     Data node: data_node_2
                     Chunks: _dist_hyper_1_2_chunk
                     Remote SQL: SELECT public.time_bucket('@ 2 days'::interval, "time"), _timescaledb_internal.partialize_agg(avg(temp)) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) GROUP BY 1
               ->  Partial GroupAggregate
                     Output: (time_bucket('@ 2 days'::interval, hyper_2."time")), PARTIAL avg(hyper_2.temp)
                     Group Key: time_bucket('@ 2 days'::interval, hyper_2."time")
                     ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                           Output: time_bucket('@ 2 days'::interval, hyper_2."time"), hyper_2.temp
                           Data node: data_node_3
                           Chunks: _dist_hyper_1_3_chunk
                           Remote SQL: SELECT "time", temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY public.time_bucket('2 days'::interval, "time") ASC NULLS LAST
(26 rows)


######### Grouping on time and device (full aggregation)

EXPLAIN (verbose, costs off)
SELECT time, device, avg(temp)
FROM hyper
WHERE time BETWEEN '2019-01-01' AND '2019-01-01 15:00'
GROUP BY 1,2


                                                                                                                                                                  QUERY PLAN                                                                                                                                                                   
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Custom Scan (AsyncAppend)
   Output: "time", device, (avg(temp))
   ->  Append
         ->  Custom Scan (DataNodeScan)
               Output: hyper."time", hyper.device, (avg(hyper.temp))
               Relations: Aggregate on (public.hyper)
               Data node: data_node_1
               Chunks: _dist_hyper_1_1_chunk
               Remote SQL: SELECT "time", device, avg(temp) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) GROUP BY 1, 2
         ->  Custom Scan (DataNodeScan)
               Output: hyper_1."time", hyper_1.device, (avg(hyper_1.temp))
               Relations: Aggregate on (public.hyper)
               Data node: data_node_2
               Chunks: _dist_hyper_1_2_chunk
               Remote SQL: SELECT "time", device, avg(temp) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) GROUP BY 1, 2
         ->  GroupAggregate
               Output: hyper_2."time", hyper_2.device, avg(hyper_2.temp)
               Group Key: hyper_2."time", hyper_2.device
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                     Output: hyper_2."time", hyper_2.device, hyper_2.temp
                     Data node: data_node_3
                     Chunks: _dist_hyper_1_3_chunk
                     Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST
(23 rows)


######### Grouping on time and device (full aggregation)

EXPLAIN (verbose, costs off)
SELECT time_bucket('2 days', time) AS time, device, avg(temp)
FROM hyper
WHERE time BETWEEN '2019-01-01' AND '2019-01-01 15:00'
GROUP BY 1,2


                                                                                                                                                                                      QUERY PLAN                                                                                                                                                                                       
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Custom Scan (AsyncAppend)
   Output: (time_bucket('@ 2 days'::interval, "time")), device, (avg(temp))
   ->  Append
         ->  Custom Scan (DataNodeScan)
               Output: (time_bucket('@ 2 days'::interval, hyper."time")), hyper.device, (avg(hyper.temp))
               Relations: Aggregate on (public.hyper)
               Data node: data_node_1
               Chunks: _dist_hyper_1_1_chunk
               Remote SQL: SELECT public.time_bucket('@ 2 days'::interval, "time"), device, avg(temp) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) GROUP BY 1, 2
         ->  Custom Scan (DataNodeScan)
               Output: (time_bucket('@ 2 days'::interval, hyper_1."time")), hyper_1.device, (avg(hyper_1.temp))
               Relations: Aggregate on (public.hyper)
               Data node: data_node_2
               Chunks: _dist_hyper_1_2_chunk
               Remote SQL: SELECT public.time_bucket('@ 2 days'::interval, "time"), device, avg(temp) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) GROUP BY 1, 2
         ->  GroupAggregate
               Output: (time_bucket('@ 2 days'::interval, hyper_2."time")), hyper_2.device, avg(hyper_2.temp)
               Group Key: time_bucket('@ 2 days'::interval, hyper_2."time"), hyper_2.device
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                     Output: time_bucket('@ 2 days'::interval, hyper_2."time"), hyper_2.device, hyper_2.temp
                     Data node: data_node_3
                     Chunks: _dist_hyper_1_3_chunk
                     Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY public.time_bucket('2 days'::interval, "time") ASC NULLS LAST, device ASC NULLS LAST
(23 rows)


######### Grouping on time and device (full aggregation)

EXPLAIN (verbose, costs off)
SELECT date_trunc('month', time) AS time, device, avg(temp)
FROM hyper
WHERE time BETWEEN '2019-01-01' AND '2019-01-01 15:00'
GROUP BY 1,2


                                                                                                                                                                                QUERY PLAN                                                                                                                                                                                
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Custom Scan (AsyncAppend)
   Output: (date_trunc('month'::text, "time")), device, (avg(temp))
   ->  Append
         ->  Custom Scan (DataNodeScan)
               Output: (date_trunc('month'::text, hyper."time")), hyper.device, (avg(hyper.temp))
               Relations: Aggregate on (public.hyper)
               Data node: data_node_1
               Chunks: _dist_hyper_1_1_chunk
               Remote SQL: SELECT date_trunc('month'::text, "time"), device, avg(temp) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) GROUP BY 1, 2
         ->  Custom Scan (DataNodeScan)
               Output: (date_trunc('month'::text, hyper_1."time")), hyper_1.device, (avg(hyper_1.temp))
               Relations: Aggregate on (public.hyper)
               Data node: data_node_2
               Chunks: _dist_hyper_1_2_chunk
               Remote SQL: SELECT date_trunc('month'::text, "time"), device, avg(temp) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) GROUP BY 1, 2
         ->  GroupAggregate
               Output: (date_trunc('month'::text, hyper_2."time")), hyper_2.device, avg(hyper_2.temp)
               Group Key: date_trunc('month'::text, hyper_2."time"), hyper_2.device
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                     Output: date_trunc('month'::text, hyper_2."time"), hyper_2.device, hyper_2.temp
                     Data node: data_node_3
                     Chunks: _dist_hyper_1_3_chunk
                     Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY date_trunc('month'::text, "time") ASC NULLS LAST, device ASC NULLS LAST
(23 rows)


######### Grouping on time and device (full aggregation)

EXPLAIN (verbose, costs off)
SELECT time_bucket('2 days', time) AS time, device, avg(temp)
FROM hyper
WHERE time BETWEEN '2019-01-01' AND '2019-01-01 15:00'
GROUP BY 1,2
HAVING device > 4


                                                                                                                                                                                                QUERY PLAN                                                                                                                                                                                                
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Custom Scan (AsyncAppend)
   Output: (time_bucket('@ 2 days'::interval, "time")), device, (avg(temp))
   ->  Append
         ->  Custom Scan (DataNodeScan)
               Output: (time_bucket('@ 2 days'::interval, hyper."time")), hyper.device, (avg(hyper.temp))
               Relations: Aggregate on (public.hyper)
               Data node: data_node_1
               Chunks: _dist_hyper_1_1_chunk
               Remote SQL: SELECT public.time_bucket('@ 2 days'::interval, "time"), device, avg(temp) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) AND ((device > 4)) GROUP BY 1, 2
         ->  Custom Scan (DataNodeScan)
               Output: (time_bucket('@ 2 days'::interval, hyper_1."time")), hyper_1.device, (avg(hyper_1.temp))
               Relations: Aggregate on (public.hyper)
               Data node: data_node_2
               Chunks: _dist_hyper_1_2_chunk
               Remote SQL: SELECT public.time_bucket('@ 2 days'::interval, "time"), device, avg(temp) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) AND ((device > 4)) GROUP BY 1, 2
         ->  GroupAggregate
               Output: (time_bucket('@ 2 days'::interval, hyper_2."time")), hyper_2.device, avg(hyper_2.temp)
               Group Key: time_bucket('@ 2 days'::interval, hyper_2."time"), hyper_2.device
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                     Output: time_bucket('@ 2 days'::interval, hyper_2."time"), hyper_2.device, hyper_2.temp
                     Data node: data_node_3
                     Chunks: _dist_hyper_1_3_chunk
                     Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) AND ((device > 4)) ORDER BY public.time_bucket('2 days'::interval, "time") ASC NULLS LAST, device ASC NULLS LAST
(23 rows)

EXPLAIN (verbose, costs off)
SELECT time_bucket('2 days', time) AS time, device, avg(temp)
FROM hyper
WHERE time BETWEEN '2019-01-01' AND '2019-01-01 15:00'
GROUP BY 1,2
HAVING avg(temp) > 40 AND max(temp) < 70


                                                                                                                                                                                                             QUERY PLAN                                                                                                                                                                                                              
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Custom Scan (AsyncAppend)
   Output: (time_bucket('@ 2 days'::interval, "time")), device, (avg(temp))
   ->  Append
         ->  Custom Scan (DataNodeScan)
               Output: (time_bucket('@ 2 days'::interval, hyper."time")), hyper.device, (avg(hyper.temp))
               Relations: Aggregate on (public.hyper)
               Data node: data_node_1
               Chunks: _dist_hyper_1_1_chunk
               Remote SQL: SELECT public.time_bucket('@ 2 days'::interval, "time"), device, avg(temp) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) GROUP BY 1, 2 HAVING ((avg(temp) > 40::double precision)) AND ((max(temp) < 70::double precision))
         ->  Custom Scan (DataNodeScan)
               Output: (time_bucket('@ 2 days'::interval, hyper_1."time")), hyper_1.device, (avg(hyper_1.temp))
               Relations: Aggregate on (public.hyper)
               Data node: data_node_2
               Chunks: _dist_hyper_1_2_chunk
               Remote SQL: SELECT public.time_bucket('@ 2 days'::interval, "time"), device, avg(temp) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) GROUP BY 1, 2 HAVING ((avg(temp) > 40::double precision)) AND ((max(temp) < 70::double precision))
         ->  Custom Scan (DataNodeScan)
               Output: (time_bucket('@ 2 days'::interval, hyper_2."time")), hyper_2.device, (avg(hyper_2.temp))
               Relations: Aggregate on (public.hyper)
               Data node: data_node_3
               Chunks: _dist_hyper_1_3_chunk
               Remote SQL: SELECT public.time_bucket('@ 2 days'::interval, "time"), device, avg(temp) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) GROUP BY 1, 2 HAVING ((avg(temp) > 40::double precision)) AND ((max(temp) < 70::double precision))
(21 rows)


######### Grouping on device only (full aggregation)

EXPLAIN (verbose, costs off)
SELECT device, avg(temp)
FROM hyper
WHERE time BETWEEN '2019-01-01' AND '2019-01-01 15:00'
GROUP BY 1


                                                                                                                                                   QUERY PLAN                                                                                                                                                   
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Custom Scan (AsyncAppend)
   Output: device, (avg(temp))
   ->  Append
         ->  Custom Scan (DataNodeScan)
               Output: hyper.device, (avg(hyper.temp))
               Relations: Aggregate on (public.hyper)
               Data node: data_node_1
               Chunks: _dist_hyper_1_1_chunk
               Remote SQL: SELECT device, avg(temp) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) GROUP BY 1
         ->  Custom Scan (DataNodeScan)
               Output: hyper_1.device, (avg(hyper_1.temp))
               Relations: Aggregate on (public.hyper)
               Data node: data_node_2
               Chunks: _dist_hyper_1_2_chunk
               Remote SQL: SELECT device, avg(temp) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) GROUP BY 1
         ->  GroupAggregate
               Output: hyper_2.device, avg(hyper_2.temp)
               Group Key: hyper_2.device
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                     Output: hyper_2.device, hyper_2.temp
                     Data node: data_node_3
                     Chunks: _dist_hyper_1_3_chunk
                     Remote SQL: SELECT device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY device ASC NULLS LAST
(23 rows)


######### No push down on some functions

EXPLAIN (verbose, costs off)
SELECT location, avg(temp)
FROM hyper
WHERE time BETWEEN '2019-01-01' AND '2019-01-01 15:00' AND (temp * random() >= 0)
GROUP BY 1


                                                                                                                                                     QUERY PLAN                                                                                                                                                     
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 GroupAggregate
   Output: hyper.location, avg(hyper.temp)
   Group Key: hyper.location
   ->  Custom Scan (AsyncAppend)
         Output: hyper.location, hyper.temp
         ->  Merge Append
               Sort Key: hyper_1.location
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_1
                     Output: hyper_1.location, hyper_1.temp
                     Filter: ((hyper_1.temp * random()) >= '0'::double precision)
                     Data node: data_node_1
                     Chunks: _dist_hyper_1_1_chunk
                     Remote SQL: SELECT location, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY location ASC NULLS LAST
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                     Output: hyper_2.location, hyper_2.temp
                     Filter: ((hyper_2.temp * random()) >= '0'::double precision)
                     Data node: data_node_2
                     Chunks: _dist_hyper_1_2_chunk
                     Remote SQL: SELECT location, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY location ASC NULLS LAST
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_3
                     Output: hyper_3.location, hyper_3.temp
                     Filter: ((hyper_3.temp * random()) >= '0'::double precision)
                     Data node: data_node_3
                     Chunks: _dist_hyper_1_3_chunk
                     Remote SQL: SELECT location, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY location ASC NULLS LAST
(25 rows)


######### No push down on some functions

EXPLAIN (verbose, costs off)
SELECT time_bucket('2 days', time) AS time, device, avg(temp), sum(temp * (random() <= 1)::int) as sum
FROM hyper
WHERE time BETWEEN '2019-01-01' AND '2019-01-01 15:00'
GROUP BY 1,2


                                                                                                                                                                                      QUERY PLAN                                                                                                                                                                                       
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 HashAggregate
   Output: (time_bucket('@ 2 days'::interval, hyper."time")), hyper.device, avg(hyper.temp), sum((hyper.temp * (((random() <= '1'::double precision))::integer)::double precision))
   Group Key: (time_bucket('@ 2 days'::interval, hyper."time")), hyper.device
   ->  Custom Scan (AsyncAppend)
         Output: (time_bucket('@ 2 days'::interval, hyper."time")), hyper.device, hyper.temp
         ->  Append
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_1
                     Output: time_bucket('@ 2 days'::interval, hyper_1."time"), hyper_1.device, hyper_1.temp
                     Data node: data_node_1
                     Chunks: _dist_hyper_1_1_chunk
                     Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY public.time_bucket('2 days'::interval, "time") ASC NULLS LAST, device ASC NULLS LAST
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                     Output: time_bucket('@ 2 days'::interval, hyper_2."time"), hyper_2.device, hyper_2.temp
                     Data node: data_node_2
                     Chunks: _dist_hyper_1_2_chunk
                     Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY public.time_bucket('2 days'::interval, "time") ASC NULLS LAST, device ASC NULLS LAST
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_3
                     Output: time_bucket('@ 2 days'::interval, hyper_3."time"), hyper_3.device, hyper_3.temp
                     Data node: data_node_3
                     Chunks: _dist_hyper_1_3_chunk
                     Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY public.time_bucket('2 days'::interval, "time") ASC NULLS LAST, device ASC NULLS LAST
(21 rows)


######### No push down on some functions

EXPLAIN (verbose, costs off)
SELECT time, device, avg(temp)
FROM hyper
WHERE time BETWEEN '2019-01-01' AND '2019-01-01 15:00'
GROUP BY 1,2
HAVING avg(temp) * custom_sum(device) > 0.8


                                                                                                                                                                  QUERY PLAN                                                                                                                                                                   
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 HashAggregate
   Output: hyper."time", hyper.device, avg(hyper.temp)
   Group Key: hyper."time", hyper.device
   Filter: ((avg(hyper.temp) * (custom_sum(hyper.device))::double precision) > '0.8'::double precision)
   ->  Custom Scan (AsyncAppend)
         Output: hyper."time", hyper.device, hyper.temp
         ->  Append
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_1
                     Output: hyper_1."time", hyper_1.device, hyper_1.temp
                     Data node: data_node_1
                     Chunks: _dist_hyper_1_1_chunk
                     Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                     Output: hyper_2."time", hyper_2.device, hyper_2.temp
                     Data node: data_node_2
                     Chunks: _dist_hyper_1_2_chunk
                     Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_3
                     Output: hyper_3."time", hyper_3.device, hyper_3.temp
                     Data node: data_node_3
                     Chunks: _dist_hyper_1_3_chunk
                     Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST
(22 rows)


######### No push down on some functions

EXPLAIN (verbose, costs off)
SELECT time, device, avg(temp), custom_sum(device)
FROM hyper
WHERE time BETWEEN '2019-01-01' AND '2019-01-01 15:00'
GROUP BY 1,2


                                                                                                                                                                  QUERY PLAN                                                                                                                                                                   
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 HashAggregate
   Output: hyper."time", hyper.device, avg(hyper.temp), custom_sum(hyper.device)
   Group Key: hyper."time", hyper.device
   ->  Custom Scan (AsyncAppend)
         Output: hyper."time", hyper.device, hyper.temp
         ->  Append
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_1
                     Output: hyper_1."time", hyper_1.device, hyper_1.temp
                     Data node: data_node_1
                     Chunks: _dist_hyper_1_1_chunk
                     Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                     Output: hyper_2."time", hyper_2.device, hyper_2.temp
                     Data node: data_node_2
                     Chunks: _dist_hyper_1_2_chunk
                     Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_3
                     Output: hyper_3."time", hyper_3.device, hyper_3.temp
                     Data node: data_node_3
                     Chunks: _dist_hyper_1_3_chunk
                     Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST
(21 rows)


######### Constification and runtime push down of time-related functions

 tsl_override_current_timestamptz 
----------------------------------
 
(1 row)

                                                                                                                                                                  QUERY PLAN                                                                                                                                                                   
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Custom Scan (AsyncAppend)
   Output: "time", device, (avg(temp))
   ->  Append
         ->  Custom Scan (DataNodeScan)
               Output: hyper."time", hyper.device, (avg(hyper.temp))
               Relations: Aggregate on (public.hyper)
               Data node: data_node_1
               Chunks: _dist_hyper_1_1_chunk
               Remote SQL: SELECT "time", device, avg(temp) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) GROUP BY 1, 2
         ->  Custom Scan (DataNodeScan)
               Output: hyper_1."time", hyper_1.device, (avg(hyper_1.temp))
               Relations: Aggregate on (public.hyper)
               Data node: data_node_2
               Chunks: _dist_hyper_1_2_chunk
               Remote SQL: SELECT "time", device, avg(temp) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) GROUP BY 1, 2
         ->  GroupAggregate
               Output: hyper_2."time", hyper_2.device, avg(hyper_2.temp)
               Group Key: hyper_2."time", hyper_2.device
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                     Output: hyper_2."time", hyper_2.device, hyper_2.temp
                     Data node: data_node_3
                     Chunks: _dist_hyper_1_3_chunk
                     Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST
(23 rows)

                                                                                                                                                                  QUERY PLAN                                                                                                                                                                   
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Custom Scan (AsyncAppend)
   Output: "time", device, (avg(temp))
   ->  Append
         ->  Custom Scan (DataNodeScan)
               Output: hyper."time", hyper.device, (avg(hyper.temp))
               Relations: Aggregate on (public.hyper)
               Data node: data_node_1
               Chunks: _dist_hyper_1_1_chunk
               Remote SQL: SELECT "time", device, avg(temp) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) GROUP BY 1, 2
         ->  Custom Scan (DataNodeScan)
               Output: hyper_1."time", hyper_1.device, (avg(hyper_1.temp))
               Relations: Aggregate on (public.hyper)
               Data node: data_node_2
               Chunks: _dist_hyper_1_2_chunk
               Remote SQL: SELECT "time", device, avg(temp) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) GROUP BY 1, 2
         ->  GroupAggregate
               Output: hyper_2."time", hyper_2.device, avg(hyper_2.temp)
               Group Key: hyper_2."time", hyper_2.device
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                     Output: hyper_2."time", hyper_2.device, hyper_2.temp
                     Data node: data_node_3
                     Chunks: _dist_hyper_1_3_chunk
                     Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST
(23 rows)

 tsl_override_current_timestamptz 
----------------------------------
 
(1 row)

                                                                                                                                                                  QUERY PLAN                                                                                                                                                                   
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Custom Scan (AsyncAppend)
   Output: "time", device, (avg(temp))
   ->  Append
         ->  Custom Scan (DataNodeScan)
               Output: hyper."time", hyper.device, (avg(hyper.temp))
               Relations: Aggregate on (public.hyper)
               Data node: data_node_1
               Chunks: _dist_hyper_1_1_chunk
               Remote SQL: SELECT "time", device, avg(temp) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) GROUP BY 1, 2
         ->  Custom Scan (DataNodeScan)
               Output: hyper_1."time", hyper_1.device, (avg(hyper_1.temp))
               Relations: Aggregate on (public.hyper)
               Data node: data_node_2
               Chunks: _dist_hyper_1_2_chunk
               Remote SQL: SELECT "time", device, avg(temp) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) GROUP BY 1, 2
         ->  GroupAggregate
               Output: hyper_2."time", hyper_2.device, avg(hyper_2.temp)
               Group Key: hyper_2."time", hyper_2.device
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                     Output: hyper_2."time", hyper_2.device, hyper_2.temp
                     Data node: data_node_3
                     Chunks: _dist_hyper_1_3_chunk
                     Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST
(23 rows)


######### LIMIT push down cases

EXPLAIN (verbose, costs off)
SELECT time, device
FROM hyper

LIMIT 10
                                                                                           QUERY PLAN                                                                                            
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit
   Output: hyper."time", hyper.device
   ->  Custom Scan (AsyncAppend)
         Output: hyper."time", hyper.device
         ->  Append
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_1
                     Output: hyper_1."time", hyper_1.device
                     Data node: data_node_1
                     Chunks: _dist_hyper_1_1_chunk, _dist_hyper_1_4_chunk, _dist_hyper_1_8_chunk, _dist_hyper_1_12_chunk, _dist_hyper_1_13_chunk, _dist_hyper_1_15_chunk, _dist_hyper_1_17_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) LIMIT 10
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                     Output: hyper_2."time", hyper_2.device
                     Data node: data_node_2
                     Chunks: _dist_hyper_1_2_chunk, _dist_hyper_1_5_chunk, _dist_hyper_1_7_chunk, _dist_hyper_1_9_chunk, _dist_hyper_1_11_chunk, _dist_hyper_1_14_chunk, _dist_hyper_1_18_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) LIMIT 10
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_3
                     Output: hyper_3."time", hyper_3.device
                     Data node: data_node_3
                     Chunks: _dist_hyper_1_3_chunk, _dist_hyper_1_6_chunk, _dist_hyper_1_10_chunk, _dist_hyper_1_16_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4]) LIMIT 10
(20 rows)


######### LIMIT push down cases

EXPLAIN (verbose, costs off)
SELECT time, device
FROM hyper

LIMIT 5
OFFSET 5
                                                                                           QUERY PLAN                                                                                            
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit
   Output: hyper."time", hyper.device
   ->  Custom Scan (AsyncAppend)
         Output: hyper."time", hyper.device
         ->  Append
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_1
                     Output: hyper_1."time", hyper_1.device
                     Data node: data_node_1
                     Chunks: _dist_hyper_1_1_chunk, _dist_hyper_1_4_chunk, _dist_hyper_1_8_chunk, _dist_hyper_1_12_chunk, _dist_hyper_1_13_chunk, _dist_hyper_1_15_chunk, _dist_hyper_1_17_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) LIMIT 10
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                     Output: hyper_2."time", hyper_2.device
                     Data node: data_node_2
                     Chunks: _dist_hyper_1_2_chunk, _dist_hyper_1_5_chunk, _dist_hyper_1_7_chunk, _dist_hyper_1_9_chunk, _dist_hyper_1_11_chunk, _dist_hyper_1_14_chunk, _dist_hyper_1_18_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) LIMIT 10
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_3
                     Output: hyper_3."time", hyper_3.device
                     Data node: data_node_3
                     Chunks: _dist_hyper_1_3_chunk, _dist_hyper_1_6_chunk, _dist_hyper_1_10_chunk, _dist_hyper_1_16_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4]) LIMIT 10
(20 rows)


######### LIMIT push down cases

EXPLAIN (verbose, costs off)
SELECT time, device
FROM hyper

LIMIT 0
                                                                                           QUERY PLAN                                                                                            
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit
   Output: hyper."time", hyper.device
   ->  Custom Scan (AsyncAppend)
         Output: hyper."time", hyper.device
         ->  Append
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_1
                     Output: hyper_1."time", hyper_1.device
                     Data node: data_node_1
                     Chunks: _dist_hyper_1_1_chunk, _dist_hyper_1_4_chunk, _dist_hyper_1_8_chunk, _dist_hyper_1_12_chunk, _dist_hyper_1_13_chunk, _dist_hyper_1_15_chunk, _dist_hyper_1_17_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) LIMIT 1
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                     Output: hyper_2."time", hyper_2.device
                     Data node: data_node_2
                     Chunks: _dist_hyper_1_2_chunk, _dist_hyper_1_5_chunk, _dist_hyper_1_7_chunk, _dist_hyper_1_9_chunk, _dist_hyper_1_11_chunk, _dist_hyper_1_14_chunk, _dist_hyper_1_18_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) LIMIT 1
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_3
                     Output: hyper_3."time", hyper_3.device
                     Data node: data_node_3
                     Chunks: _dist_hyper_1_3_chunk, _dist_hyper_1_6_chunk, _dist_hyper_1_10_chunk, _dist_hyper_1_16_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4]) LIMIT 1
(20 rows)


######### LIMIT push down cases

EXPLAIN (verbose, costs off)
SELECT time, device
FROM hyper

LIMIT extract(year from date '2000-01-01')
                                                                                           QUERY PLAN                                                                                            
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit
   Output: hyper."time", hyper.device
   ->  Custom Scan (AsyncAppend)
         Output: hyper."time", hyper.device
         ->  Append
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_1
                     Output: hyper_1."time", hyper_1.device
                     Data node: data_node_1
                     Chunks: _dist_hyper_1_1_chunk, _dist_hyper_1_4_chunk, _dist_hyper_1_8_chunk, _dist_hyper_1_12_chunk, _dist_hyper_1_13_chunk, _dist_hyper_1_15_chunk, _dist_hyper_1_17_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) LIMIT 2000
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                     Output: hyper_2."time", hyper_2.device
                     Data node: data_node_2
                     Chunks: _dist_hyper_1_2_chunk, _dist_hyper_1_5_chunk, _dist_hyper_1_7_chunk, _dist_hyper_1_9_chunk, _dist_hyper_1_11_chunk, _dist_hyper_1_14_chunk, _dist_hyper_1_18_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) LIMIT 2000
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_3
                     Output: hyper_3."time", hyper_3.device
                     Data node: data_node_3
                     Chunks: _dist_hyper_1_3_chunk, _dist_hyper_1_6_chunk, _dist_hyper_1_10_chunk, _dist_hyper_1_16_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4]) LIMIT 2000
(20 rows)


######### LIMIT push down cases

EXPLAIN (verbose, costs off)
SELECT time, device
FROM hyper

LIMIT greatest(random(), 10.0)
                                                                                           QUERY PLAN                                                                                            
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit
   Output: hyper."time", hyper.device
   ->  Custom Scan (AsyncAppend)
         Output: hyper."time", hyper.device
         ->  Append
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_1
                     Output: hyper_1."time", hyper_1.device
                     Data node: data_node_1
                     Chunks: _dist_hyper_1_1_chunk, _dist_hyper_1_4_chunk, _dist_hyper_1_8_chunk, _dist_hyper_1_12_chunk, _dist_hyper_1_13_chunk, _dist_hyper_1_15_chunk, _dist_hyper_1_17_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7])
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                     Output: hyper_2."time", hyper_2.device
                     Data node: data_node_2
                     Chunks: _dist_hyper_1_2_chunk, _dist_hyper_1_5_chunk, _dist_hyper_1_7_chunk, _dist_hyper_1_9_chunk, _dist_hyper_1_11_chunk, _dist_hyper_1_14_chunk, _dist_hyper_1_18_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7])
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_3
                     Output: hyper_3."time", hyper_3.device
                     Data node: data_node_3
                     Chunks: _dist_hyper_1_3_chunk, _dist_hyper_1_6_chunk, _dist_hyper_1_10_chunk, _dist_hyper_1_16_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4])
(20 rows)


######### LIMIT push down cases

EXPLAIN (verbose, costs off)
SELECT time, device, avg(temp) OVER (PARTITION BY device)
FROM hyper

LIMIT 10
                                                                                              QUERY PLAN                                                                                               
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit
   Output: hyper."time", hyper.device, (avg(hyper.temp) OVER (?))
   ->  WindowAgg
         Output: hyper."time", hyper.device, avg(hyper.temp) OVER (?)
         ->  Custom Scan (AsyncAppend)
               Output: hyper.device, hyper."time", hyper.temp
               ->  Merge Append
                     Sort Key: hyper_1.device
                     ->  Custom Scan (DataNodeScan) on public.hyper hyper_1
                           Output: hyper_1.device, hyper_1."time", hyper_1.temp
                           Data node: data_node_1
                           Chunks: _dist_hyper_1_1_chunk, _dist_hyper_1_4_chunk, _dist_hyper_1_8_chunk, _dist_hyper_1_12_chunk, _dist_hyper_1_13_chunk, _dist_hyper_1_15_chunk, _dist_hyper_1_17_chunk
                           Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) ORDER BY device ASC NULLS LAST
                     ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                           Output: hyper_2.device, hyper_2."time", hyper_2.temp
                           Data node: data_node_2
                           Chunks: _dist_hyper_1_2_chunk, _dist_hyper_1_5_chunk, _dist_hyper_1_7_chunk, _dist_hyper_1_9_chunk, _dist_hyper_1_11_chunk, _dist_hyper_1_14_chunk, _dist_hyper_1_18_chunk
                           Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) ORDER BY device ASC NULLS LAST
                     ->  Custom Scan (DataNodeScan) on public.hyper hyper_3
                           Output: hyper_3.device, hyper_3."time", hyper_3.temp
                           Data node: data_node_3
                           Chunks: _dist_hyper_1_3_chunk, _dist_hyper_1_6_chunk, _dist_hyper_1_10_chunk, _dist_hyper_1_16_chunk
                           Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4]) ORDER BY device ASC NULLS LAST
(23 rows)


######### LIMIT push down cases

EXPLAIN (verbose, costs off)
SELECT DISTINCT device, time
FROM hyper

LIMIT 10
                                                                                                      QUERY PLAN                                                                                                       
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit
   Output: hyper.device, hyper."time"
   ->  Unique
         Output: hyper.device, hyper."time"
         ->  Custom Scan (AsyncAppend)
               Output: hyper.device, hyper."time"
               ->  Merge Append
                     Sort Key: hyper_1.device, hyper_1."time"
                     ->  Custom Scan (DataNodeScan) on public.hyper hyper_1
                           Output: hyper_1.device, hyper_1."time"
                           Data node: data_node_1
                           Chunks: _dist_hyper_1_1_chunk, _dist_hyper_1_4_chunk, _dist_hyper_1_8_chunk, _dist_hyper_1_12_chunk, _dist_hyper_1_13_chunk, _dist_hyper_1_15_chunk, _dist_hyper_1_17_chunk
                           Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) ORDER BY device ASC NULLS LAST, "time" ASC NULLS LAST
                     ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                           Output: hyper_2.device, hyper_2."time"
                           Data node: data_node_2
                           Chunks: _dist_hyper_1_2_chunk, _dist_hyper_1_5_chunk, _dist_hyper_1_7_chunk, _dist_hyper_1_9_chunk, _dist_hyper_1_11_chunk, _dist_hyper_1_14_chunk, _dist_hyper_1_18_chunk
                           Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) ORDER BY device ASC NULLS LAST, "time" ASC NULLS LAST
                     ->  Custom Scan (DataNodeScan) on public.hyper hyper_3
                           Output: hyper_3.device, hyper_3."time"
                           Data node: data_node_3
                           Chunks: _dist_hyper_1_3_chunk, _dist_hyper_1_6_chunk, _dist_hyper_1_10_chunk, _dist_hyper_1_16_chunk
                           Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4]) ORDER BY device ASC NULLS LAST, "time" ASC NULLS LAST
(23 rows)


######### LIMIT push down cases

EXPLAIN (verbose, costs off)
SELECT DISTINCT ON (device) device, time
FROM hyper

LIMIT 10
                                                                                              QUERY PLAN                                                                                               
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit
   Output: hyper.device, hyper."time"
   ->  Unique
         Output: hyper.device, hyper."time"
         ->  Custom Scan (AsyncAppend)
               Output: hyper.device, hyper."time"
               ->  Merge Append
                     Sort Key: hyper_1.device
                     ->  Custom Scan (DataNodeScan) on public.hyper hyper_1
                           Output: hyper_1.device, hyper_1."time"
                           Data node: data_node_1
                           Chunks: _dist_hyper_1_1_chunk, _dist_hyper_1_4_chunk, _dist_hyper_1_8_chunk, _dist_hyper_1_12_chunk, _dist_hyper_1_13_chunk, _dist_hyper_1_15_chunk, _dist_hyper_1_17_chunk
                           Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) ORDER BY device ASC NULLS LAST
                     ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                           Output: hyper_2.device, hyper_2."time"
                           Data node: data_node_2
                           Chunks: _dist_hyper_1_2_chunk, _dist_hyper_1_5_chunk, _dist_hyper_1_7_chunk, _dist_hyper_1_9_chunk, _dist_hyper_1_11_chunk, _dist_hyper_1_14_chunk, _dist_hyper_1_18_chunk
                           Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) ORDER BY device ASC NULLS LAST
                     ->  Custom Scan (DataNodeScan) on public.hyper hyper_3
                           Output: hyper_3.device, hyper_3."time"
                           Data node: data_node_3
                           Chunks: _dist_hyper_1_3_chunk, _dist_hyper_1_6_chunk, _dist_hyper_1_10_chunk, _dist_hyper_1_16_chunk
                           Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4]) ORDER BY device ASC NULLS LAST
(23 rows)


######### LIMIT push down cases

                                                                                              QUERY PLAN                                                                                               
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit
   Output: t."time"
   ->  Nested Loop
         Output: t."time"
         Join Filter: (t.device = join_test.device)
         ->  Custom Scan (AsyncAppend)
               Output: t."time", t.device
               ->  Append
                     ->  Custom Scan (DataNodeScan) on public.hyper t_1
                           Output: t_1."time", t_1.device
                           Data node: data_node_1
                           Chunks: _dist_hyper_1_1_chunk, _dist_hyper_1_4_chunk, _dist_hyper_1_8_chunk, _dist_hyper_1_12_chunk, _dist_hyper_1_13_chunk, _dist_hyper_1_15_chunk, _dist_hyper_1_17_chunk
                           Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7])
                     ->  Custom Scan (DataNodeScan) on public.hyper t_2
                           Output: t_2."time", t_2.device
                           Data node: data_node_2
                           Chunks: _dist_hyper_1_2_chunk, _dist_hyper_1_5_chunk, _dist_hyper_1_7_chunk, _dist_hyper_1_9_chunk, _dist_hyper_1_11_chunk, _dist_hyper_1_14_chunk, _dist_hyper_1_18_chunk
                           Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7])
                     ->  Custom Scan (DataNodeScan) on public.hyper t_3
                           Output: t_3."time", t_3.device
                           Data node: data_node_3
                           Chunks: _dist_hyper_1_3_chunk, _dist_hyper_1_6_chunk, _dist_hyper_1_10_chunk, _dist_hyper_1_16_chunk
                           Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4])
         ->  Materialize
               Output: join_test.device
               ->  Seq Scan on public.join_test
                     Output: join_test.device
(27 rows)

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% RUNNING TESTS on table: hyper
%%% PREFIX: EXPLAIN (verbose, costs off)
%%% WHERE_CLAUSE: :CLEAN_PARTITIONING_TIME_RANGE
%%% ORDER_BY_1: ORDER BY 1
%%% ORDER_BY_1_2: ORDER BY 1,2
%%% LIMIT: 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
 setseed 
---------
 
(1 row)


######### Grouping on time only (partial aggregation)

EXPLAIN (verbose, costs off)
SELECT time, avg(temp)
FROM hyper
WHERE time BETWEEN '2019-01-01' AND '2019-01-01 15:00'
GROUP BY 1
ORDER BY 1

                                                                                                                                                   QUERY PLAN                                                                                                                                                   
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 GroupAggregate
   Output: hyper."time", avg(hyper.temp)
   Group Key: hyper."time"
   ->  Custom Scan (AsyncAppend)
         Output: hyper."time", hyper.temp
         ->  Merge Append
               Sort Key: hyper_1."time"
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_1
                     Output: hyper_1."time", hyper_1.temp
                     Data node: data_node_1
                     Chunks: _dist_hyper_1_1_chunk
                     Remote SQL: SELECT "time", temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY "time" ASC NULLS LAST
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                     Output: hyper_2."time", hyper_2.temp
                     Data node: data_node_2
                     Chunks: _dist_hyper_1_2_chunk
                     Remote SQL: SELECT "time", temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY "time" ASC NULLS LAST
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_3
                     Output: hyper_3."time", hyper_3.temp
                     Data node: data_node_3
                     Chunks: _dist_hyper_1_3_chunk
                     Remote SQL: SELECT "time", temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY "time" ASC NULLS LAST
(22 rows)


######### Grouping on time only (partial aggregation)

EXPLAIN (verbose, costs off)
SELECT time_bucket('2 days', time) AS time, avg(temp)
FROM hyper
WHERE time BETWEEN '2019-01-01' AND '2019-01-01 15:00'
GROUP BY 1
ORDER BY 1

                                                                                                                                                                       QUERY PLAN                                                                                                                                                                       
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 GroupAggregate
   Output: (time_bucket('@ 2 days'::interval, hyper."time")), avg(hyper.temp)
   Group Key: (time_bucket('@ 2 days'::interval, hyper."time"))
   ->  Custom Scan (AsyncAppend)
         Output: (time_bucket('@ 2 days'::interval, hyper."time")), hyper.temp
         ->  Merge Append
               Sort Key: (time_bucket('@ 2 days'::interval, hyper_1."time"))
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_1
                     Output: time_bucket('@ 2 days'::interval, hyper_1."time"), hyper_1.temp
                     Data node: data_node_1
                     Chunks: _dist_hyper_1_1_chunk
                     Remote SQL: SELECT "time", temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY public.time_bucket('2 days'::interval, "time") ASC NULLS LAST
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                     Output: time_bucket('@ 2 days'::interval, hyper_2."time"), hyper_2.temp
                     Data node: data_node_2
                     Chunks: _dist_hyper_1_2_chunk
                     Remote SQL: SELECT "time", temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY public.time_bucket('2 days'::interval, "time") ASC NULLS LAST
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_3
                     Output: time_bucket('@ 2 days'::interval, hyper_3."time"), hyper_3.temp
                     Data node: data_node_3
                     Chunks: _dist_hyper_1_3_chunk
                     Remote SQL: SELECT "time", temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY public.time_bucket('2 days'::interval, "time") ASC NULLS LAST
(22 rows)


######### Grouping on time and device (full aggregation)

EXPLAIN (verbose, costs off)
SELECT time, device, avg(temp)
FROM hyper
WHERE time BETWEEN '2019-01-01' AND '2019-01-01 15:00'
GROUP BY 1,2
ORDER BY 1,2

                                                                                                                                                                         QUERY PLAN                                                                                                                                                                         
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Custom Scan (AsyncAppend)
   Output: "time", device, (avg(temp))
   ->  Merge Append
         Sort Key: hyper."time", hyper.device
         ->  Custom Scan (DataNodeScan)
               Output: hyper."time", hyper.device, (avg(hyper.temp))
               Relations: Aggregate on (public.hyper)
               Data node: data_node_1
               Chunks: _dist_hyper_1_1_chunk
               Remote SQL: SELECT "time", device, avg(temp) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) GROUP BY 1, 2 ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST
         ->  Custom Scan (DataNodeScan)
               Output: hyper_1."time", hyper_1.device, (avg(hyper_1.temp))
               Relations: Aggregate on (public.hyper)
               Data node: data_node_2
               Chunks: _dist_hyper_1_2_chunk
               Remote SQL: SELECT "time", device, avg(temp) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) GROUP BY 1, 2 ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST
         ->  GroupAggregate
               Output: hyper_2."time", hyper_2.device, avg(hyper_2.temp)
               Group Key: hyper_2."time", hyper_2.device
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                     Output: hyper_2."time", hyper_2.device, hyper_2.temp
                     Data node: data_node_3
                     Chunks: _dist_hyper_1_3_chunk
                     Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST
(24 rows)


######### Grouping on time and device (full aggregation)

EXPLAIN (verbose, costs off)
SELECT time_bucket('2 days', time) AS time, device, avg(temp)
FROM hyper
WHERE time BETWEEN '2019-01-01' AND '2019-01-01 15:00'
GROUP BY 1,2
ORDER BY 1,2

                                                                                                                                                                                                                  QUERY PLAN                                                                                                                                                                                                                  
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Custom Scan (AsyncAppend)
   Output: (time_bucket('@ 2 days'::interval, "time")), device, (avg(temp))
   ->  Merge Append
         Sort Key: (time_bucket('@ 2 days'::interval, hyper."time")), hyper.device
         ->  Custom Scan (DataNodeScan)
               Output: (time_bucket('@ 2 days'::interval, hyper."time")), hyper.device, (avg(hyper.temp))
               Relations: Aggregate on (public.hyper)
               Data node: data_node_1
               Chunks: _dist_hyper_1_1_chunk
               Remote SQL: SELECT public.time_bucket('@ 2 days'::interval, "time"), device, avg(temp) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) GROUP BY 1, 2 ORDER BY public.time_bucket('2 days'::interval, "time") ASC NULLS LAST, device ASC NULLS LAST
         ->  Custom Scan (DataNodeScan)
               Output: (time_bucket('@ 2 days'::interval, hyper_1."time")), hyper_1.device, (avg(hyper_1.temp))
               Relations: Aggregate on (public.hyper)
               Data node: data_node_2
               Chunks: _dist_hyper_1_2_chunk
               Remote SQL: SELECT public.time_bucket('@ 2 days'::interval, "time"), device, avg(temp) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) GROUP BY 1, 2 ORDER BY public.time_bucket('2 days'::interval, "time") ASC NULLS LAST, device ASC NULLS LAST
         ->  GroupAggregate
               Output: (time_bucket('@ 2 days'::interval, hyper_2."time")), hyper_2.device, avg(hyper_2.temp)
               Group Key: time_bucket('@ 2 days'::interval, hyper_2."time"), hyper_2.device
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                     Output: time_bucket('@ 2 days'::interval, hyper_2."time"), hyper_2.device, hyper_2.temp
                     Data node: data_node_3
                     Chunks: _dist_hyper_1_3_chunk
                     Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY public.time_bucket('2 days'::interval, "time") ASC NULLS LAST, device ASC NULLS LAST
(24 rows)


######### Grouping on time and device (full aggregation)

EXPLAIN (verbose, costs off)
SELECT date_trunc('month', time) AS time, device, avg(temp)
FROM hyper
WHERE time BETWEEN '2019-01-01' AND '2019-01-01 15:00'
GROUP BY 1,2
ORDER BY 1,2

                                                                                                                                                                                                    QUERY PLAN                                                                                                                                                                                                    
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Custom Scan (AsyncAppend)
   Output: (date_trunc('month'::text, "time")), device, (avg(temp))
   ->  Merge Append
         Sort Key: (date_trunc('month'::text, hyper."time")), hyper.device
         ->  Custom Scan (DataNodeScan)
               Output: (date_trunc('month'::text, hyper."time")), hyper.device, (avg(hyper.temp))
               Relations: Aggregate on (public.hyper)
               Data node: data_node_1
               Chunks: _dist_hyper_1_1_chunk
               Remote SQL: SELECT date_trunc('month'::text, "time"), device, avg(temp) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) GROUP BY 1, 2 ORDER BY date_trunc('month'::text, "time") ASC NULLS LAST, device ASC NULLS LAST
         ->  Custom Scan (DataNodeScan)
               Output: (date_trunc('month'::text, hyper_1."time")), hyper_1.device, (avg(hyper_1.temp))
               Relations: Aggregate on (public.hyper)
               Data node: data_node_2
               Chunks: _dist_hyper_1_2_chunk
               Remote SQL: SELECT date_trunc('month'::text, "time"), device, avg(temp) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) GROUP BY 1, 2 ORDER BY date_trunc('month'::text, "time") ASC NULLS LAST, device ASC NULLS LAST
         ->  GroupAggregate
               Output: (date_trunc('month'::text, hyper_2."time")), hyper_2.device, avg(hyper_2.temp)
               Group Key: date_trunc('month'::text, hyper_2."time"), hyper_2.device
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                     Output: date_trunc('month'::text, hyper_2."time"), hyper_2.device, hyper_2.temp
                     Data node: data_node_3
                     Chunks: _dist_hyper_1_3_chunk
                     Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY date_trunc('month'::text, "time") ASC NULLS LAST, device ASC NULLS LAST
(24 rows)


######### Grouping on time and device (full aggregation)

EXPLAIN (verbose, costs off)
SELECT time_bucket('2 days', time) AS time, device, avg(temp)
FROM hyper
WHERE time BETWEEN '2019-01-01' AND '2019-01-01 15:00'
GROUP BY 1,2
HAVING device > 4
ORDER BY 1,2

                                                                                                                                                                                                QUERY PLAN                                                                                                                                                                                                
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 GroupAggregate
   Output: (time_bucket('@ 2 days'::interval, hyper."time")), hyper.device, avg(hyper.temp)
   Group Key: (time_bucket('@ 2 days'::interval, hyper."time")), hyper.device
   ->  Custom Scan (AsyncAppend)
         Output: (time_bucket('@ 2 days'::interval, hyper."time")), hyper.device, hyper.temp
         ->  Merge Append
               Sort Key: (time_bucket('@ 2 days'::interval, hyper_1."time")), hyper_1.device
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_1
                     Output: time_bucket('@ 2 days'::interval, hyper_1."time"), hyper_1.device, hyper_1.temp
                     Data node: data_node_1
                     Chunks: _dist_hyper_1_1_chunk
                     Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) AND ((device > 4)) ORDER BY public.time_bucket('2 days'::interval, "time") ASC NULLS LAST, device ASC NULLS LAST
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                     Output: time_bucket('@ 2 days'::interval, hyper_2."time"), hyper_2.device, hyper_2.temp
                     Data node: data_node_2
                     Chunks: _dist_hyper_1_2_chunk
                     Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) AND ((device > 4)) ORDER BY public.time_bucket('2 days'::interval, "time") ASC NULLS LAST, device ASC NULLS LAST
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_3
                     Output: time_bucket('@ 2 days'::interval, hyper_3."time"), hyper_3.device, hyper_3.temp
                     Data node: data_node_3
                     Chunks: _dist_hyper_1_3_chunk
                     Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) AND ((device > 4)) ORDER BY public.time_bucket('2 days'::interval, "time") ASC NULLS LAST, device ASC NULLS LAST
(22 rows)

EXPLAIN (verbose, costs off)
SELECT time_bucket('2 days', time) AS time, device, avg(temp)
FROM hyper
WHERE time BETWEEN '2019-01-01' AND '2019-01-01 15:00'
GROUP BY 1,2
HAVING avg(temp) > 40 AND max(temp) < 70
ORDER BY 1,2

                                                                                                                                                                                                                                                            QUERY PLAN                                                                                                                                                                                                                                                             
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Custom Scan (AsyncAppend)
   Output: (time_bucket('@ 2 days'::interval, "time")), device, (avg(temp))
   ->  Merge Append
         Sort Key: (time_bucket('@ 2 days'::interval, hyper."time")), hyper.device
         ->  Custom Scan (DataNodeScan)
               Output: (time_bucket('@ 2 days'::interval, hyper."time")), hyper.device, (avg(hyper.temp))
               Relations: Aggregate on (public.hyper)
               Data node: data_node_1
               Chunks: _dist_hyper_1_1_chunk
               Remote SQL: SELECT public.time_bucket('@ 2 days'::interval, "time"), device, avg(temp) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) GROUP BY 1, 2 HAVING ((avg(temp) > 40::double precision)) AND ((max(temp) < 70::double precision)) ORDER BY public.time_bucket('2 days'::interval, "time") ASC NULLS LAST, device ASC NULLS LAST
         ->  Custom Scan (DataNodeScan)
               Output: (time_bucket('@ 2 days'::interval, hyper_1."time")), hyper_1.device, (avg(hyper_1.temp))
               Relations: Aggregate on (public.hyper)
               Data node: data_node_2
               Chunks: _dist_hyper_1_2_chunk
               Remote SQL: SELECT public.time_bucket('@ 2 days'::interval, "time"), device, avg(temp) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) GROUP BY 1, 2 HAVING ((avg(temp) > 40::double precision)) AND ((max(temp) < 70::double precision)) ORDER BY public.time_bucket('2 days'::interval, "time") ASC NULLS LAST, device ASC NULLS LAST
         ->  GroupAggregate
               Output: (time_bucket('@ 2 days'::interval, hyper_2."time")), hyper_2.device, avg(hyper_2.temp)
               Group Key: time_bucket('@ 2 days'::interval, hyper_2."time"), hyper_2.device
               Filter: ((avg(hyper_2.temp) > '40'::double precision) AND (max(hyper_2.temp) < '70'::double precision))
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                     Output: time_bucket('@ 2 days'::interval, hyper_2."time"), hyper_2.device, hyper_2.temp
                     Data node: data_node_3
                     Chunks: _dist_hyper_1_3_chunk
                     Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY public.time_bucket('2 days'::interval, "time") ASC NULLS LAST, device ASC NULLS LAST
(25 rows)


######### Grouping on device only (full aggregation)

EXPLAIN (verbose, costs off)
SELECT device, avg(temp)
FROM hyper
WHERE time BETWEEN '2019-01-01' AND '2019-01-01 15:00'
GROUP BY 1
ORDER BY 1

                                                                                                                                                        QUERY PLAN                                                                                                                                                        
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Custom Scan (AsyncAppend)
   Output: device, (avg(temp))
   ->  Merge Append
         Sort Key: hyper.device
         ->  Custom Scan (DataNodeScan)
               Output: hyper.device, (avg(hyper.temp))
               Relations: Aggregate on (public.hyper)
               Data node: data_node_1
               Chunks: _dist_hyper_1_1_chunk
               Remote SQL: SELECT device, avg(temp) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) GROUP BY 1 ORDER BY device ASC NULLS LAST
         ->  Custom Scan (DataNodeScan)
               Output: hyper_1.device, (avg(hyper_1.temp))
               Relations: Aggregate on (public.hyper)
               Data node: data_node_2
               Chunks: _dist_hyper_1_2_chunk
               Remote SQL: SELECT device, avg(temp) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) GROUP BY 1 ORDER BY device ASC NULLS LAST
         ->  GroupAggregate
               Output: hyper_2.device, avg(hyper_2.temp)
               Group Key: hyper_2.device
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                     Output: hyper_2.device, hyper_2.temp
                     Data node: data_node_3
                     Chunks: _dist_hyper_1_3_chunk
                     Remote SQL: SELECT device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY device ASC NULLS LAST
(24 rows)


######### No push down on some functions

EXPLAIN (verbose, costs off)
SELECT location, avg(temp)
FROM hyper
WHERE time BETWEEN '2019-01-01' AND '2019-01-01 15:00' AND (temp * random() >= 0)
GROUP BY 1
ORDER BY 1

                                                                                                                                                     QUERY PLAN                                                                                                                                                     
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 GroupAggregate
   Output: hyper.location, avg(hyper.temp)
   Group Key: hyper.location
   ->  Custom Scan (AsyncAppend)
         Output: hyper.location, hyper.temp
         ->  Merge Append
               Sort Key: hyper_1.location
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_1
                     Output: hyper_1.location, hyper_1.temp
                     Filter: ((hyper_1.temp * random()) >= '0'::double precision)
                     Data node: data_node_1
                     Chunks: _dist_hyper_1_1_chunk
                     Remote SQL: SELECT location, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY location ASC NULLS LAST
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                     Output: hyper_2.location, hyper_2.temp
                     Filter: ((hyper_2.temp * random()) >= '0'::double precision)
                     Data node: data_node_2
                     Chunks: _dist_hyper_1_2_chunk
                     Remote SQL: SELECT location, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY location ASC NULLS LAST
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_3
                     Output: hyper_3.location, hyper_3.temp
                     Filter: ((hyper_3.temp * random()) >= '0'::double precision)
                     Data node: data_node_3
                     Chunks: _dist_hyper_1_3_chunk
                     Remote SQL: SELECT location, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY location ASC NULLS LAST
(25 rows)


######### No push down on some functions

EXPLAIN (verbose, costs off)
SELECT time_bucket('2 days', time) AS time, device, avg(temp), sum(temp * (random() <= 1)::int) as sum
FROM hyper
WHERE time BETWEEN '2019-01-01' AND '2019-01-01 15:00'
GROUP BY 1,2
ORDER BY 1,2

                                                                                                                                                                                      QUERY PLAN                                                                                                                                                                                       
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 GroupAggregate
   Output: (time_bucket('@ 2 days'::interval, hyper."time")), hyper.device, avg(hyper.temp), sum((hyper.temp * (((random() <= '1'::double precision))::integer)::double precision))
   Group Key: (time_bucket('@ 2 days'::interval, hyper."time")), hyper.device
   ->  Custom Scan (AsyncAppend)
         Output: (time_bucket('@ 2 days'::interval, hyper."time")), hyper.device, hyper.temp
         ->  Merge Append
               Sort Key: (time_bucket('@ 2 days'::interval, hyper_1."time")), hyper_1.device
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_1
                     Output: time_bucket('@ 2 days'::interval, hyper_1."time"), hyper_1.device, hyper_1.temp
                     Data node: data_node_1
                     Chunks: _dist_hyper_1_1_chunk
                     Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY public.time_bucket('2 days'::interval, "time") ASC NULLS LAST, device ASC NULLS LAST
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                     Output: time_bucket('@ 2 days'::interval, hyper_2."time"), hyper_2.device, hyper_2.temp
                     Data node: data_node_2
                     Chunks: _dist_hyper_1_2_chunk
                     Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY public.time_bucket('2 days'::interval, "time") ASC NULLS LAST, device ASC NULLS LAST
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_3
                     Output: time_bucket('@ 2 days'::interval, hyper_3."time"), hyper_3.device, hyper_3.temp
                     Data node: data_node_3
                     Chunks: _dist_hyper_1_3_chunk
                     Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY public.time_bucket('2 days'::interval, "time") ASC NULLS LAST, device ASC NULLS LAST
(22 rows)


######### No push down on some functions

EXPLAIN (verbose, costs off)
SELECT time, device, avg(temp)
FROM hyper
WHERE time BETWEEN '2019-01-01' AND '2019-01-01 15:00'
GROUP BY 1,2
HAVING avg(temp) * custom_sum(device) > 0.8
ORDER BY 1,2

                                                                                                                                                                     QUERY PLAN                                                                                                                                                                      
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Sort
   Output: hyper."time", hyper.device, (avg(hyper.temp))
   Sort Key: hyper."time", hyper.device
   ->  HashAggregate
         Output: hyper."time", hyper.device, avg(hyper.temp)
         Group Key: hyper."time", hyper.device
         Filter: ((avg(hyper.temp) * (custom_sum(hyper.device))::double precision) > '0.8'::double precision)
         ->  Custom Scan (AsyncAppend)
               Output: hyper."time", hyper.device, hyper.temp
               ->  Append
                     ->  Custom Scan (DataNodeScan) on public.hyper hyper_1
                           Output: hyper_1."time", hyper_1.device, hyper_1.temp
                           Data node: data_node_1
                           Chunks: _dist_hyper_1_1_chunk
                           Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST
                     ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                           Output: hyper_2."time", hyper_2.device, hyper_2.temp
                           Data node: data_node_2
                           Chunks: _dist_hyper_1_2_chunk
                           Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST
                     ->  Custom Scan (DataNodeScan) on public.hyper hyper_3
                           Output: hyper_3."time", hyper_3.device, hyper_3.temp
                           Data node: data_node_3
                           Chunks: _dist_hyper_1_3_chunk
                           Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST
(25 rows)


######### No push down on some functions

EXPLAIN (verbose, costs off)
SELECT time, device, avg(temp), custom_sum(device)
FROM hyper
WHERE time BETWEEN '2019-01-01' AND '2019-01-01 15:00'
GROUP BY 1,2
ORDER BY 1,2

                                                                                                                                                                  QUERY PLAN                                                                                                                                                                   
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 GroupAggregate
   Output: hyper."time", hyper.device, avg(hyper.temp), custom_sum(hyper.device)
   Group Key: hyper."time", hyper.device
   ->  Custom Scan (AsyncAppend)
         Output: hyper."time", hyper.device, hyper.temp
         ->  Merge Append
               Sort Key: hyper_1."time", hyper_1.device
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_1
                     Output: hyper_1."time", hyper_1.device, hyper_1.temp
                     Data node: data_node_1
                     Chunks: _dist_hyper_1_1_chunk
                     Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                     Output: hyper_2."time", hyper_2.device, hyper_2.temp
                     Data node: data_node_2
                     Chunks: _dist_hyper_1_2_chunk
                     Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_3
                     Output: hyper_3."time", hyper_3.device, hyper_3.temp
                     Data node: data_node_3
                     Chunks: _dist_hyper_1_3_chunk
                     Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST
(22 rows)


######### Constification and runtime push down of time-related functions

 tsl_override_current_timestamptz 
----------------------------------
 
(1 row)

                                                                                                                                                                         QUERY PLAN                                                                                                                                                                         
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Custom Scan (AsyncAppend)
   Output: "time", device, (avg(temp))
   ->  Merge Append
         Sort Key: hyper."time", hyper.device
         ->  Custom Scan (DataNodeScan)
               Output: hyper."time", hyper.device, (avg(hyper.temp))
               Relations: Aggregate on (public.hyper)
               Data node: data_node_1
               Chunks: _dist_hyper_1_1_chunk
               Remote SQL: SELECT "time", device, avg(temp) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) GROUP BY 1, 2 ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST
         ->  Custom Scan (DataNodeScan)
               Output: hyper_1."time", hyper_1.device, (avg(hyper_1.temp))
               Relations: Aggregate on (public.hyper)
               Data node: data_node_2
               Chunks: _dist_hyper_1_2_chunk
               Remote SQL: SELECT "time", device, avg(temp) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) GROUP BY 1, 2 ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST
         ->  GroupAggregate
               Output: hyper_2."time", hyper_2.device, avg(hyper_2.temp)
               Group Key: hyper_2."time", hyper_2.device
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                     Output: hyper_2."time", hyper_2.device, hyper_2.temp
                     Data node: data_node_3
                     Chunks: _dist_hyper_1_3_chunk
                     Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST
(24 rows)

                                                                                                                                                                         QUERY PLAN                                                                                                                                                                         
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Custom Scan (AsyncAppend)
   Output: "time", device, (avg(temp))
   ->  Merge Append
         Sort Key: hyper."time", hyper.device
         ->  Custom Scan (DataNodeScan)
               Output: hyper."time", hyper.device, (avg(hyper.temp))
               Relations: Aggregate on (public.hyper)
               Data node: data_node_1
               Chunks: _dist_hyper_1_1_chunk
               Remote SQL: SELECT "time", device, avg(temp) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) GROUP BY 1, 2 ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST
         ->  Custom Scan (DataNodeScan)
               Output: hyper_1."time", hyper_1.device, (avg(hyper_1.temp))
               Relations: Aggregate on (public.hyper)
               Data node: data_node_2
               Chunks: _dist_hyper_1_2_chunk
               Remote SQL: SELECT "time", device, avg(temp) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) GROUP BY 1, 2 ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST
         ->  GroupAggregate
               Output: hyper_2."time", hyper_2.device, avg(hyper_2.temp)
               Group Key: hyper_2."time", hyper_2.device
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                     Output: hyper_2."time", hyper_2.device, hyper_2.temp
                     Data node: data_node_3
                     Chunks: _dist_hyper_1_3_chunk
                     Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST
(24 rows)

 tsl_override_current_timestamptz 
----------------------------------
 
(1 row)

                                                                                                                                                                         QUERY PLAN                                                                                                                                                                         
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Custom Scan (AsyncAppend)
   Output: "time", device, (avg(temp))
   ->  Merge Append
         Sort Key: hyper."time", hyper.device
         ->  Custom Scan (DataNodeScan)
               Output: hyper."time", hyper.device, (avg(hyper.temp))
               Relations: Aggregate on (public.hyper)
               Data node: data_node_1
               Chunks: _dist_hyper_1_1_chunk
               Remote SQL: SELECT "time", device, avg(temp) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) GROUP BY 1, 2 ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST
         ->  Custom Scan (DataNodeScan)
               Output: hyper_1."time", hyper_1.device, (avg(hyper_1.temp))
               Relations: Aggregate on (public.hyper)
               Data node: data_node_2
               Chunks: _dist_hyper_1_2_chunk
               Remote SQL: SELECT "time", device, avg(temp) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) GROUP BY 1, 2 ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST
         ->  GroupAggregate
               Output: hyper_2."time", hyper_2.device, avg(hyper_2.temp)
               Group Key: hyper_2."time", hyper_2.device
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                     Output: hyper_2."time", hyper_2.device, hyper_2.temp
                     Data node: data_node_3
                     Chunks: _dist_hyper_1_3_chunk
                     Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST
(24 rows)


######### LIMIT push down cases

EXPLAIN (verbose, costs off)
SELECT time, device
FROM hyper
ORDER BY 1,2
LIMIT 10
                                                                                                        QUERY PLAN                                                                                                        
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit
   Output: hyper."time", hyper.device
   ->  Custom Scan (AsyncAppend)
         Output: hyper."time", hyper.device
         ->  Merge Append
               Sort Key: hyper_1."time", hyper_1.device
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_1
                     Output: hyper_1."time", hyper_1.device
                     Data node: data_node_1
                     Chunks: _dist_hyper_1_1_chunk, _dist_hyper_1_4_chunk, _dist_hyper_1_8_chunk, _dist_hyper_1_12_chunk, _dist_hyper_1_13_chunk, _dist_hyper_1_15_chunk, _dist_hyper_1_17_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST LIMIT 10
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                     Output: hyper_2."time", hyper_2.device
                     Data node: data_node_2
                     Chunks: _dist_hyper_1_2_chunk, _dist_hyper_1_5_chunk, _dist_hyper_1_7_chunk, _dist_hyper_1_9_chunk, _dist_hyper_1_11_chunk, _dist_hyper_1_14_chunk, _dist_hyper_1_18_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST LIMIT 10
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_3
                     Output: hyper_3."time", hyper_3.device
                     Data node: data_node_3
                     Chunks: _dist_hyper_1_3_chunk, _dist_hyper_1_6_chunk, _dist_hyper_1_10_chunk, _dist_hyper_1_16_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4]) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST LIMIT 10
(21 rows)


######### LIMIT push down cases

EXPLAIN (verbose, costs off)
SELECT time, device
FROM hyper
ORDER BY 1,2
LIMIT 5
OFFSET 5
                                                                                                        QUERY PLAN                                                                                                        
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit
   Output: hyper."time", hyper.device
   ->  Custom Scan (AsyncAppend)
         Output: hyper."time", hyper.device
         ->  Merge Append
               Sort Key: hyper_1."time", hyper_1.device
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_1
                     Output: hyper_1."time", hyper_1.device
                     Data node: data_node_1
                     Chunks: _dist_hyper_1_1_chunk, _dist_hyper_1_4_chunk, _dist_hyper_1_8_chunk, _dist_hyper_1_12_chunk, _dist_hyper_1_13_chunk, _dist_hyper_1_15_chunk, _dist_hyper_1_17_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST LIMIT 10
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                     Output: hyper_2."time", hyper_2.device
                     Data node: data_node_2
                     Chunks: _dist_hyper_1_2_chunk, _dist_hyper_1_5_chunk, _dist_hyper_1_7_chunk, _dist_hyper_1_9_chunk, _dist_hyper_1_11_chunk, _dist_hyper_1_14_chunk, _dist_hyper_1_18_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST LIMIT 10
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_3
                     Output: hyper_3."time", hyper_3.device
                     Data node: data_node_3
                     Chunks: _dist_hyper_1_3_chunk, _dist_hyper_1_6_chunk, _dist_hyper_1_10_chunk, _dist_hyper_1_16_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4]) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST LIMIT 10
(21 rows)


######### LIMIT push down cases

EXPLAIN (verbose, costs off)
SELECT time, device
FROM hyper
ORDER BY 1,2
LIMIT 0
                                                                                                       QUERY PLAN                                                                                                        
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit
   Output: hyper."time", hyper.device
   ->  Custom Scan (AsyncAppend)
         Output: hyper."time", hyper.device
         ->  Merge Append
               Sort Key: hyper_1."time", hyper_1.device
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_1
                     Output: hyper_1."time", hyper_1.device
                     Data node: data_node_1
                     Chunks: _dist_hyper_1_1_chunk, _dist_hyper_1_4_chunk, _dist_hyper_1_8_chunk, _dist_hyper_1_12_chunk, _dist_hyper_1_13_chunk, _dist_hyper_1_15_chunk, _dist_hyper_1_17_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST LIMIT 1
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                     Output: hyper_2."time", hyper_2.device
                     Data node: data_node_2
                     Chunks: _dist_hyper_1_2_chunk, _dist_hyper_1_5_chunk, _dist_hyper_1_7_chunk, _dist_hyper_1_9_chunk, _dist_hyper_1_11_chunk, _dist_hyper_1_14_chunk, _dist_hyper_1_18_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST LIMIT 1
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_3
                     Output: hyper_3."time", hyper_3.device
                     Data node: data_node_3
                     Chunks: _dist_hyper_1_3_chunk, _dist_hyper_1_6_chunk, _dist_hyper_1_10_chunk, _dist_hyper_1_16_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4]) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST LIMIT 1
(21 rows)


######### LIMIT push down cases

EXPLAIN (verbose, costs off)
SELECT time, device
FROM hyper
ORDER BY 1,2
LIMIT extract(year from date '2000-01-01')
                                                                                                         QUERY PLAN                                                                                                         
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit
   Output: hyper."time", hyper.device
   ->  Custom Scan (AsyncAppend)
         Output: hyper."time", hyper.device
         ->  Merge Append
               Sort Key: hyper_1."time", hyper_1.device
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_1
                     Output: hyper_1."time", hyper_1.device
                     Data node: data_node_1
                     Chunks: _dist_hyper_1_1_chunk, _dist_hyper_1_4_chunk, _dist_hyper_1_8_chunk, _dist_hyper_1_12_chunk, _dist_hyper_1_13_chunk, _dist_hyper_1_15_chunk, _dist_hyper_1_17_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST LIMIT 2000
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                     Output: hyper_2."time", hyper_2.device
                     Data node: data_node_2
                     Chunks: _dist_hyper_1_2_chunk, _dist_hyper_1_5_chunk, _dist_hyper_1_7_chunk, _dist_hyper_1_9_chunk, _dist_hyper_1_11_chunk, _dist_hyper_1_14_chunk, _dist_hyper_1_18_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST LIMIT 2000
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_3
                     Output: hyper_3."time", hyper_3.device
                     Data node: data_node_3
                     Chunks: _dist_hyper_1_3_chunk, _dist_hyper_1_6_chunk, _dist_hyper_1_10_chunk, _dist_hyper_1_16_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4]) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST LIMIT 2000
(21 rows)


######### LIMIT push down cases

EXPLAIN (verbose, costs off)
SELECT time, device
FROM hyper
ORDER BY 1,2
LIMIT greatest(random(), 10.0)
                                                                                                   QUERY PLAN                                                                                                    
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit
   Output: hyper."time", hyper.device
   ->  Custom Scan (AsyncAppend)
         Output: hyper."time", hyper.device
         ->  Merge Append
               Sort Key: hyper_1."time", hyper_1.device
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_1
                     Output: hyper_1."time", hyper_1.device
                     Data node: data_node_1
                     Chunks: _dist_hyper_1_1_chunk, _dist_hyper_1_4_chunk, _dist_hyper_1_8_chunk, _dist_hyper_1_12_chunk, _dist_hyper_1_13_chunk, _dist_hyper_1_15_chunk, _dist_hyper_1_17_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                     Output: hyper_2."time", hyper_2.device
                     Data node: data_node_2
                     Chunks: _dist_hyper_1_2_chunk, _dist_hyper_1_5_chunk, _dist_hyper_1_7_chunk, _dist_hyper_1_9_chunk, _dist_hyper_1_11_chunk, _dist_hyper_1_14_chunk, _dist_hyper_1_18_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_3
                     Output: hyper_3."time", hyper_3.device
                     Data node: data_node_3
                     Chunks: _dist_hyper_1_3_chunk, _dist_hyper_1_6_chunk, _dist_hyper_1_10_chunk, _dist_hyper_1_16_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4]) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST
(21 rows)


######### LIMIT push down cases

EXPLAIN (verbose, costs off)
SELECT time, device, avg(temp) OVER (PARTITION BY device)
FROM hyper
ORDER BY 1,2
LIMIT 10
                                                                                                 QUERY PLAN                                                                                                  
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit
   Output: hyper."time", hyper.device, (avg(hyper.temp) OVER (?))
   ->  Sort
         Output: hyper."time", hyper.device, (avg(hyper.temp) OVER (?))
         Sort Key: hyper."time", hyper.device
         ->  WindowAgg
               Output: hyper."time", hyper.device, avg(hyper.temp) OVER (?)
               ->  Custom Scan (AsyncAppend)
                     Output: hyper.device, hyper."time", hyper.temp
                     ->  Merge Append
                           Sort Key: hyper_1.device
                           ->  Custom Scan (DataNodeScan) on public.hyper hyper_1
                                 Output: hyper_1.device, hyper_1."time", hyper_1.temp
                                 Data node: data_node_1
                                 Chunks: _dist_hyper_1_1_chunk, _dist_hyper_1_4_chunk, _dist_hyper_1_8_chunk, _dist_hyper_1_12_chunk, _dist_hyper_1_13_chunk, _dist_hyper_1_15_chunk, _dist_hyper_1_17_chunk
                                 Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) ORDER BY device ASC NULLS LAST
                           ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                                 Output: hyper_2.device, hyper_2."time", hyper_2.temp
                                 Data node: data_node_2
                                 Chunks: _dist_hyper_1_2_chunk, _dist_hyper_1_5_chunk, _dist_hyper_1_7_chunk, _dist_hyper_1_9_chunk, _dist_hyper_1_11_chunk, _dist_hyper_1_14_chunk, _dist_hyper_1_18_chunk
                                 Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) ORDER BY device ASC NULLS LAST
                           ->  Custom Scan (DataNodeScan) on public.hyper hyper_3
                                 Output: hyper_3.device, hyper_3."time", hyper_3.temp
                                 Data node: data_node_3
                                 Chunks: _dist_hyper_1_3_chunk, _dist_hyper_1_6_chunk, _dist_hyper_1_10_chunk, _dist_hyper_1_16_chunk
                                 Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4]) ORDER BY device ASC NULLS LAST
(26 rows)


######### LIMIT push down cases

EXPLAIN (verbose, costs off)
SELECT DISTINCT device, time
FROM hyper
ORDER BY 1,2
LIMIT 10
                                                                                                      QUERY PLAN                                                                                                       
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit
   Output: hyper.device, hyper."time"
   ->  Unique
         Output: hyper.device, hyper."time"
         ->  Custom Scan (AsyncAppend)
               Output: hyper.device, hyper."time"
               ->  Merge Append
                     Sort Key: hyper_1.device, hyper_1."time"
                     ->  Custom Scan (DataNodeScan) on public.hyper hyper_1
                           Output: hyper_1.device, hyper_1."time"
                           Data node: data_node_1
                           Chunks: _dist_hyper_1_1_chunk, _dist_hyper_1_4_chunk, _dist_hyper_1_8_chunk, _dist_hyper_1_12_chunk, _dist_hyper_1_13_chunk, _dist_hyper_1_15_chunk, _dist_hyper_1_17_chunk
                           Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) ORDER BY device ASC NULLS LAST, "time" ASC NULLS LAST
                     ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                           Output: hyper_2.device, hyper_2."time"
                           Data node: data_node_2
                           Chunks: _dist_hyper_1_2_chunk, _dist_hyper_1_5_chunk, _dist_hyper_1_7_chunk, _dist_hyper_1_9_chunk, _dist_hyper_1_11_chunk, _dist_hyper_1_14_chunk, _dist_hyper_1_18_chunk
                           Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) ORDER BY device ASC NULLS LAST, "time" ASC NULLS LAST
                     ->  Custom Scan (DataNodeScan) on public.hyper hyper_3
                           Output: hyper_3.device, hyper_3."time"
                           Data node: data_node_3
                           Chunks: _dist_hyper_1_3_chunk, _dist_hyper_1_6_chunk, _dist_hyper_1_10_chunk, _dist_hyper_1_16_chunk
                           Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4]) ORDER BY device ASC NULLS LAST, "time" ASC NULLS LAST
(23 rows)


######### LIMIT push down cases

EXPLAIN (verbose, costs off)
SELECT DISTINCT ON (device) device, time
FROM hyper
ORDER BY 1,2
LIMIT 10
                                                                                                      QUERY PLAN                                                                                                       
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit
   Output: hyper.device, hyper."time"
   ->  Unique
         Output: hyper.device, hyper."time"
         ->  Custom Scan (AsyncAppend)
               Output: hyper.device, hyper."time"
               ->  Merge Append
                     Sort Key: hyper_1.device, hyper_1."time"
                     ->  Custom Scan (DataNodeScan) on public.hyper hyper_1
                           Output: hyper_1.device, hyper_1."time"
                           Data node: data_node_1
                           Chunks: _dist_hyper_1_1_chunk, _dist_hyper_1_4_chunk, _dist_hyper_1_8_chunk, _dist_hyper_1_12_chunk, _dist_hyper_1_13_chunk, _dist_hyper_1_15_chunk, _dist_hyper_1_17_chunk
                           Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) ORDER BY device ASC NULLS LAST, "time" ASC NULLS LAST
                     ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                           Output: hyper_2.device, hyper_2."time"
                           Data node: data_node_2
                           Chunks: _dist_hyper_1_2_chunk, _dist_hyper_1_5_chunk, _dist_hyper_1_7_chunk, _dist_hyper_1_9_chunk, _dist_hyper_1_11_chunk, _dist_hyper_1_14_chunk, _dist_hyper_1_18_chunk
                           Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) ORDER BY device ASC NULLS LAST, "time" ASC NULLS LAST
                     ->  Custom Scan (DataNodeScan) on public.hyper hyper_3
                           Output: hyper_3.device, hyper_3."time"
                           Data node: data_node_3
                           Chunks: _dist_hyper_1_3_chunk, _dist_hyper_1_6_chunk, _dist_hyper_1_10_chunk, _dist_hyper_1_16_chunk
                           Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4]) ORDER BY device ASC NULLS LAST, "time" ASC NULLS LAST
(23 rows)


######### LIMIT push down cases

                                                                                              QUERY PLAN                                                                                               
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit
   Output: t."time"
   ->  Nested Loop
         Output: t."time"
         Join Filter: (t.device = join_test.device)
         ->  Custom Scan (AsyncAppend)
               Output: t."time", t.device
               ->  Append
                     ->  Custom Scan (DataNodeScan) on public.hyper t_1
                           Output: t_1."time", t_1.device
                           Data node: data_node_1
                           Chunks: _dist_hyper_1_1_chunk, _dist_hyper_1_4_chunk, _dist_hyper_1_8_chunk, _dist_hyper_1_12_chunk, _dist_hyper_1_13_chunk, _dist_hyper_1_15_chunk, _dist_hyper_1_17_chunk
                           Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7])
                     ->  Custom Scan (DataNodeScan) on public.hyper t_2
                           Output: t_2."time", t_2.device
                           Data node: data_node_2
                           Chunks: _dist_hyper_1_2_chunk, _dist_hyper_1_5_chunk, _dist_hyper_1_7_chunk, _dist_hyper_1_9_chunk, _dist_hyper_1_11_chunk, _dist_hyper_1_14_chunk, _dist_hyper_1_18_chunk
                           Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7])
                     ->  Custom Scan (DataNodeScan) on public.hyper t_3
                           Output: t_3."time", t_3.device
                           Data node: data_node_3
                           Chunks: _dist_hyper_1_3_chunk, _dist_hyper_1_6_chunk, _dist_hyper_1_10_chunk, _dist_hyper_1_16_chunk
                           Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4])
         ->  Materialize
               Output: join_test.device
               ->  Seq Scan on public.join_test
                     Output: join_test.device
(27 rows)

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% RUNNING TESTS on table: hyper
%%% PREFIX: EXPLAIN (verbose, costs off)
%%% WHERE_CLAUSE: :CLEAN_PARTITIONING_TIME_RANGE AND device = 1
%%% ORDER_BY_1: ORDER BY 1
%%% ORDER_BY_1_2: ORDER BY 1,2
%%% LIMIT: 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
 setseed 
---------
 
(1 row)


######### Grouping on time only (partial aggregation)

EXPLAIN (verbose, costs off)
SELECT time, avg(temp)
FROM hyper
WHERE time BETWEEN '2019-01-01' AND '2019-01-01 15:00' AND device = 1
GROUP BY 1
ORDER BY 1

                                                                                                                                                           QUERY PLAN                                                                                                                                                            
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Custom Scan (DataNodeScan)
   Output: hyper."time", (avg(hyper.temp))
   Relations: Aggregate on (public.hyper)
   Data node: data_node_1
   Chunks: _dist_hyper_1_1_chunk
   Remote SQL: SELECT "time", avg(temp) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) AND ((device = 1)) GROUP BY 1 ORDER BY "time" ASC NULLS LAST
(6 rows)


######### Grouping on time only (partial aggregation)

EXPLAIN (verbose, costs off)
SELECT time_bucket('2 days', time) AS time, avg(temp)
FROM hyper
WHERE time BETWEEN '2019-01-01' AND '2019-01-01 15:00' AND device = 1
GROUP BY 1
ORDER BY 1

                                                                                                                                                                                                    QUERY PLAN                                                                                                                                                                                                     
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Custom Scan (DataNodeScan)
   Output: (time_bucket('@ 2 days'::interval, hyper."time")), (avg(hyper.temp))
   Relations: Aggregate on (public.hyper)
   Data node: data_node_1
   Chunks: _dist_hyper_1_1_chunk
   Remote SQL: SELECT public.time_bucket('@ 2 days'::interval, "time"), avg(temp) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) AND ((device = 1)) GROUP BY 1 ORDER BY public.time_bucket('2 days'::interval, "time") ASC NULLS LAST
(6 rows)


######### Grouping on time and device (full aggregation)

EXPLAIN (verbose, costs off)
SELECT time, device, avg(temp)
FROM hyper
WHERE time BETWEEN '2019-01-01' AND '2019-01-01 15:00' AND device = 1
GROUP BY 1,2
ORDER BY 1,2

                                                                                                                                                                 QUERY PLAN                                                                                                                                                                 
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Custom Scan (DataNodeScan)
   Output: hyper."time", hyper.device, (avg(hyper.temp))
   Relations: Aggregate on (public.hyper)
   Data node: data_node_1
   Chunks: _dist_hyper_1_1_chunk
   Remote SQL: SELECT "time", device, avg(temp) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) AND ((device = 1)) GROUP BY 1, 2 ORDER BY "time" ASC NULLS LAST
(6 rows)


######### Grouping on time and device (full aggregation)

EXPLAIN (verbose, costs off)
SELECT time_bucket('2 days', time) AS time, device, avg(temp)
FROM hyper
WHERE time BETWEEN '2019-01-01' AND '2019-01-01 15:00' AND device = 1
GROUP BY 1,2
ORDER BY 1,2

                                                                                                                                                                                                          QUERY PLAN                                                                                                                                                                                                          
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Custom Scan (DataNodeScan)
   Output: (time_bucket('@ 2 days'::interval, hyper."time")), hyper.device, (avg(hyper.temp))
   Relations: Aggregate on (public.hyper)
   Data node: data_node_1
   Chunks: _dist_hyper_1_1_chunk
   Remote SQL: SELECT public.time_bucket('@ 2 days'::interval, "time"), device, avg(temp) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) AND ((device = 1)) GROUP BY 1, 2 ORDER BY public.time_bucket('2 days'::interval, "time") ASC NULLS LAST
(6 rows)


######### Grouping on time and device (full aggregation)

EXPLAIN (verbose, costs off)
SELECT date_trunc('month', time) AS time, device, avg(temp)
FROM hyper
WHERE time BETWEEN '2019-01-01' AND '2019-01-01 15:00' AND device = 1
GROUP BY 1,2
ORDER BY 1,2

                                                                                                                                                                                            QUERY PLAN                                                                                                                                                                                            
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Custom Scan (DataNodeScan)
   Output: (date_trunc('month'::text, hyper."time")), hyper.device, (avg(hyper.temp))
   Relations: Aggregate on (public.hyper)
   Data node: data_node_1
   Chunks: _dist_hyper_1_1_chunk
   Remote SQL: SELECT date_trunc('month'::text, "time"), device, avg(temp) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) AND ((device = 1)) GROUP BY 1, 2 ORDER BY date_trunc('month'::text, "time") ASC NULLS LAST
(6 rows)


######### Grouping on time and device (full aggregation)

EXPLAIN (verbose, costs off)
SELECT time_bucket('2 days', time) AS time, device, avg(temp)
FROM hyper
WHERE time BETWEEN '2019-01-01' AND '2019-01-01 15:00' AND device = 1
GROUP BY 1,2
HAVING device > 4
ORDER BY 1,2

                                                                                                                                                                                        QUERY PLAN                                                                                                                                                                                        
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 GroupAggregate
   Output: (time_bucket('@ 2 days'::interval, hyper."time")), hyper.device, avg(hyper.temp)
   Group Key: time_bucket('@ 2 days'::interval, hyper."time"), hyper.device
   ->  Custom Scan (DataNodeScan) on public.hyper
         Output: time_bucket('@ 2 days'::interval, hyper."time"), hyper.device, hyper.temp
         Data node: data_node_1
         Chunks: _dist_hyper_1_1_chunk
         Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) AND ((device > 4)) AND ((device = 1)) ORDER BY public.time_bucket('2 days'::interval, "time") ASC NULLS LAST
(8 rows)

EXPLAIN (verbose, costs off)
SELECT time_bucket('2 days', time) AS time, device, avg(temp)
FROM hyper
WHERE time BETWEEN '2019-01-01' AND '2019-01-01 15:00' AND device = 1
GROUP BY 1,2
HAVING avg(temp) > 40 AND max(temp) < 70
ORDER BY 1,2

                                                                                                                                                                              QUERY PLAN                                                                                                                                                                               
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 GroupAggregate
   Output: (time_bucket('@ 2 days'::interval, hyper."time")), hyper.device, avg(hyper.temp)
   Group Key: time_bucket('@ 2 days'::interval, hyper."time"), hyper.device
   Filter: ((avg(hyper.temp) > '40'::double precision) AND (max(hyper.temp) < '70'::double precision))
   ->  Custom Scan (DataNodeScan) on public.hyper
         Output: time_bucket('@ 2 days'::interval, hyper."time"), hyper.device, hyper.temp
         Data node: data_node_1
         Chunks: _dist_hyper_1_1_chunk
         Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) AND ((device = 1)) ORDER BY public.time_bucket('2 days'::interval, "time") ASC NULLS LAST
(9 rows)


######### Grouping on device only (full aggregation)

EXPLAIN (verbose, costs off)
SELECT device, avg(temp)
FROM hyper
WHERE time BETWEEN '2019-01-01' AND '2019-01-01 15:00' AND device = 1
GROUP BY 1
ORDER BY 1

                                                                                                                                            QUERY PLAN                                                                                                                                            
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Custom Scan (DataNodeScan)
   Output: hyper.device, (avg(hyper.temp))
   Relations: Aggregate on (public.hyper)
   Data node: data_node_1
   Chunks: _dist_hyper_1_1_chunk
   Remote SQL: SELECT device, avg(temp) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) AND ((device = 1)) GROUP BY 1
(6 rows)


######### No push down on some functions

EXPLAIN (verbose, costs off)
SELECT location, avg(temp)
FROM hyper
WHERE time BETWEEN '2019-01-01' AND '2019-01-01 15:00' AND device = 1 AND (temp * random() >= 0)
GROUP BY 1
ORDER BY 1

                                                                                                                                                        QUERY PLAN                                                                                                                                                         
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 GroupAggregate
   Output: hyper.location, avg(hyper.temp)
   Group Key: hyper.location
   ->  Custom Scan (DataNodeScan) on public.hyper
         Output: hyper.location, hyper.temp
         Filter: ((hyper.temp * random()) >= '0'::double precision)
         Data node: data_node_1
         Chunks: _dist_hyper_1_1_chunk
         Remote SQL: SELECT location, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) AND ((device = 1)) ORDER BY location ASC NULLS LAST
(9 rows)


######### No push down on some functions

EXPLAIN (verbose, costs off)
SELECT time_bucket('2 days', time) AS time, device, avg(temp), sum(temp * (random() <= 1)::int) as sum
FROM hyper
WHERE time BETWEEN '2019-01-01' AND '2019-01-01 15:00' AND device = 1
GROUP BY 1,2
ORDER BY 1,2

                                                                                                                                                                              QUERY PLAN                                                                                                                                                                               
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 GroupAggregate
   Output: (time_bucket('@ 2 days'::interval, hyper."time")), hyper.device, avg(hyper.temp), sum((hyper.temp * (((random() <= '1'::double precision))::integer)::double precision))
   Group Key: time_bucket('@ 2 days'::interval, hyper."time"), hyper.device
   ->  Custom Scan (DataNodeScan) on public.hyper
         Output: time_bucket('@ 2 days'::interval, hyper."time"), hyper.device, hyper.temp
         Data node: data_node_1
         Chunks: _dist_hyper_1_1_chunk
         Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) AND ((device = 1)) ORDER BY public.time_bucket('2 days'::interval, "time") ASC NULLS LAST
(8 rows)


######### No push down on some functions

EXPLAIN (verbose, costs off)
SELECT time, device, avg(temp)
FROM hyper
WHERE time BETWEEN '2019-01-01' AND '2019-01-01 15:00' AND device = 1
GROUP BY 1,2
HAVING avg(temp) * custom_sum(device) > 0.8
ORDER BY 1,2

                                                                                                                                                          QUERY PLAN                                                                                                                                                           
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 GroupAggregate
   Output: hyper."time", hyper.device, avg(hyper.temp)
   Group Key: hyper."time", hyper.device
   Filter: ((avg(hyper.temp) * (custom_sum(hyper.device))::double precision) > '0.8'::double precision)
   ->  Custom Scan (DataNodeScan) on public.hyper
         Output: hyper."time", hyper.device, hyper.temp
         Data node: data_node_1
         Chunks: _dist_hyper_1_1_chunk
         Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) AND ((device = 1)) ORDER BY "time" ASC NULLS LAST
(9 rows)


######### No push down on some functions

EXPLAIN (verbose, costs off)
SELECT time, device, avg(temp), custom_sum(device)
FROM hyper
WHERE time BETWEEN '2019-01-01' AND '2019-01-01 15:00' AND device = 1
GROUP BY 1,2
ORDER BY 1,2

                                                                                                                                                          QUERY PLAN                                                                                                                                                           
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 GroupAggregate
   Output: hyper."time", hyper.device, avg(hyper.temp), custom_sum(hyper.device)
   Group Key: hyper."time", hyper.device
   ->  Custom Scan (DataNodeScan) on public.hyper
         Output: hyper."time", hyper.device, hyper.temp
         Data node: data_node_1
         Chunks: _dist_hyper_1_1_chunk
         Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) AND ((device = 1)) ORDER BY "time" ASC NULLS LAST
(8 rows)


######### Constification and runtime push down of time-related functions

 tsl_override_current_timestamptz 
----------------------------------
 
(1 row)

                                                                                                                                                                 QUERY PLAN                                                                                                                                                                 
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Custom Scan (DataNodeScan)
   Output: hyper."time", hyper.device, (avg(hyper.temp))
   Relations: Aggregate on (public.hyper)
   Data node: data_node_1
   Chunks: _dist_hyper_1_1_chunk
   Remote SQL: SELECT "time", device, avg(temp) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) AND ((device = 1)) GROUP BY 1, 2 ORDER BY "time" ASC NULLS LAST
(6 rows)

                                                                                                                                                                 QUERY PLAN                                                                                                                                                                 
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Custom Scan (DataNodeScan)
   Output: hyper."time", hyper.device, (avg(hyper.temp))
   Relations: Aggregate on (public.hyper)
   Data node: data_node_1
   Chunks: _dist_hyper_1_1_chunk
   Remote SQL: SELECT "time", device, avg(temp) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) AND ((device = 1)) GROUP BY 1, 2 ORDER BY "time" ASC NULLS LAST
(6 rows)

 tsl_override_current_timestamptz 
----------------------------------
 
(1 row)

                                                                                                                                                                 QUERY PLAN                                                                                                                                                                 
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Custom Scan (DataNodeScan)
   Output: hyper."time", hyper.device, (avg(hyper.temp))
   Relations: Aggregate on (public.hyper)
   Data node: data_node_1
   Chunks: _dist_hyper_1_1_chunk
   Remote SQL: SELECT "time", device, avg(temp) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) AND ((device = 1)) GROUP BY 1, 2 ORDER BY "time" ASC NULLS LAST
(6 rows)


######### LIMIT push down cases

EXPLAIN (verbose, costs off)
SELECT time, device
FROM hyper
ORDER BY 1,2
LIMIT 10
                                                                                                        QUERY PLAN                                                                                                        
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit
   Output: hyper."time", hyper.device
   ->  Custom Scan (AsyncAppend)
         Output: hyper."time", hyper.device
         ->  Merge Append
               Sort Key: hyper_1."time", hyper_1.device
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_1
                     Output: hyper_1."time", hyper_1.device
                     Data node: data_node_1
                     Chunks: _dist_hyper_1_1_chunk, _dist_hyper_1_4_chunk, _dist_hyper_1_8_chunk, _dist_hyper_1_12_chunk, _dist_hyper_1_13_chunk, _dist_hyper_1_15_chunk, _dist_hyper_1_17_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST LIMIT 10
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                     Output: hyper_2."time", hyper_2.device
                     Data node: data_node_2
                     Chunks: _dist_hyper_1_2_chunk, _dist_hyper_1_5_chunk, _dist_hyper_1_7_chunk, _dist_hyper_1_9_chunk, _dist_hyper_1_11_chunk, _dist_hyper_1_14_chunk, _dist_hyper_1_18_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST LIMIT 10
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_3
                     Output: hyper_3."time", hyper_3.device
                     Data node: data_node_3
                     Chunks: _dist_hyper_1_3_chunk, _dist_hyper_1_6_chunk, _dist_hyper_1_10_chunk, _dist_hyper_1_16_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4]) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST LIMIT 10
(21 rows)


######### LIMIT push down cases

EXPLAIN (verbose, costs off)
SELECT time, device
FROM hyper
ORDER BY 1,2
LIMIT 5
OFFSET 5
                                                                                                        QUERY PLAN                                                                                                        
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit
   Output: hyper."time", hyper.device
   ->  Custom Scan (AsyncAppend)
         Output: hyper."time", hyper.device
         ->  Merge Append
               Sort Key: hyper_1."time", hyper_1.device
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_1
                     Output: hyper_1."time", hyper_1.device
                     Data node: data_node_1
                     Chunks: _dist_hyper_1_1_chunk, _dist_hyper_1_4_chunk, _dist_hyper_1_8_chunk, _dist_hyper_1_12_chunk, _dist_hyper_1_13_chunk, _dist_hyper_1_15_chunk, _dist_hyper_1_17_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST LIMIT 10
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                     Output: hyper_2."time", hyper_2.device
                     Data node: data_node_2
                     Chunks: _dist_hyper_1_2_chunk, _dist_hyper_1_5_chunk, _dist_hyper_1_7_chunk, _dist_hyper_1_9_chunk, _dist_hyper_1_11_chunk, _dist_hyper_1_14_chunk, _dist_hyper_1_18_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST LIMIT 10
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_3
                     Output: hyper_3."time", hyper_3.device
                     Data node: data_node_3
                     Chunks: _dist_hyper_1_3_chunk, _dist_hyper_1_6_chunk, _dist_hyper_1_10_chunk, _dist_hyper_1_16_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4]) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST LIMIT 10
(21 rows)


######### LIMIT push down cases

EXPLAIN (verbose, costs off)
SELECT time, device
FROM hyper
ORDER BY 1,2
LIMIT 0
                                                                                                       QUERY PLAN                                                                                                        
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit
   Output: hyper."time", hyper.device
   ->  Custom Scan (AsyncAppend)
         Output: hyper."time", hyper.device
         ->  Merge Append
               Sort Key: hyper_1."time", hyper_1.device
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_1
                     Output: hyper_1."time", hyper_1.device
                     Data node: data_node_1
                     Chunks: _dist_hyper_1_1_chunk, _dist_hyper_1_4_chunk, _dist_hyper_1_8_chunk, _dist_hyper_1_12_chunk, _dist_hyper_1_13_chunk, _dist_hyper_1_15_chunk, _dist_hyper_1_17_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST LIMIT 1
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                     Output: hyper_2."time", hyper_2.device
                     Data node: data_node_2
                     Chunks: _dist_hyper_1_2_chunk, _dist_hyper_1_5_chunk, _dist_hyper_1_7_chunk, _dist_hyper_1_9_chunk, _dist_hyper_1_11_chunk, _dist_hyper_1_14_chunk, _dist_hyper_1_18_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST LIMIT 1
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_3
                     Output: hyper_3."time", hyper_3.device
                     Data node: data_node_3
                     Chunks: _dist_hyper_1_3_chunk, _dist_hyper_1_6_chunk, _dist_hyper_1_10_chunk, _dist_hyper_1_16_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4]) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST LIMIT 1
(21 rows)


######### LIMIT push down cases

EXPLAIN (verbose, costs off)
SELECT time, device
FROM hyper
ORDER BY 1,2
LIMIT extract(year from date '2000-01-01')
                                                                                                         QUERY PLAN                                                                                                         
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit
   Output: hyper."time", hyper.device
   ->  Custom Scan (AsyncAppend)
         Output: hyper."time", hyper.device
         ->  Merge Append
               Sort Key: hyper_1."time", hyper_1.device
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_1
                     Output: hyper_1."time", hyper_1.device
                     Data node: data_node_1
                     Chunks: _dist_hyper_1_1_chunk, _dist_hyper_1_4_chunk, _dist_hyper_1_8_chunk, _dist_hyper_1_12_chunk, _dist_hyper_1_13_chunk, _dist_hyper_1_15_chunk, _dist_hyper_1_17_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST LIMIT 2000
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                     Output: hyper_2."time", hyper_2.device
                     Data node: data_node_2
                     Chunks: _dist_hyper_1_2_chunk, _dist_hyper_1_5_chunk, _dist_hyper_1_7_chunk, _dist_hyper_1_9_chunk, _dist_hyper_1_11_chunk, _dist_hyper_1_14_chunk, _dist_hyper_1_18_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST LIMIT 2000
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_3
                     Output: hyper_3."time", hyper_3.device
                     Data node: data_node_3
                     Chunks: _dist_hyper_1_3_chunk, _dist_hyper_1_6_chunk, _dist_hyper_1_10_chunk, _dist_hyper_1_16_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4]) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST LIMIT 2000
(21 rows)


######### LIMIT push down cases

EXPLAIN (verbose, costs off)
SELECT time, device
FROM hyper
ORDER BY 1,2
LIMIT greatest(random(), 10.0)
                                                                                                   QUERY PLAN                                                                                                    
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit
   Output: hyper."time", hyper.device
   ->  Custom Scan (AsyncAppend)
         Output: hyper."time", hyper.device
         ->  Merge Append
               Sort Key: hyper_1."time", hyper_1.device
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_1
                     Output: hyper_1."time", hyper_1.device
                     Data node: data_node_1
                     Chunks: _dist_hyper_1_1_chunk, _dist_hyper_1_4_chunk, _dist_hyper_1_8_chunk, _dist_hyper_1_12_chunk, _dist_hyper_1_13_chunk, _dist_hyper_1_15_chunk, _dist_hyper_1_17_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                     Output: hyper_2."time", hyper_2.device
                     Data node: data_node_2
                     Chunks: _dist_hyper_1_2_chunk, _dist_hyper_1_5_chunk, _dist_hyper_1_7_chunk, _dist_hyper_1_9_chunk, _dist_hyper_1_11_chunk, _dist_hyper_1_14_chunk, _dist_hyper_1_18_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_3
                     Output: hyper_3."time", hyper_3.device
                     Data node: data_node_3
                     Chunks: _dist_hyper_1_3_chunk, _dist_hyper_1_6_chunk, _dist_hyper_1_10_chunk, _dist_hyper_1_16_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4]) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST
(21 rows)


######### LIMIT push down cases

EXPLAIN (verbose, costs off)
SELECT time, device, avg(temp) OVER (PARTITION BY device)
FROM hyper
ORDER BY 1,2
LIMIT 10
                                                                                                 QUERY PLAN                                                                                                  
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit
   Output: hyper."time", hyper.device, (avg(hyper.temp) OVER (?))
   ->  Sort
         Output: hyper."time", hyper.device, (avg(hyper.temp) OVER (?))
         Sort Key: hyper."time", hyper.device
         ->  WindowAgg
               Output: hyper."time", hyper.device, avg(hyper.temp) OVER (?)
               ->  Custom Scan (AsyncAppend)
                     Output: hyper.device, hyper."time", hyper.temp
                     ->  Merge Append
                           Sort Key: hyper_1.device
                           ->  Custom Scan (DataNodeScan) on public.hyper hyper_1
                                 Output: hyper_1.device, hyper_1."time", hyper_1.temp
                                 Data node: data_node_1
                                 Chunks: _dist_hyper_1_1_chunk, _dist_hyper_1_4_chunk, _dist_hyper_1_8_chunk, _dist_hyper_1_12_chunk, _dist_hyper_1_13_chunk, _dist_hyper_1_15_chunk, _dist_hyper_1_17_chunk
                                 Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) ORDER BY device ASC NULLS LAST
                           ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                                 Output: hyper_2.device, hyper_2."time", hyper_2.temp
                                 Data node: data_node_2
                                 Chunks: _dist_hyper_1_2_chunk, _dist_hyper_1_5_chunk, _dist_hyper_1_7_chunk, _dist_hyper_1_9_chunk, _dist_hyper_1_11_chunk, _dist_hyper_1_14_chunk, _dist_hyper_1_18_chunk
                                 Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) ORDER BY device ASC NULLS LAST
                           ->  Custom Scan (DataNodeScan) on public.hyper hyper_3
                                 Output: hyper_3.device, hyper_3."time", hyper_3.temp
                                 Data node: data_node_3
                                 Chunks: _dist_hyper_1_3_chunk, _dist_hyper_1_6_chunk, _dist_hyper_1_10_chunk, _dist_hyper_1_16_chunk
                                 Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4]) ORDER BY device ASC NULLS LAST
(26 rows)


######### LIMIT push down cases

EXPLAIN (verbose, costs off)
SELECT DISTINCT device, time
FROM hyper
ORDER BY 1,2
LIMIT 10
                                                                                                      QUERY PLAN                                                                                                       
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit
   Output: hyper.device, hyper."time"
   ->  Unique
         Output: hyper.device, hyper."time"
         ->  Custom Scan (AsyncAppend)
               Output: hyper.device, hyper."time"
               ->  Merge Append
                     Sort Key: hyper_1.device, hyper_1."time"
                     ->  Custom Scan (DataNodeScan) on public.hyper hyper_1
                           Output: hyper_1.device, hyper_1."time"
                           Data node: data_node_1
                           Chunks: _dist_hyper_1_1_chunk, _dist_hyper_1_4_chunk, _dist_hyper_1_8_chunk, _dist_hyper_1_12_chunk, _dist_hyper_1_13_chunk, _dist_hyper_1_15_chunk, _dist_hyper_1_17_chunk
                           Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) ORDER BY device ASC NULLS LAST, "time" ASC NULLS LAST
                     ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                           Output: hyper_2.device, hyper_2."time"
                           Data node: data_node_2
                           Chunks: _dist_hyper_1_2_chunk, _dist_hyper_1_5_chunk, _dist_hyper_1_7_chunk, _dist_hyper_1_9_chunk, _dist_hyper_1_11_chunk, _dist_hyper_1_14_chunk, _dist_hyper_1_18_chunk
                           Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) ORDER BY device ASC NULLS LAST, "time" ASC NULLS LAST
                     ->  Custom Scan (DataNodeScan) on public.hyper hyper_3
                           Output: hyper_3.device, hyper_3."time"
                           Data node: data_node_3
                           Chunks: _dist_hyper_1_3_chunk, _dist_hyper_1_6_chunk, _dist_hyper_1_10_chunk, _dist_hyper_1_16_chunk
                           Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4]) ORDER BY device ASC NULLS LAST, "time" ASC NULLS LAST
(23 rows)


######### LIMIT push down cases

EXPLAIN (verbose, costs off)
SELECT DISTINCT ON (device) device, time
FROM hyper
ORDER BY 1,2
LIMIT 10
                                                                                                      QUERY PLAN                                                                                                       
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit
   Output: hyper.device, hyper."time"
   ->  Unique
         Output: hyper.device, hyper."time"
         ->  Custom Scan (AsyncAppend)
               Output: hyper.device, hyper."time"
               ->  Merge Append
                     Sort Key: hyper_1.device, hyper_1."time"
                     ->  Custom Scan (DataNodeScan) on public.hyper hyper_1
                           Output: hyper_1.device, hyper_1."time"
                           Data node: data_node_1
                           Chunks: _dist_hyper_1_1_chunk, _dist_hyper_1_4_chunk, _dist_hyper_1_8_chunk, _dist_hyper_1_12_chunk, _dist_hyper_1_13_chunk, _dist_hyper_1_15_chunk, _dist_hyper_1_17_chunk
                           Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) ORDER BY device ASC NULLS LAST, "time" ASC NULLS LAST
                     ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                           Output: hyper_2.device, hyper_2."time"
                           Data node: data_node_2
                           Chunks: _dist_hyper_1_2_chunk, _dist_hyper_1_5_chunk, _dist_hyper_1_7_chunk, _dist_hyper_1_9_chunk, _dist_hyper_1_11_chunk, _dist_hyper_1_14_chunk, _dist_hyper_1_18_chunk
                           Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) ORDER BY device ASC NULLS LAST, "time" ASC NULLS LAST
                     ->  Custom Scan (DataNodeScan) on public.hyper hyper_3
                           Output: hyper_3.device, hyper_3."time"
                           Data node: data_node_3
                           Chunks: _dist_hyper_1_3_chunk, _dist_hyper_1_6_chunk, _dist_hyper_1_10_chunk, _dist_hyper_1_16_chunk
                           Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4]) ORDER BY device ASC NULLS LAST, "time" ASC NULLS LAST
(23 rows)


######### LIMIT push down cases

                                                                                              QUERY PLAN                                                                                               
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit
   Output: t."time"
   ->  Nested Loop
         Output: t."time"
         Join Filter: (t.device = join_test.device)
         ->  Custom Scan (AsyncAppend)
               Output: t."time", t.device
               ->  Append
                     ->  Custom Scan (DataNodeScan) on public.hyper t_1
                           Output: t_1."time", t_1.device
                           Data node: data_node_1
                           Chunks: _dist_hyper_1_1_chunk, _dist_hyper_1_4_chunk, _dist_hyper_1_8_chunk, _dist_hyper_1_12_chunk, _dist_hyper_1_13_chunk, _dist_hyper_1_15_chunk, _dist_hyper_1_17_chunk
                           Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7])
                     ->  Custom Scan (DataNodeScan) on public.hyper t_2
                           Output: t_2."time", t_2.device
                           Data node: data_node_2
                           Chunks: _dist_hyper_1_2_chunk, _dist_hyper_1_5_chunk, _dist_hyper_1_7_chunk, _dist_hyper_1_9_chunk, _dist_hyper_1_11_chunk, _dist_hyper_1_14_chunk, _dist_hyper_1_18_chunk
                           Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7])
                     ->  Custom Scan (DataNodeScan) on public.hyper t_3
                           Output: t_3."time", t_3.device
                           Data node: data_node_3
                           Chunks: _dist_hyper_1_3_chunk, _dist_hyper_1_6_chunk, _dist_hyper_1_10_chunk, _dist_hyper_1_16_chunk
                           Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4])
         ->  Materialize
               Output: join_test.device
               ->  Seq Scan on public.join_test
                     Output: join_test.device
(27 rows)

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% RUNNING TESTS on table: hyper
%%% PREFIX: EXPLAIN (verbose, costs off)
%%% WHERE_CLAUSE: :CLEAN_PARTITIONING_TIME_RANGE
%%% ORDER_BY_1: ORDER BY 1
%%% ORDER_BY_1_2: ORDER BY 1,2
%%% LIMIT: LIMIT 10
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
 setseed 
---------
 
(1 row)


######### Grouping on time only (partial aggregation)

EXPLAIN (verbose, costs off)
SELECT time, avg(temp)
FROM hyper
WHERE time BETWEEN '2019-01-01' AND '2019-01-01 15:00'
GROUP BY 1
ORDER BY 1
LIMIT 10
                                                                                                                                                      QUERY PLAN                                                                                                                                                      
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit
   Output: hyper."time", (avg(hyper.temp))
   ->  GroupAggregate
         Output: hyper."time", avg(hyper.temp)
         Group Key: hyper."time"
         ->  Custom Scan (AsyncAppend)
               Output: hyper."time", hyper.temp
               ->  Merge Append
                     Sort Key: hyper_1."time"
                     ->  Custom Scan (DataNodeScan) on public.hyper hyper_1
                           Output: hyper_1."time", hyper_1.temp
                           Data node: data_node_1
                           Chunks: _dist_hyper_1_1_chunk
                           Remote SQL: SELECT "time", temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY "time" ASC NULLS LAST
                     ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                           Output: hyper_2."time", hyper_2.temp
                           Data node: data_node_2
                           Chunks: _dist_hyper_1_2_chunk
                           Remote SQL: SELECT "time", temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY "time" ASC NULLS LAST
                     ->  Custom Scan (DataNodeScan) on public.hyper hyper_3
                           Output: hyper_3."time", hyper_3.temp
                           Data node: data_node_3
                           Chunks: _dist_hyper_1_3_chunk
                           Remote SQL: SELECT "time", temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY "time" ASC NULLS LAST
(24 rows)


######### Grouping on time only (partial aggregation)

EXPLAIN (verbose, costs off)
SELECT time_bucket('2 days', time) AS time, avg(temp)
FROM hyper
WHERE time BETWEEN '2019-01-01' AND '2019-01-01 15:00'
GROUP BY 1
ORDER BY 1
LIMIT 10
                                                                                                                                                                          QUERY PLAN                                                                                                                                                                          
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit
   Output: (time_bucket('@ 2 days'::interval, hyper."time")), (avg(hyper.temp))
   ->  GroupAggregate
         Output: (time_bucket('@ 2 days'::interval, hyper."time")), avg(hyper.temp)
         Group Key: (time_bucket('@ 2 days'::interval, hyper."time"))
         ->  Custom Scan (AsyncAppend)
               Output: (time_bucket('@ 2 days'::interval, hyper."time")), hyper.temp
               ->  Merge Append
                     Sort Key: (time_bucket('@ 2 days'::interval, hyper_1."time"))
                     ->  Custom Scan (DataNodeScan) on public.hyper hyper_1
                           Output: time_bucket('@ 2 days'::interval, hyper_1."time"), hyper_1.temp
                           Data node: data_node_1
                           Chunks: _dist_hyper_1_1_chunk
                           Remote SQL: SELECT "time", temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY public.time_bucket('2 days'::interval, "time") ASC NULLS LAST
                     ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                           Output: time_bucket('@ 2 days'::interval, hyper_2."time"), hyper_2.temp
                           Data node: data_node_2
                           Chunks: _dist_hyper_1_2_chunk
                           Remote SQL: SELECT "time", temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY public.time_bucket('2 days'::interval, "time") ASC NULLS LAST
                     ->  Custom Scan (DataNodeScan) on public.hyper hyper_3
                           Output: time_bucket('@ 2 days'::interval, hyper_3."time"), hyper_3.temp
                           Data node: data_node_3
                           Chunks: _dist_hyper_1_3_chunk
                           Remote SQL: SELECT "time", temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY public.time_bucket('2 days'::interval, "time") ASC NULLS LAST
(24 rows)


######### Grouping on time and device (full aggregation)

EXPLAIN (verbose, costs off)
SELECT time, device, avg(temp)
FROM hyper
WHERE time BETWEEN '2019-01-01' AND '2019-01-01 15:00'
GROUP BY 1,2
ORDER BY 1,2
LIMIT 10
                                                                                                                                                                     QUERY PLAN                                                                                                                                                                      
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit
   Output: hyper."time", hyper.device, (avg(hyper.temp))
   ->  GroupAggregate
         Output: hyper."time", hyper.device, avg(hyper.temp)
         Group Key: hyper."time", hyper.device
         ->  Custom Scan (AsyncAppend)
               Output: hyper."time", hyper.device, hyper.temp
               ->  Merge Append
                     Sort Key: hyper_1."time", hyper_1.device
                     ->  Custom Scan (DataNodeScan) on public.hyper hyper_1
                           Output: hyper_1."time", hyper_1.device, hyper_1.temp
                           Data node: data_node_1
                           Chunks: _dist_hyper_1_1_chunk
                           Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST
                     ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                           Output: hyper_2."time", hyper_2.device, hyper_2.temp
                           Data node: data_node_2
                           Chunks: _dist_hyper_1_2_chunk
                           Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST
                     ->  Custom Scan (DataNodeScan) on public.hyper hyper_3
                           Output: hyper_3."time", hyper_3.device, hyper_3.temp
                           Data node: data_node_3
                           Chunks: _dist_hyper_1_3_chunk
                           Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST
(24 rows)


######### Grouping on time and device (full aggregation)

EXPLAIN (verbose, costs off)
SELECT time_bucket('2 days', time) AS time, device, avg(temp)
FROM hyper
WHERE time BETWEEN '2019-01-01' AND '2019-01-01 15:00'
GROUP BY 1,2
ORDER BY 1,2
LIMIT 10
                                                                                                                                                                                         QUERY PLAN                                                                                                                                                                                          
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit
   Output: (time_bucket('@ 2 days'::interval, hyper."time")), hyper.device, (avg(hyper.temp))
   ->  GroupAggregate
         Output: (time_bucket('@ 2 days'::interval, hyper."time")), hyper.device, avg(hyper.temp)
         Group Key: (time_bucket('@ 2 days'::interval, hyper."time")), hyper.device
         ->  Custom Scan (AsyncAppend)
               Output: (time_bucket('@ 2 days'::interval, hyper."time")), hyper.device, hyper.temp
               ->  Merge Append
                     Sort Key: (time_bucket('@ 2 days'::interval, hyper_1."time")), hyper_1.device
                     ->  Custom Scan (DataNodeScan) on public.hyper hyper_1
                           Output: time_bucket('@ 2 days'::interval, hyper_1."time"), hyper_1.device, hyper_1.temp
                           Data node: data_node_1
                           Chunks: _dist_hyper_1_1_chunk
                           Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY public.time_bucket('2 days'::interval, "time") ASC NULLS LAST, device ASC NULLS LAST
                     ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                           Output: time_bucket('@ 2 days'::interval, hyper_2."time"), hyper_2.device, hyper_2.temp
                           Data node: data_node_2
                           Chunks: _dist_hyper_1_2_chunk
                           Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY public.time_bucket('2 days'::interval, "time") ASC NULLS LAST, device ASC NULLS LAST
                     ->  Custom Scan (DataNodeScan) on public.hyper hyper_3
                           Output: time_bucket('@ 2 days'::interval, hyper_3."time"), hyper_3.device, hyper_3.temp
                           Data node: data_node_3
                           Chunks: _dist_hyper_1_3_chunk
                           Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY public.time_bucket('2 days'::interval, "time") ASC NULLS LAST, device ASC NULLS LAST
(24 rows)


######### Grouping on time and device (full aggregation)

EXPLAIN (verbose, costs off)
SELECT date_trunc('month', time) AS time, device, avg(temp)
FROM hyper
WHERE time BETWEEN '2019-01-01' AND '2019-01-01 15:00'
GROUP BY 1,2
ORDER BY 1,2
LIMIT 10
                                                                                                                                                                                   QUERY PLAN                                                                                                                                                                                   
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit
   Output: (date_trunc('month'::text, hyper."time")), hyper.device, (avg(hyper.temp))
   ->  GroupAggregate
         Output: (date_trunc('month'::text, hyper."time")), hyper.device, avg(hyper.temp)
         Group Key: (date_trunc('month'::text, hyper."time")), hyper.device
         ->  Custom Scan (AsyncAppend)
               Output: (date_trunc('month'::text, hyper."time")), hyper.device, hyper.temp
               ->  Merge Append
                     Sort Key: (date_trunc('month'::text, hyper_1."time")), hyper_1.device
                     ->  Custom Scan (DataNodeScan) on public.hyper hyper_1
                           Output: date_trunc('month'::text, hyper_1."time"), hyper_1.device, hyper_1.temp
                           Data node: data_node_1
                           Chunks: _dist_hyper_1_1_chunk
                           Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY date_trunc('month'::text, "time") ASC NULLS LAST, device ASC NULLS LAST
                     ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                           Output: date_trunc('month'::text, hyper_2."time"), hyper_2.device, hyper_2.temp
                           Data node: data_node_2
                           Chunks: _dist_hyper_1_2_chunk
                           Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY date_trunc('month'::text, "time") ASC NULLS LAST, device ASC NULLS LAST
                     ->  Custom Scan (DataNodeScan) on public.hyper hyper_3
                           Output: date_trunc('month'::text, hyper_3."time"), hyper_3.device, hyper_3.temp
                           Data node: data_node_3
                           Chunks: _dist_hyper_1_3_chunk
                           Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY date_trunc('month'::text, "time") ASC NULLS LAST, device ASC NULLS LAST
(24 rows)


######### Grouping on time and device (full aggregation)

EXPLAIN (verbose, costs off)
SELECT time_bucket('2 days', time) AS time, device, avg(temp)
FROM hyper
WHERE time BETWEEN '2019-01-01' AND '2019-01-01 15:00'
GROUP BY 1,2
HAVING device > 4
ORDER BY 1,2
LIMIT 10
                                                                                                                                                                                                   QUERY PLAN                                                                                                                                                                                                   
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit
   Output: (time_bucket('@ 2 days'::interval, hyper."time")), hyper.device, (avg(hyper.temp))
   ->  GroupAggregate
         Output: (time_bucket('@ 2 days'::interval, hyper."time")), hyper.device, avg(hyper.temp)
         Group Key: (time_bucket('@ 2 days'::interval, hyper."time")), hyper.device
         ->  Custom Scan (AsyncAppend)
               Output: (time_bucket('@ 2 days'::interval, hyper."time")), hyper.device, hyper.temp
               ->  Merge Append
                     Sort Key: (time_bucket('@ 2 days'::interval, hyper_1."time")), hyper_1.device
                     ->  Custom Scan (DataNodeScan) on public.hyper hyper_1
                           Output: time_bucket('@ 2 days'::interval, hyper_1."time"), hyper_1.device, hyper_1.temp
                           Data node: data_node_1
                           Chunks: _dist_hyper_1_1_chunk
                           Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) AND ((device > 4)) ORDER BY public.time_bucket('2 days'::interval, "time") ASC NULLS LAST, device ASC NULLS LAST
                     ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                           Output: time_bucket('@ 2 days'::interval, hyper_2."time"), hyper_2.device, hyper_2.temp
                           Data node: data_node_2
                           Chunks: _dist_hyper_1_2_chunk
                           Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) AND ((device > 4)) ORDER BY public.time_bucket('2 days'::interval, "time") ASC NULLS LAST, device ASC NULLS LAST
                     ->  Custom Scan (DataNodeScan) on public.hyper hyper_3
                           Output: time_bucket('@ 2 days'::interval, hyper_3."time"), hyper_3.device, hyper_3.temp
                           Data node: data_node_3
                           Chunks: _dist_hyper_1_3_chunk
                           Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) AND ((device > 4)) ORDER BY public.time_bucket('2 days'::interval, "time") ASC NULLS LAST, device ASC NULLS LAST
(24 rows)

EXPLAIN (verbose, costs off)
SELECT time_bucket('2 days', time) AS time, device, avg(temp)
FROM hyper
WHERE time BETWEEN '2019-01-01' AND '2019-01-01 15:00'
GROUP BY 1,2
HAVING avg(temp) > 40 AND max(temp) < 70
ORDER BY 1,2
LIMIT 10
                                                                                                                                                                                                                                                               QUERY PLAN                                                                                                                                                                                                                                                                
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit
   Output: (time_bucket('@ 2 days'::interval, "time")), device, (avg(temp))
   ->  Custom Scan (AsyncAppend)
         Output: (time_bucket('@ 2 days'::interval, "time")), device, (avg(temp))
         ->  Merge Append
               Sort Key: (time_bucket('@ 2 days'::interval, hyper."time")), hyper.device
               ->  Custom Scan (DataNodeScan)
                     Output: (time_bucket('@ 2 days'::interval, hyper."time")), hyper.device, (avg(hyper.temp))
                     Relations: Aggregate on (public.hyper)
                     Data node: data_node_1
                     Chunks: _dist_hyper_1_1_chunk
                     Remote SQL: SELECT public.time_bucket('@ 2 days'::interval, "time"), device, avg(temp) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) GROUP BY 1, 2 HAVING ((avg(temp) > 40::double precision)) AND ((max(temp) < 70::double precision)) ORDER BY public.time_bucket('2 days'::interval, "time") ASC NULLS LAST, device ASC NULLS LAST
               ->  Custom Scan (DataNodeScan)
                     Output: (time_bucket('@ 2 days'::interval, hyper_1."time")), hyper_1.device, (avg(hyper_1.temp))
                     Relations: Aggregate on (public.hyper)
                     Data node: data_node_2
                     Chunks: _dist_hyper_1_2_chunk
                     Remote SQL: SELECT public.time_bucket('@ 2 days'::interval, "time"), device, avg(temp) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) GROUP BY 1, 2 HAVING ((avg(temp) > 40::double precision)) AND ((max(temp) < 70::double precision)) ORDER BY public.time_bucket('2 days'::interval, "time") ASC NULLS LAST, device ASC NULLS LAST
               ->  GroupAggregate
                     Output: (time_bucket('@ 2 days'::interval, hyper_2."time")), hyper_2.device, avg(hyper_2.temp)
                     Group Key: time_bucket('@ 2 days'::interval, hyper_2."time"), hyper_2.device
                     Filter: ((avg(hyper_2.temp) > '40'::double precision) AND (max(hyper_2.temp) < '70'::double precision))
                     ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                           Output: time_bucket('@ 2 days'::interval, hyper_2."time"), hyper_2.device, hyper_2.temp
                           Data node: data_node_3
                           Chunks: _dist_hyper_1_3_chunk
                           Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY public.time_bucket('2 days'::interval, "time") ASC NULLS LAST, device ASC NULLS LAST
(27 rows)


######### Grouping on device only (full aggregation)

EXPLAIN (verbose, costs off)
SELECT device, avg(temp)
FROM hyper
WHERE time BETWEEN '2019-01-01' AND '2019-01-01 15:00'
GROUP BY 1
ORDER BY 1
LIMIT 10
                                                                                                                                                      QUERY PLAN                                                                                                                                                      
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit
   Output: hyper.device, (avg(hyper.temp))
   ->  GroupAggregate
         Output: hyper.device, avg(hyper.temp)
         Group Key: hyper.device
         ->  Custom Scan (AsyncAppend)
               Output: hyper.device, hyper.temp
               ->  Merge Append
                     Sort Key: hyper_1.device
                     ->  Custom Scan (DataNodeScan) on public.hyper hyper_1
                           Output: hyper_1.device, hyper_1.temp
                           Data node: data_node_1
                           Chunks: _dist_hyper_1_1_chunk
                           Remote SQL: SELECT device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY device ASC NULLS LAST
                     ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                           Output: hyper_2.device, hyper_2.temp
                           Data node: data_node_2
                           Chunks: _dist_hyper_1_2_chunk
                           Remote SQL: SELECT device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY device ASC NULLS LAST
                     ->  Custom Scan (DataNodeScan) on public.hyper hyper_3
                           Output: hyper_3.device, hyper_3.temp
                           Data node: data_node_3
                           Chunks: _dist_hyper_1_3_chunk
                           Remote SQL: SELECT device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY device ASC NULLS LAST
(24 rows)


######### No push down on some functions

EXPLAIN (verbose, costs off)
SELECT location, avg(temp)
FROM hyper
WHERE time BETWEEN '2019-01-01' AND '2019-01-01 15:00' AND (temp * random() >= 0)
GROUP BY 1
ORDER BY 1
LIMIT 10
                                                                                                                                                        QUERY PLAN                                                                                                                                                        
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit
   Output: hyper.location, (avg(hyper.temp))
   ->  GroupAggregate
         Output: hyper.location, avg(hyper.temp)
         Group Key: hyper.location
         ->  Custom Scan (AsyncAppend)
               Output: hyper.location, hyper.temp
               ->  Merge Append
                     Sort Key: hyper_1.location
                     ->  Custom Scan (DataNodeScan) on public.hyper hyper_1
                           Output: hyper_1.location, hyper_1.temp
                           Filter: ((hyper_1.temp * random()) >= '0'::double precision)
                           Data node: data_node_1
                           Chunks: _dist_hyper_1_1_chunk
                           Remote SQL: SELECT location, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY location ASC NULLS LAST
                     ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                           Output: hyper_2.location, hyper_2.temp
                           Filter: ((hyper_2.temp * random()) >= '0'::double precision)
                           Data node: data_node_2
                           Chunks: _dist_hyper_1_2_chunk
                           Remote SQL: SELECT location, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY location ASC NULLS LAST
                     ->  Custom Scan (DataNodeScan) on public.hyper hyper_3
                           Output: hyper_3.location, hyper_3.temp
                           Filter: ((hyper_3.temp * random()) >= '0'::double precision)
                           Data node: data_node_3
                           Chunks: _dist_hyper_1_3_chunk
                           Remote SQL: SELECT location, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY location ASC NULLS LAST
(27 rows)


######### No push down on some functions

EXPLAIN (verbose, costs off)
SELECT time_bucket('2 days', time) AS time, device, avg(temp), sum(temp * (random() <= 1)::int) as sum
FROM hyper
WHERE time BETWEEN '2019-01-01' AND '2019-01-01 15:00'
GROUP BY 1,2
ORDER BY 1,2
LIMIT 10
                                                                                                                                                                                         QUERY PLAN                                                                                                                                                                                          
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit
   Output: (time_bucket('@ 2 days'::interval, hyper."time")), hyper.device, (avg(hyper.temp)), (sum((hyper.temp * (((random() <= '1'::double precision))::integer)::double precision)))
   ->  GroupAggregate
         Output: (time_bucket('@ 2 days'::interval, hyper."time")), hyper.device, avg(hyper.temp), sum((hyper.temp * (((random() <= '1'::double precision))::integer)::double precision))
         Group Key: (time_bucket('@ 2 days'::interval, hyper."time")), hyper.device
         ->  Custom Scan (AsyncAppend)
               Output: (time_bucket('@ 2 days'::interval, hyper."time")), hyper.device, hyper.temp
               ->  Merge Append
                     Sort Key: (time_bucket('@ 2 days'::interval, hyper_1."time")), hyper_1.device
                     ->  Custom Scan (DataNodeScan) on public.hyper hyper_1
                           Output: time_bucket('@ 2 days'::interval, hyper_1."time"), hyper_1.device, hyper_1.temp
                           Data node: data_node_1
                           Chunks: _dist_hyper_1_1_chunk
                           Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY public.time_bucket('2 days'::interval, "time") ASC NULLS LAST, device ASC NULLS LAST
                     ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                           Output: time_bucket('@ 2 days'::interval, hyper_2."time"), hyper_2.device, hyper_2.temp
                           Data node: data_node_2
                           Chunks: _dist_hyper_1_2_chunk
                           Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY public.time_bucket('2 days'::interval, "time") ASC NULLS LAST, device ASC NULLS LAST
                     ->  Custom Scan (DataNodeScan) on public.hyper hyper_3
                           Output: time_bucket('@ 2 days'::interval, hyper_3."time"), hyper_3.device, hyper_3.temp
                           Data node: data_node_3
                           Chunks: _dist_hyper_1_3_chunk
                           Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY public.time_bucket('2 days'::interval, "time") ASC NULLS LAST, device ASC NULLS LAST
(24 rows)


######### No push down on some functions

EXPLAIN (verbose, costs off)
SELECT time, device, avg(temp)
FROM hyper
WHERE time BETWEEN '2019-01-01' AND '2019-01-01 15:00'
GROUP BY 1,2
HAVING avg(temp) * custom_sum(device) > 0.8
ORDER BY 1,2
LIMIT 10
                                                                                                                                                                     QUERY PLAN                                                                                                                                                                      
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit
   Output: hyper."time", hyper.device, (avg(hyper.temp))
   ->  GroupAggregate
         Output: hyper."time", hyper.device, avg(hyper.temp)
         Group Key: hyper."time", hyper.device
         Filter: ((avg(hyper.temp) * (custom_sum(hyper.device))::double precision) > '0.8'::double precision)
         ->  Custom Scan (AsyncAppend)
               Output: hyper."time", hyper.device, hyper.temp
               ->  Merge Append
                     Sort Key: hyper_1."time", hyper_1.device
                     ->  Custom Scan (DataNodeScan) on public.hyper hyper_1
                           Output: hyper_1."time", hyper_1.device, hyper_1.temp
                           Data node: data_node_1
                           Chunks: _dist_hyper_1_1_chunk
                           Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST
                     ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                           Output: hyper_2."time", hyper_2.device, hyper_2.temp
                           Data node: data_node_2
                           Chunks: _dist_hyper_1_2_chunk
                           Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST
                     ->  Custom Scan (DataNodeScan) on public.hyper hyper_3
                           Output: hyper_3."time", hyper_3.device, hyper_3.temp
                           Data node: data_node_3
                           Chunks: _dist_hyper_1_3_chunk
                           Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST
(25 rows)


######### No push down on some functions

EXPLAIN (verbose, costs off)
SELECT time, device, avg(temp), custom_sum(device)
FROM hyper
WHERE time BETWEEN '2019-01-01' AND '2019-01-01 15:00'
GROUP BY 1,2
ORDER BY 1,2
LIMIT 10
                                                                                                                                                                     QUERY PLAN                                                                                                                                                                      
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit
   Output: hyper."time", hyper.device, (avg(hyper.temp)), (custom_sum(hyper.device))
   ->  GroupAggregate
         Output: hyper."time", hyper.device, avg(hyper.temp), custom_sum(hyper.device)
         Group Key: hyper."time", hyper.device
         ->  Custom Scan (AsyncAppend)
               Output: hyper."time", hyper.device, hyper.temp
               ->  Merge Append
                     Sort Key: hyper_1."time", hyper_1.device
                     ->  Custom Scan (DataNodeScan) on public.hyper hyper_1
                           Output: hyper_1."time", hyper_1.device, hyper_1.temp
                           Data node: data_node_1
                           Chunks: _dist_hyper_1_1_chunk
                           Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST
                     ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                           Output: hyper_2."time", hyper_2.device, hyper_2.temp
                           Data node: data_node_2
                           Chunks: _dist_hyper_1_2_chunk
                           Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST
                     ->  Custom Scan (DataNodeScan) on public.hyper hyper_3
                           Output: hyper_3."time", hyper_3.device, hyper_3.temp
                           Data node: data_node_3
                           Chunks: _dist_hyper_1_3_chunk
                           Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST
(24 rows)


######### Constification and runtime push down of time-related functions

 tsl_override_current_timestamptz 
----------------------------------
 
(1 row)

                                                                                                                                                                     QUERY PLAN                                                                                                                                                                      
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit
   Output: hyper."time", hyper.device, (avg(hyper.temp))
   ->  GroupAggregate
         Output: hyper."time", hyper.device, avg(hyper.temp)
         Group Key: hyper."time", hyper.device
         ->  Custom Scan (AsyncAppend)
               Output: hyper."time", hyper.device, hyper.temp
               ->  Merge Append
                     Sort Key: hyper_1."time", hyper_1.device
                     ->  Custom Scan (DataNodeScan) on public.hyper hyper_1
                           Output: hyper_1."time", hyper_1.device, hyper_1.temp
                           Data node: data_node_1
                           Chunks: _dist_hyper_1_1_chunk
                           Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST
                     ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                           Output: hyper_2."time", hyper_2.device, hyper_2.temp
                           Data node: data_node_2
                           Chunks: _dist_hyper_1_2_chunk
                           Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST
                     ->  Custom Scan (DataNodeScan) on public.hyper hyper_3
                           Output: hyper_3."time", hyper_3.device, hyper_3.temp
                           Data node: data_node_3
                           Chunks: _dist_hyper_1_3_chunk
                           Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST
(24 rows)

                                                                                                                                                                     QUERY PLAN                                                                                                                                                                      
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit
   Output: hyper."time", hyper.device, (avg(hyper.temp))
   ->  GroupAggregate
         Output: hyper."time", hyper.device, avg(hyper.temp)
         Group Key: hyper."time", hyper.device
         ->  Custom Scan (AsyncAppend)
               Output: hyper."time", hyper.device, hyper.temp
               ->  Merge Append
                     Sort Key: hyper_1."time", hyper_1.device
                     ->  Custom Scan (DataNodeScan) on public.hyper hyper_1
                           Output: hyper_1."time", hyper_1.device, hyper_1.temp
                           Data node: data_node_1
                           Chunks: _dist_hyper_1_1_chunk
                           Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST
                     ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                           Output: hyper_2."time", hyper_2.device, hyper_2.temp
                           Data node: data_node_2
                           Chunks: _dist_hyper_1_2_chunk
                           Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST
                     ->  Custom Scan (DataNodeScan) on public.hyper hyper_3
                           Output: hyper_3."time", hyper_3.device, hyper_3.temp
                           Data node: data_node_3
                           Chunks: _dist_hyper_1_3_chunk
                           Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST
(24 rows)

 tsl_override_current_timestamptz 
----------------------------------
 
(1 row)

                                                                                                                                                                     QUERY PLAN                                                                                                                                                                      
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit
   Output: hyper."time", hyper.device, (avg(hyper.temp))
   ->  GroupAggregate
         Output: hyper."time", hyper.device, avg(hyper.temp)
         Group Key: hyper."time", hyper.device
         ->  Custom Scan (AsyncAppend)
               Output: hyper."time", hyper.device, hyper.temp
               ->  Merge Append
                     Sort Key: hyper_1."time", hyper_1.device
                     ->  Custom Scan (DataNodeScan) on public.hyper hyper_1
                           Output: hyper_1."time", hyper_1.device, hyper_1.temp
                           Data node: data_node_1
                           Chunks: _dist_hyper_1_1_chunk
                           Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST
                     ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                           Output: hyper_2."time", hyper_2.device, hyper_2.temp
                           Data node: data_node_2
                           Chunks: _dist_hyper_1_2_chunk
                           Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST
                     ->  Custom Scan (DataNodeScan) on public.hyper hyper_3
                           Output: hyper_3."time", hyper_3.device, hyper_3.temp
                           Data node: data_node_3
                           Chunks: _dist_hyper_1_3_chunk
                           Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND (("time" <= '2019-01-01 15:00:00-08'::timestamp with time zone)) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST
(24 rows)


######### LIMIT push down cases

EXPLAIN (verbose, costs off)
SELECT time, device
FROM hyper
ORDER BY 1,2
LIMIT 10
                                                                                                        QUERY PLAN                                                                                                        
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit
   Output: hyper."time", hyper.device
   ->  Custom Scan (AsyncAppend)
         Output: hyper."time", hyper.device
         ->  Merge Append
               Sort Key: hyper_1."time", hyper_1.device
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_1
                     Output: hyper_1."time", hyper_1.device
                     Data node: data_node_1
                     Chunks: _dist_hyper_1_1_chunk, _dist_hyper_1_4_chunk, _dist_hyper_1_8_chunk, _dist_hyper_1_12_chunk, _dist_hyper_1_13_chunk, _dist_hyper_1_15_chunk, _dist_hyper_1_17_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST LIMIT 10
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                     Output: hyper_2."time", hyper_2.device
                     Data node: data_node_2
                     Chunks: _dist_hyper_1_2_chunk, _dist_hyper_1_5_chunk, _dist_hyper_1_7_chunk, _dist_hyper_1_9_chunk, _dist_hyper_1_11_chunk, _dist_hyper_1_14_chunk, _dist_hyper_1_18_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST LIMIT 10
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_3
                     Output: hyper_3."time", hyper_3.device
                     Data node: data_node_3
                     Chunks: _dist_hyper_1_3_chunk, _dist_hyper_1_6_chunk, _dist_hyper_1_10_chunk, _dist_hyper_1_16_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4]) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST LIMIT 10
(21 rows)


######### LIMIT push down cases

EXPLAIN (verbose, costs off)
SELECT time, device
FROM hyper
ORDER BY 1,2
LIMIT 5
OFFSET 5
                                                                                                        QUERY PLAN                                                                                                        
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit
   Output: hyper."time", hyper.device
   ->  Custom Scan (AsyncAppend)
         Output: hyper."time", hyper.device
         ->  Merge Append
               Sort Key: hyper_1."time", hyper_1.device
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_1
                     Output: hyper_1."time", hyper_1.device
                     Data node: data_node_1
                     Chunks: _dist_hyper_1_1_chunk, _dist_hyper_1_4_chunk, _dist_hyper_1_8_chunk, _dist_hyper_1_12_chunk, _dist_hyper_1_13_chunk, _dist_hyper_1_15_chunk, _dist_hyper_1_17_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST LIMIT 10
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                     Output: hyper_2."time", hyper_2.device
                     Data node: data_node_2
                     Chunks: _dist_hyper_1_2_chunk, _dist_hyper_1_5_chunk, _dist_hyper_1_7_chunk, _dist_hyper_1_9_chunk, _dist_hyper_1_11_chunk, _dist_hyper_1_14_chunk, _dist_hyper_1_18_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST LIMIT 10
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_3
                     Output: hyper_3."time", hyper_3.device
                     Data node: data_node_3
                     Chunks: _dist_hyper_1_3_chunk, _dist_hyper_1_6_chunk, _dist_hyper_1_10_chunk, _dist_hyper_1_16_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4]) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST LIMIT 10
(21 rows)


######### LIMIT push down cases

EXPLAIN (verbose, costs off)
SELECT time, device
FROM hyper
ORDER BY 1,2
LIMIT 0
                                                                                                       QUERY PLAN                                                                                                        
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit
   Output: hyper."time", hyper.device
   ->  Custom Scan (AsyncAppend)
         Output: hyper."time", hyper.device
         ->  Merge Append
               Sort Key: hyper_1."time", hyper_1.device
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_1
                     Output: hyper_1."time", hyper_1.device
                     Data node: data_node_1
                     Chunks: _dist_hyper_1_1_chunk, _dist_hyper_1_4_chunk, _dist_hyper_1_8_chunk, _dist_hyper_1_12_chunk, _dist_hyper_1_13_chunk, _dist_hyper_1_15_chunk, _dist_hyper_1_17_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST LIMIT 1
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                     Output: hyper_2."time", hyper_2.device
                     Data node: data_node_2
                     Chunks: _dist_hyper_1_2_chunk, _dist_hyper_1_5_chunk, _dist_hyper_1_7_chunk, _dist_hyper_1_9_chunk, _dist_hyper_1_11_chunk, _dist_hyper_1_14_chunk, _dist_hyper_1_18_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST LIMIT 1
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_3
                     Output: hyper_3."time", hyper_3.device
                     Data node: data_node_3
                     Chunks: _dist_hyper_1_3_chunk, _dist_hyper_1_6_chunk, _dist_hyper_1_10_chunk, _dist_hyper_1_16_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4]) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST LIMIT 1
(21 rows)


######### LIMIT push down cases

EXPLAIN (verbose, costs off)
SELECT time, device
FROM hyper
ORDER BY 1,2
LIMIT extract(year from date '2000-01-01')
                                                                                                         QUERY PLAN                                                                                                         
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit
   Output: hyper."time", hyper.device
   ->  Custom Scan (AsyncAppend)
         Output: hyper."time", hyper.device
         ->  Merge Append
               Sort Key: hyper_1."time", hyper_1.device
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_1
                     Output: hyper_1."time", hyper_1.device
                     Data node: data_node_1
                     Chunks: _dist_hyper_1_1_chunk, _dist_hyper_1_4_chunk, _dist_hyper_1_8_chunk, _dist_hyper_1_12_chunk, _dist_hyper_1_13_chunk, _dist_hyper_1_15_chunk, _dist_hyper_1_17_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST LIMIT 2000
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                     Output: hyper_2."time", hyper_2.device
                     Data node: data_node_2
                     Chunks: _dist_hyper_1_2_chunk, _dist_hyper_1_5_chunk, _dist_hyper_1_7_chunk, _dist_hyper_1_9_chunk, _dist_hyper_1_11_chunk, _dist_hyper_1_14_chunk, _dist_hyper_1_18_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST LIMIT 2000
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_3
                     Output: hyper_3."time", hyper_3.device
                     Data node: data_node_3
                     Chunks: _dist_hyper_1_3_chunk, _dist_hyper_1_6_chunk, _dist_hyper_1_10_chunk, _dist_hyper_1_16_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4]) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST LIMIT 2000
(21 rows)


######### LIMIT push down cases

EXPLAIN (verbose, costs off)
SELECT time, device
FROM hyper
ORDER BY 1,2
LIMIT greatest(random(), 10.0)
                                                                                                   QUERY PLAN                                                                                                    
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit
   Output: hyper."time", hyper.device
   ->  Custom Scan (AsyncAppend)
         Output: hyper."time", hyper.device
         ->  Merge Append
               Sort Key: hyper_1."time", hyper_1.device
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_1
                     Output: hyper_1."time", hyper_1.device
                     Data node: data_node_1
                     Chunks: _dist_hyper_1_1_chunk, _dist_hyper_1_4_chunk, _dist_hyper_1_8_chunk, _dist_hyper_1_12_chunk, _dist_hyper_1_13_chunk, _dist_hyper_1_15_chunk, _dist_hyper_1_17_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                     Output: hyper_2."time", hyper_2.device
                     Data node: data_node_2
                     Chunks: _dist_hyper_1_2_chunk, _dist_hyper_1_5_chunk, _dist_hyper_1_7_chunk, _dist_hyper_1_9_chunk, _dist_hyper_1_11_chunk, _dist_hyper_1_14_chunk, _dist_hyper_1_18_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_3
                     Output: hyper_3."time", hyper_3.device
                     Data node: data_node_3
                     Chunks: _dist_hyper_1_3_chunk, _dist_hyper_1_6_chunk, _dist_hyper_1_10_chunk, _dist_hyper_1_16_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4]) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST
(21 rows)


######### LIMIT push down cases

EXPLAIN (verbose, costs off)
SELECT time, device, avg(temp) OVER (PARTITION BY device)
FROM hyper
ORDER BY 1,2
LIMIT 10
                                                                                                 QUERY PLAN                                                                                                  
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit
   Output: hyper."time", hyper.device, (avg(hyper.temp) OVER (?))
   ->  Sort
         Output: hyper."time", hyper.device, (avg(hyper.temp) OVER (?))
         Sort Key: hyper."time", hyper.device
         ->  WindowAgg
               Output: hyper."time", hyper.device, avg(hyper.temp) OVER (?)
               ->  Custom Scan (AsyncAppend)
                     Output: hyper.device, hyper."time", hyper.temp
                     ->  Merge Append
                           Sort Key: hyper_1.device
                           ->  Custom Scan (DataNodeScan) on public.hyper hyper_1
                                 Output: hyper_1.device, hyper_1."time", hyper_1.temp
                                 Data node: data_node_1
                                 Chunks: _dist_hyper_1_1_chunk, _dist_hyper_1_4_chunk, _dist_hyper_1_8_chunk, _dist_hyper_1_12_chunk, _dist_hyper_1_13_chunk, _dist_hyper_1_15_chunk, _dist_hyper_1_17_chunk
                                 Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) ORDER BY device ASC NULLS LAST
                           ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                                 Output: hyper_2.device, hyper_2."time", hyper_2.temp
                                 Data node: data_node_2
                                 Chunks: _dist_hyper_1_2_chunk, _dist_hyper_1_5_chunk, _dist_hyper_1_7_chunk, _dist_hyper_1_9_chunk, _dist_hyper_1_11_chunk, _dist_hyper_1_14_chunk, _dist_hyper_1_18_chunk
                                 Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) ORDER BY device ASC NULLS LAST
                           ->  Custom Scan (DataNodeScan) on public.hyper hyper_3
                                 Output: hyper_3.device, hyper_3."time", hyper_3.temp
                                 Data node: data_node_3
                                 Chunks: _dist_hyper_1_3_chunk, _dist_hyper_1_6_chunk, _dist_hyper_1_10_chunk, _dist_hyper_1_16_chunk
                                 Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4]) ORDER BY device ASC NULLS LAST
(26 rows)


######### LIMIT push down cases

EXPLAIN (verbose, costs off)
SELECT DISTINCT device, time
FROM hyper
ORDER BY 1,2
LIMIT 10
                                                                                                      QUERY PLAN                                                                                                       
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit
   Output: hyper.device, hyper."time"
   ->  Unique
         Output: hyper.device, hyper."time"
         ->  Custom Scan (AsyncAppend)
               Output: hyper.device, hyper."time"
               ->  Merge Append
                     Sort Key: hyper_1.device, hyper_1."time"
                     ->  Custom Scan (DataNodeScan) on public.hyper hyper_1
                           Output: hyper_1.device, hyper_1."time"
                           Data node: data_node_1
                           Chunks: _dist_hyper_1_1_chunk, _dist_hyper_1_4_chunk, _dist_hyper_1_8_chunk, _dist_hyper_1_12_chunk, _dist_hyper_1_13_chunk, _dist_hyper_1_15_chunk, _dist_hyper_1_17_chunk
                           Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) ORDER BY device ASC NULLS LAST, "time" ASC NULLS LAST
                     ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                           Output: hyper_2.device, hyper_2."time"
                           Data node: data_node_2
                           Chunks: _dist_hyper_1_2_chunk, _dist_hyper_1_5_chunk, _dist_hyper_1_7_chunk, _dist_hyper_1_9_chunk, _dist_hyper_1_11_chunk, _dist_hyper_1_14_chunk, _dist_hyper_1_18_chunk
                           Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) ORDER BY device ASC NULLS LAST, "time" ASC NULLS LAST
                     ->  Custom Scan (DataNodeScan) on public.hyper hyper_3
                           Output: hyper_3.device, hyper_3."time"
                           Data node: data_node_3
                           Chunks: _dist_hyper_1_3_chunk, _dist_hyper_1_6_chunk, _dist_hyper_1_10_chunk, _dist_hyper_1_16_chunk
                           Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4]) ORDER BY device ASC NULLS LAST, "time" ASC NULLS LAST
(23 rows)


######### LIMIT push down cases

EXPLAIN (verbose, costs off)
SELECT DISTINCT ON (device) device, time
FROM hyper
ORDER BY 1,2
LIMIT 10
                                                                                                      QUERY PLAN                                                                                                       
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit
   Output: hyper.device, hyper."time"
   ->  Unique
         Output: hyper.device, hyper."time"
         ->  Custom Scan (AsyncAppend)
               Output: hyper.device, hyper."time"
               ->  Merge Append
                     Sort Key: hyper_1.device, hyper_1."time"
                     ->  Custom Scan (DataNodeScan) on public.hyper hyper_1
                           Output: hyper_1.device, hyper_1."time"
                           Data node: data_node_1
                           Chunks: _dist_hyper_1_1_chunk, _dist_hyper_1_4_chunk, _dist_hyper_1_8_chunk, _dist_hyper_1_12_chunk, _dist_hyper_1_13_chunk, _dist_hyper_1_15_chunk, _dist_hyper_1_17_chunk
                           Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) ORDER BY device ASC NULLS LAST, "time" ASC NULLS LAST
                     ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                           Output: hyper_2.device, hyper_2."time"
                           Data node: data_node_2
                           Chunks: _dist_hyper_1_2_chunk, _dist_hyper_1_5_chunk, _dist_hyper_1_7_chunk, _dist_hyper_1_9_chunk, _dist_hyper_1_11_chunk, _dist_hyper_1_14_chunk, _dist_hyper_1_18_chunk
                           Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) ORDER BY device ASC NULLS LAST, "time" ASC NULLS LAST
                     ->  Custom Scan (DataNodeScan) on public.hyper hyper_3
                           Output: hyper_3.device, hyper_3."time"
                           Data node: data_node_3
                           Chunks: _dist_hyper_1_3_chunk, _dist_hyper_1_6_chunk, _dist_hyper_1_10_chunk, _dist_hyper_1_16_chunk
                           Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4]) ORDER BY device ASC NULLS LAST, "time" ASC NULLS LAST
(23 rows)


######### LIMIT push down cases

                                                                                              QUERY PLAN                                                                                               
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit
   Output: t."time"
   ->  Nested Loop
         Output: t."time"
         Join Filter: (t.device = join_test.device)
         ->  Custom Scan (AsyncAppend)
               Output: t."time", t.device
               ->  Append
                     ->  Custom Scan (DataNodeScan) on public.hyper t_1
                           Output: t_1."time", t_1.device
                           Data node: data_node_1
                           Chunks: _dist_hyper_1_1_chunk, _dist_hyper_1_4_chunk, _dist_hyper_1_8_chunk, _dist_hyper_1_12_chunk, _dist_hyper_1_13_chunk, _dist_hyper_1_15_chunk, _dist_hyper_1_17_chunk
                           Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7])
                     ->  Custom Scan (DataNodeScan) on public.hyper t_2
                           Output: t_2."time", t_2.device
                           Data node: data_node_2
                           Chunks: _dist_hyper_1_2_chunk, _dist_hyper_1_5_chunk, _dist_hyper_1_7_chunk, _dist_hyper_1_9_chunk, _dist_hyper_1_11_chunk, _dist_hyper_1_14_chunk, _dist_hyper_1_18_chunk
                           Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7])
                     ->  Custom Scan (DataNodeScan) on public.hyper t_3
                           Output: t_3."time", t_3.device
                           Data node: data_node_3
                           Chunks: _dist_hyper_1_3_chunk, _dist_hyper_1_6_chunk, _dist_hyper_1_10_chunk, _dist_hyper_1_16_chunk
                           Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4])
         ->  Materialize
               Output: join_test.device
               ->  Seq Scan on public.join_test
                     Output: join_test.device
(27 rows)

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% RUNNING TESTS on table: hyper
%%% PREFIX: EXPLAIN (verbose, costs off)
%%% WHERE_CLAUSE: :REPARTITIONED_TIME_RANGE
%%% ORDER_BY_1: 
%%% ORDER_BY_1_2: ORDER BY 1,2
%%% LIMIT: 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
 setseed 
---------
 
(1 row)


######### Grouping on time only (partial aggregation)

EXPLAIN (verbose, costs off)
SELECT time, avg(temp)
FROM hyper
WHERE time >= '2019-01-01'
GROUP BY 1


                                                                                                                                     QUERY PLAN                                                                                                                                     
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Finalize HashAggregate
   Output: "time", avg(temp)
   Group Key: "time"
   ->  Custom Scan (AsyncAppend)
         Output: "time", (PARTIAL avg(temp))
         ->  Append
               ->  Custom Scan (DataNodeScan)
                     Output: hyper."time", (PARTIAL avg(hyper.temp))
                     Relations: Aggregate on (public.hyper)
                     Data node: data_node_1
                     Chunks: _dist_hyper_1_8_chunk, _dist_hyper_1_12_chunk, _dist_hyper_1_17_chunk, _dist_hyper_1_1_chunk, _dist_hyper_1_15_chunk, _dist_hyper_1_4_chunk, _dist_hyper_1_13_chunk
                     Remote SQL: SELECT "time", _timescaledb_internal.partialize_agg(avg(temp)) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[3, 4, 7, 1, 6, 2, 5]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) GROUP BY 1
               ->  Custom Scan (DataNodeScan)
                     Output: hyper_1."time", (PARTIAL avg(hyper_1.temp))
                     Relations: Aggregate on (public.hyper)
                     Data node: data_node_2
                     Chunks: _dist_hyper_1_14_chunk, _dist_hyper_1_11_chunk, _dist_hyper_1_18_chunk, _dist_hyper_1_2_chunk, _dist_hyper_1_5_chunk, _dist_hyper_1_9_chunk, _dist_hyper_1_7_chunk
                     Remote SQL: SELECT "time", _timescaledb_internal.partialize_agg(avg(temp)) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[6, 5, 7, 1, 2, 4, 3]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) GROUP BY 1
               ->  Custom Scan (DataNodeScan)
                     Output: hyper_2."time", (PARTIAL avg(hyper_2.temp))
                     Relations: Aggregate on (public.hyper)
                     Data node: data_node_3
                     Chunks: _dist_hyper_1_10_chunk, _dist_hyper_1_16_chunk, _dist_hyper_1_6_chunk, _dist_hyper_1_3_chunk
                     Remote SQL: SELECT "time", _timescaledb_internal.partialize_agg(avg(temp)) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[3, 4, 2, 1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) GROUP BY 1
(24 rows)


######### Grouping on time only (partial aggregation)

EXPLAIN (verbose, costs off)
SELECT time_bucket('2 days', time) AS time, avg(temp)
FROM hyper
WHERE time >= '2019-01-01'
GROUP BY 1


                                                                                                                                                          QUERY PLAN                                                                                                                                                          
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Finalize HashAggregate
   Output: (time_bucket('@ 2 days'::interval, "time")), avg(temp)
   Group Key: (time_bucket('@ 2 days'::interval, "time"))
   ->  Custom Scan (AsyncAppend)
         Output: (time_bucket('@ 2 days'::interval, "time")), (PARTIAL avg(temp))
         ->  Append
               ->  Custom Scan (DataNodeScan)
                     Output: (time_bucket('@ 2 days'::interval, hyper."time")), (PARTIAL avg(hyper.temp))
                     Relations: Aggregate on (public.hyper)
                     Data node: data_node_1
                     Chunks: _dist_hyper_1_8_chunk, _dist_hyper_1_12_chunk, _dist_hyper_1_17_chunk, _dist_hyper_1_1_chunk, _dist_hyper_1_15_chunk, _dist_hyper_1_4_chunk, _dist_hyper_1_13_chunk
                     Remote SQL: SELECT public.time_bucket('@ 2 days'::interval, "time"), _timescaledb_internal.partialize_agg(avg(temp)) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[3, 4, 7, 1, 6, 2, 5]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) GROUP BY 1
               ->  Custom Scan (DataNodeScan)
                     Output: (time_bucket('@ 2 days'::interval, hyper_1."time")), (PARTIAL avg(hyper_1.temp))
                     Relations: Aggregate on (public.hyper)
                     Data node: data_node_2
                     Chunks: _dist_hyper_1_14_chunk, _dist_hyper_1_11_chunk, _dist_hyper_1_18_chunk, _dist_hyper_1_2_chunk, _dist_hyper_1_5_chunk, _dist_hyper_1_9_chunk, _dist_hyper_1_7_chunk
                     Remote SQL: SELECT public.time_bucket('@ 2 days'::interval, "time"), _timescaledb_internal.partialize_agg(avg(temp)) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[6, 5, 7, 1, 2, 4, 3]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) GROUP BY 1
               ->  Custom Scan (DataNodeScan)
                     Output: (time_bucket('@ 2 days'::interval, hyper_2."time")), (PARTIAL avg(hyper_2.temp))
                     Relations: Aggregate on (public.hyper)
                     Data node: data_node_3
                     Chunks: _dist_hyper_1_10_chunk, _dist_hyper_1_16_chunk, _dist_hyper_1_6_chunk, _dist_hyper_1_3_chunk
                     Remote SQL: SELECT public.time_bucket('@ 2 days'::interval, "time"), _timescaledb_internal.partialize_agg(avg(temp)) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[3, 4, 2, 1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) GROUP BY 1
(24 rows)


######### Grouping on time and device (full aggregation)

EXPLAIN (verbose, costs off)
SELECT time, device, avg(temp)
FROM hyper
WHERE time >= '2019-01-01'
GROUP BY 1,2
ORDER BY 1,2

                                                                                                                                               QUERY PLAN                                                                                                                                                
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Custom Scan (AsyncAppend)
   Output: "time", device, (avg(temp))
   ->  Merge Append
         Sort Key: hyper."time", hyper.device
         ->  Custom Scan (DataNodeScan)
               Output: hyper."time", hyper.device, (avg(hyper.temp))
               Relations: Aggregate on (public.hyper)
               Data node: data_node_1
               Chunks: _dist_hyper_1_1_chunk, _dist_hyper_1_4_chunk, _dist_hyper_1_8_chunk, _dist_hyper_1_12_chunk, _dist_hyper_1_13_chunk, _dist_hyper_1_15_chunk, _dist_hyper_1_17_chunk
               Remote SQL: SELECT "time", device, avg(temp) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) GROUP BY 1, 2 ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST
         ->  Custom Scan (DataNodeScan)
               Output: hyper_1."time", hyper_1.device, (avg(hyper_1.temp))
               Relations: Aggregate on (public.hyper)
               Data node: data_node_2
               Chunks: _dist_hyper_1_2_chunk, _dist_hyper_1_5_chunk, _dist_hyper_1_7_chunk, _dist_hyper_1_9_chunk, _dist_hyper_1_11_chunk, _dist_hyper_1_14_chunk, _dist_hyper_1_18_chunk
               Remote SQL: SELECT "time", device, avg(temp) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) GROUP BY 1, 2 ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST
         ->  Custom Scan (DataNodeScan)
               Output: hyper_2."time", hyper_2.device, (avg(hyper_2.temp))
               Relations: Aggregate on (public.hyper)
               Data node: data_node_3
               Chunks: _dist_hyper_1_3_chunk, _dist_hyper_1_6_chunk, _dist_hyper_1_10_chunk, _dist_hyper_1_16_chunk
               Remote SQL: SELECT "time", device, avg(temp) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) GROUP BY 1, 2 ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST
(22 rows)


######### Grouping on time and device (full aggregation)

EXPLAIN (verbose, costs off)
SELECT time_bucket('2 days', time) AS time, device, avg(temp)
FROM hyper
WHERE time >= '2019-01-01'
GROUP BY 1,2
ORDER BY 1,2

                                                                                                                                                                                                              QUERY PLAN                                                                                                                                                                                                               
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Finalize GroupAggregate
   Output: (time_bucket('@ 2 days'::interval, "time")), device, avg(temp)
   Group Key: (time_bucket('@ 2 days'::interval, "time")), device
   ->  Custom Scan (AsyncAppend)
         Output: (time_bucket('@ 2 days'::interval, "time")), device, (PARTIAL avg(temp))
         ->  Merge Append
               Sort Key: (time_bucket('@ 2 days'::interval, hyper."time")), hyper.device
               ->  Custom Scan (DataNodeScan)
                     Output: (time_bucket('@ 2 days'::interval, hyper."time")), hyper.device, (PARTIAL avg(hyper.temp))
                     Relations: Aggregate on (public.hyper)
                     Data node: data_node_1
                     Chunks: _dist_hyper_1_8_chunk, _dist_hyper_1_12_chunk, _dist_hyper_1_17_chunk, _dist_hyper_1_1_chunk, _dist_hyper_1_15_chunk, _dist_hyper_1_4_chunk, _dist_hyper_1_13_chunk
                     Remote SQL: SELECT public.time_bucket('@ 2 days'::interval, "time"), device, _timescaledb_internal.partialize_agg(avg(temp)) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[3, 4, 7, 1, 6, 2, 5]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) GROUP BY 1, 2 ORDER BY public.time_bucket('2 days'::interval, "time") ASC NULLS LAST, device ASC NULLS LAST
               ->  Custom Scan (DataNodeScan)
                     Output: (time_bucket('@ 2 days'::interval, hyper_1."time")), hyper_1.device, (PARTIAL avg(hyper_1.temp))
                     Relations: Aggregate on (public.hyper)
                     Data node: data_node_2
                     Chunks: _dist_hyper_1_14_chunk, _dist_hyper_1_11_chunk, _dist_hyper_1_18_chunk, _dist_hyper_1_2_chunk, _dist_hyper_1_5_chunk, _dist_hyper_1_9_chunk, _dist_hyper_1_7_chunk
                     Remote SQL: SELECT public.time_bucket('@ 2 days'::interval, "time"), device, _timescaledb_internal.partialize_agg(avg(temp)) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[6, 5, 7, 1, 2, 4, 3]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) GROUP BY 1, 2 ORDER BY public.time_bucket('2 days'::interval, "time") ASC NULLS LAST, device ASC NULLS LAST
               ->  Custom Scan (DataNodeScan)
                     Output: (time_bucket('@ 2 days'::interval, hyper_2."time")), hyper_2.device, (PARTIAL avg(hyper_2.temp))
                     Relations: Aggregate on (public.hyper)
                     Data node: data_node_3
                     Chunks: _dist_hyper_1_10_chunk, _dist_hyper_1_16_chunk, _dist_hyper_1_6_chunk, _dist_hyper_1_3_chunk
                     Remote SQL: SELECT public.time_bucket('@ 2 days'::interval, "time"), device, _timescaledb_internal.partialize_agg(avg(temp)) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[3, 4, 2, 1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) GROUP BY 1, 2 ORDER BY public.time_bucket('2 days'::interval, "time") ASC NULLS LAST, device ASC NULLS LAST
(25 rows)


######### Grouping on time and device (full aggregation)

EXPLAIN (verbose, costs off)
SELECT date_trunc('month', time) AS time, device, avg(temp)
FROM hyper
WHERE time >= '2019-01-01'
GROUP BY 1,2
ORDER BY 1,2

                                                                                                                                                                                                QUERY PLAN                                                                                                                                                                                                 
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Finalize GroupAggregate
   Output: (date_trunc('month'::text, "time")), device, avg(temp)
   Group Key: (date_trunc('month'::text, "time")), device
   ->  Custom Scan (AsyncAppend)
         Output: (date_trunc('month'::text, "time")), device, (PARTIAL avg(temp))
         ->  Merge Append
               Sort Key: (date_trunc('month'::text, hyper."time")), hyper.device
               ->  Custom Scan (DataNodeScan)
                     Output: (date_trunc('month'::text, hyper."time")), hyper.device, (PARTIAL avg(hyper.temp))
                     Relations: Aggregate on (public.hyper)
                     Data node: data_node_1
                     Chunks: _dist_hyper_1_8_chunk, _dist_hyper_1_12_chunk, _dist_hyper_1_17_chunk, _dist_hyper_1_1_chunk, _dist_hyper_1_15_chunk, _dist_hyper_1_4_chunk, _dist_hyper_1_13_chunk
                     Remote SQL: SELECT date_trunc('month'::text, "time"), device, _timescaledb_internal.partialize_agg(avg(temp)) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[3, 4, 7, 1, 6, 2, 5]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) GROUP BY 1, 2 ORDER BY date_trunc('month'::text, "time") ASC NULLS LAST, device ASC NULLS LAST
               ->  Custom Scan (DataNodeScan)
                     Output: (date_trunc('month'::text, hyper_1."time")), hyper_1.device, (PARTIAL avg(hyper_1.temp))
                     Relations: Aggregate on (public.hyper)
                     Data node: data_node_2
                     Chunks: _dist_hyper_1_14_chunk, _dist_hyper_1_11_chunk, _dist_hyper_1_18_chunk, _dist_hyper_1_2_chunk, _dist_hyper_1_5_chunk, _dist_hyper_1_9_chunk, _dist_hyper_1_7_chunk
                     Remote SQL: SELECT date_trunc('month'::text, "time"), device, _timescaledb_internal.partialize_agg(avg(temp)) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[6, 5, 7, 1, 2, 4, 3]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) GROUP BY 1, 2 ORDER BY date_trunc('month'::text, "time") ASC NULLS LAST, device ASC NULLS LAST
               ->  Custom Scan (DataNodeScan)
                     Output: (date_trunc('month'::text, hyper_2."time")), hyper_2.device, (PARTIAL avg(hyper_2.temp))
                     Relations: Aggregate on (public.hyper)
                     Data node: data_node_3
                     Chunks: _dist_hyper_1_10_chunk, _dist_hyper_1_16_chunk, _dist_hyper_1_6_chunk, _dist_hyper_1_3_chunk
                     Remote SQL: SELECT date_trunc('month'::text, "time"), device, _timescaledb_internal.partialize_agg(avg(temp)) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[3, 4, 2, 1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) GROUP BY 1, 2 ORDER BY date_trunc('month'::text, "time") ASC NULLS LAST, device ASC NULLS LAST
(25 rows)


######### Grouping on time and device (full aggregation)

EXPLAIN (verbose, costs off)
SELECT time_bucket('2 days', time) AS time, device, avg(temp)
FROM hyper
WHERE time >= '2019-01-01'
GROUP BY 1,2
HAVING device > 4
ORDER BY 1,2

                                                                                                                                                                                                                        QUERY PLAN                                                                                                                                                                                                                        
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Finalize GroupAggregate
   Output: (time_bucket('@ 2 days'::interval, "time")), device, avg(temp)
   Group Key: (time_bucket('@ 2 days'::interval, "time")), device
   ->  Custom Scan (AsyncAppend)
         Output: (time_bucket('@ 2 days'::interval, "time")), device, (PARTIAL avg(temp))
         ->  Merge Append
               Sort Key: (time_bucket('@ 2 days'::interval, hyper."time")), hyper.device
               ->  Custom Scan (DataNodeScan)
                     Output: (time_bucket('@ 2 days'::interval, hyper."time")), hyper.device, (PARTIAL avg(hyper.temp))
                     Relations: Aggregate on (public.hyper)
                     Data node: data_node_1
                     Chunks: _dist_hyper_1_8_chunk, _dist_hyper_1_12_chunk, _dist_hyper_1_17_chunk, _dist_hyper_1_1_chunk, _dist_hyper_1_15_chunk, _dist_hyper_1_4_chunk, _dist_hyper_1_13_chunk
                     Remote SQL: SELECT public.time_bucket('@ 2 days'::interval, "time"), device, _timescaledb_internal.partialize_agg(avg(temp)) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[3, 4, 7, 1, 6, 2, 5]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND ((device > 4)) GROUP BY 1, 2 ORDER BY public.time_bucket('2 days'::interval, "time") ASC NULLS LAST, device ASC NULLS LAST
               ->  Custom Scan (DataNodeScan)
                     Output: (time_bucket('@ 2 days'::interval, hyper_1."time")), hyper_1.device, (PARTIAL avg(hyper_1.temp))
                     Relations: Aggregate on (public.hyper)
                     Data node: data_node_2
                     Chunks: _dist_hyper_1_14_chunk, _dist_hyper_1_11_chunk, _dist_hyper_1_18_chunk, _dist_hyper_1_2_chunk, _dist_hyper_1_5_chunk, _dist_hyper_1_9_chunk, _dist_hyper_1_7_chunk
                     Remote SQL: SELECT public.time_bucket('@ 2 days'::interval, "time"), device, _timescaledb_internal.partialize_agg(avg(temp)) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[6, 5, 7, 1, 2, 4, 3]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND ((device > 4)) GROUP BY 1, 2 ORDER BY public.time_bucket('2 days'::interval, "time") ASC NULLS LAST, device ASC NULLS LAST
               ->  Custom Scan (DataNodeScan)
                     Output: (time_bucket('@ 2 days'::interval, hyper_2."time")), hyper_2.device, (PARTIAL avg(hyper_2.temp))
                     Relations: Aggregate on (public.hyper)
                     Data node: data_node_3
                     Chunks: _dist_hyper_1_10_chunk, _dist_hyper_1_16_chunk, _dist_hyper_1_6_chunk, _dist_hyper_1_3_chunk
                     Remote SQL: SELECT public.time_bucket('@ 2 days'::interval, "time"), device, _timescaledb_internal.partialize_agg(avg(temp)) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[3, 4, 2, 1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND ((device > 4)) GROUP BY 1, 2 ORDER BY public.time_bucket('2 days'::interval, "time") ASC NULLS LAST, device ASC NULLS LAST
(25 rows)

EXPLAIN (verbose, costs off)
SELECT time_bucket('2 days', time) AS time, device, avg(temp)
FROM hyper
WHERE time >= '2019-01-01'
GROUP BY 1,2
HAVING avg(temp) > 40 AND max(temp) < 70
ORDER BY 1,2

                                                                                                                                                                                           QUERY PLAN                                                                                                                                                                                           
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Sort
   Output: (time_bucket('@ 2 days'::interval, "time")), device, (avg(temp))
   Sort Key: (time_bucket('@ 2 days'::interval, "time")), device
   ->  Finalize HashAggregate
         Output: (time_bucket('@ 2 days'::interval, "time")), device, avg(temp)
         Group Key: (time_bucket('@ 2 days'::interval, "time")), device
         Filter: ((avg(temp) > '40'::double precision) AND (max(temp) < '70'::double precision))
         ->  Custom Scan (AsyncAppend)
               Output: (time_bucket('@ 2 days'::interval, "time")), device, (PARTIAL avg(temp)), (PARTIAL max(temp))
               ->  Append
                     ->  Custom Scan (DataNodeScan)
                           Output: (time_bucket('@ 2 days'::interval, hyper."time")), hyper.device, (PARTIAL avg(hyper.temp)), (PARTIAL max(hyper.temp))
                           Relations: Aggregate on (public.hyper)
                           Data node: data_node_1
                           Chunks: _dist_hyper_1_8_chunk, _dist_hyper_1_12_chunk, _dist_hyper_1_17_chunk, _dist_hyper_1_1_chunk, _dist_hyper_1_15_chunk, _dist_hyper_1_4_chunk, _dist_hyper_1_13_chunk
                           Remote SQL: SELECT public.time_bucket('@ 2 days'::interval, "time"), device, _timescaledb_internal.partialize_agg(avg(temp)), _timescaledb_internal.partialize_agg(max(temp)) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[3, 4, 7, 1, 6, 2, 5]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) GROUP BY 1, 2
                     ->  Custom Scan (DataNodeScan)
                           Output: (time_bucket('@ 2 days'::interval, hyper_1."time")), hyper_1.device, (PARTIAL avg(hyper_1.temp)), (PARTIAL max(hyper_1.temp))
                           Relations: Aggregate on (public.hyper)
                           Data node: data_node_2
                           Chunks: _dist_hyper_1_14_chunk, _dist_hyper_1_11_chunk, _dist_hyper_1_18_chunk, _dist_hyper_1_2_chunk, _dist_hyper_1_5_chunk, _dist_hyper_1_9_chunk, _dist_hyper_1_7_chunk
                           Remote SQL: SELECT public.time_bucket('@ 2 days'::interval, "time"), device, _timescaledb_internal.partialize_agg(avg(temp)), _timescaledb_internal.partialize_agg(max(temp)) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[6, 5, 7, 1, 2, 4, 3]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) GROUP BY 1, 2
                     ->  Custom Scan (DataNodeScan)
                           Output: (time_bucket('@ 2 days'::interval, hyper_2."time")), hyper_2.device, (PARTIAL avg(hyper_2.temp)), (PARTIAL max(hyper_2.temp))
                           Relations: Aggregate on (public.hyper)
                           Data node: data_node_3
                           Chunks: _dist_hyper_1_10_chunk, _dist_hyper_1_16_chunk, _dist_hyper_1_6_chunk, _dist_hyper_1_3_chunk
                           Remote SQL: SELECT public.time_bucket('@ 2 days'::interval, "time"), device, _timescaledb_internal.partialize_agg(avg(temp)), _timescaledb_internal.partialize_agg(max(temp)) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[3, 4, 2, 1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) GROUP BY 1, 2
(28 rows)


######### Grouping on device only (full aggregation)

EXPLAIN (verbose, costs off)
SELECT device, avg(temp)
FROM hyper
WHERE time >= '2019-01-01'
GROUP BY 1


                                                                                                                                     QUERY PLAN                                                                                                                                     
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Finalize HashAggregate
   Output: device, avg(temp)
   Group Key: device
   ->  Custom Scan (AsyncAppend)
         Output: device, (PARTIAL avg(temp))
         ->  Append
               ->  Custom Scan (DataNodeScan)
                     Output: hyper.device, (PARTIAL avg(hyper.temp))
                     Relations: Aggregate on (public.hyper)
                     Data node: data_node_1
                     Chunks: _dist_hyper_1_8_chunk, _dist_hyper_1_12_chunk, _dist_hyper_1_17_chunk, _dist_hyper_1_1_chunk, _dist_hyper_1_15_chunk, _dist_hyper_1_4_chunk, _dist_hyper_1_13_chunk
                     Remote SQL: SELECT device, _timescaledb_internal.partialize_agg(avg(temp)) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[3, 4, 7, 1, 6, 2, 5]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) GROUP BY 1
               ->  Custom Scan (DataNodeScan)
                     Output: hyper_1.device, (PARTIAL avg(hyper_1.temp))
                     Relations: Aggregate on (public.hyper)
                     Data node: data_node_2
                     Chunks: _dist_hyper_1_14_chunk, _dist_hyper_1_11_chunk, _dist_hyper_1_18_chunk, _dist_hyper_1_2_chunk, _dist_hyper_1_5_chunk, _dist_hyper_1_9_chunk, _dist_hyper_1_7_chunk
                     Remote SQL: SELECT device, _timescaledb_internal.partialize_agg(avg(temp)) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[6, 5, 7, 1, 2, 4, 3]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) GROUP BY 1
               ->  Custom Scan (DataNodeScan)
                     Output: hyper_2.device, (PARTIAL avg(hyper_2.temp))
                     Relations: Aggregate on (public.hyper)
                     Data node: data_node_3
                     Chunks: _dist_hyper_1_10_chunk, _dist_hyper_1_16_chunk, _dist_hyper_1_6_chunk, _dist_hyper_1_3_chunk
                     Remote SQL: SELECT device, _timescaledb_internal.partialize_agg(avg(temp)) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[3, 4, 2, 1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) GROUP BY 1
(24 rows)


######### No push down on some functions

EXPLAIN (verbose, costs off)
SELECT location, avg(temp)
FROM hyper
WHERE time >= '2019-01-01' AND (temp * random() >= 0)
GROUP BY 1


                                                                                                                       QUERY PLAN                                                                                                                       
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 HashAggregate
   Output: hyper.location, avg(hyper.temp)
   Group Key: hyper.location
   ->  Custom Scan (AsyncAppend)
         Output: hyper.location, hyper.temp
         ->  Append
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_1
                     Output: hyper_1.location, hyper_1.temp
                     Filter: ((hyper_1.temp * random()) >= '0'::double precision)
                     Data node: data_node_1
                     Chunks: _dist_hyper_1_8_chunk, _dist_hyper_1_12_chunk, _dist_hyper_1_17_chunk, _dist_hyper_1_1_chunk, _dist_hyper_1_15_chunk, _dist_hyper_1_4_chunk, _dist_hyper_1_13_chunk
                     Remote SQL: SELECT location, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[3, 4, 7, 1, 6, 2, 5]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone))
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                     Output: hyper_2.location, hyper_2.temp
                     Filter: ((hyper_2.temp * random()) >= '0'::double precision)
                     Data node: data_node_2
                     Chunks: _dist_hyper_1_14_chunk, _dist_hyper_1_11_chunk, _dist_hyper_1_18_chunk, _dist_hyper_1_2_chunk, _dist_hyper_1_5_chunk, _dist_hyper_1_9_chunk, _dist_hyper_1_7_chunk
                     Remote SQL: SELECT location, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[6, 5, 7, 1, 2, 4, 3]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone))
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_3
                     Output: hyper_3.location, hyper_3.temp
                     Filter: ((hyper_3.temp * random()) >= '0'::double precision)
                     Data node: data_node_3
                     Chunks: _dist_hyper_1_10_chunk, _dist_hyper_1_16_chunk, _dist_hyper_1_6_chunk, _dist_hyper_1_3_chunk
                     Remote SQL: SELECT location, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[3, 4, 2, 1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) ORDER BY location ASC NULLS LAST
(24 rows)


######### No push down on some functions

EXPLAIN (verbose, costs off)
SELECT time_bucket('2 days', time) AS time, device, avg(temp), sum(temp * (random() <= 1)::int) as sum
FROM hyper
WHERE time >= '2019-01-01'
GROUP BY 1,2
ORDER BY 1,2

                                                                                                                                                             QUERY PLAN                                                                                                                                                             
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Finalize GroupAggregate
   Output: (time_bucket('@ 2 days'::interval, hyper."time")), hyper.device, avg(hyper.temp), sum((hyper.temp * (((random() <= '1'::double precision))::integer)::double precision))
   Group Key: (time_bucket('@ 2 days'::interval, hyper."time")), hyper.device
   ->  Merge Append
         Sort Key: (time_bucket('@ 2 days'::interval, hyper."time")), hyper.device
         ->  Partial GroupAggregate
               Output: (time_bucket('@ 2 days'::interval, hyper."time")), hyper.device, PARTIAL avg(hyper.temp), PARTIAL sum((hyper.temp * (((random() <= '1'::double precision))::integer)::double precision))
               Group Key: time_bucket('@ 2 days'::interval, hyper."time"), hyper.device
               ->  Custom Scan (DataNodeScan) on public.hyper
                     Output: time_bucket('@ 2 days'::interval, hyper."time"), hyper.device, hyper.temp
                     Data node: data_node_1
                     Chunks: _dist_hyper_1_8_chunk, _dist_hyper_1_12_chunk, _dist_hyper_1_17_chunk, _dist_hyper_1_1_chunk, _dist_hyper_1_15_chunk, _dist_hyper_1_4_chunk, _dist_hyper_1_13_chunk
                     Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[3, 4, 7, 1, 6, 2, 5]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) ORDER BY public.time_bucket('2 days'::interval, "time") ASC NULLS LAST, device ASC NULLS LAST
         ->  Partial GroupAggregate
               Output: (time_bucket('@ 2 days'::interval, hyper_1."time")), hyper_1.device, PARTIAL avg(hyper_1.temp), PARTIAL sum((hyper_1.temp * (((random() <= '1'::double precision))::integer)::double precision))
               Group Key: time_bucket('@ 2 days'::interval, hyper_1."time"), hyper_1.device
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_1
                     Output: time_bucket('@ 2 days'::interval, hyper_1."time"), hyper_1.device, hyper_1.temp
                     Data node: data_node_2
                     Chunks: _dist_hyper_1_14_chunk, _dist_hyper_1_11_chunk, _dist_hyper_1_18_chunk, _dist_hyper_1_2_chunk, _dist_hyper_1_5_chunk, _dist_hyper_1_9_chunk, _dist_hyper_1_7_chunk
                     Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[6, 5, 7, 1, 2, 4, 3]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) ORDER BY public.time_bucket('2 days'::interval, "time") ASC NULLS LAST, device ASC NULLS LAST
         ->  Partial GroupAggregate
               Output: (time_bucket('@ 2 days'::interval, hyper_2."time")), hyper_2.device, PARTIAL avg(hyper_2.temp), PARTIAL sum((hyper_2.temp * (((random() <= '1'::double precision))::integer)::double precision))
               Group Key: time_bucket('@ 2 days'::interval, hyper_2."time"), hyper_2.device
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                     Output: time_bucket('@ 2 days'::interval, hyper_2."time"), hyper_2.device, hyper_2.temp
                     Data node: data_node_3
                     Chunks: _dist_hyper_1_10_chunk, _dist_hyper_1_16_chunk, _dist_hyper_1_6_chunk, _dist_hyper_1_3_chunk
                     Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[3, 4, 2, 1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) ORDER BY public.time_bucket('2 days'::interval, "time") ASC NULLS LAST, device ASC NULLS LAST
(29 rows)


######### No push down on some functions

EXPLAIN (verbose, costs off)
SELECT time, device, avg(temp)
FROM hyper
WHERE time >= '2019-01-01'
GROUP BY 1,2
HAVING avg(temp) * custom_sum(device) > 0.8
ORDER BY 1,2

                                                                                                                                         QUERY PLAN                                                                                                                                         
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Custom Scan (AsyncAppend)
   Output: "time", device, (avg(temp))
   ->  Merge Append
         Sort Key: hyper."time", hyper.device
         ->  GroupAggregate
               Output: hyper."time", hyper.device, avg(hyper.temp)
               Group Key: hyper."time", hyper.device
               Filter: ((avg(hyper.temp) * (custom_sum(hyper.device))::double precision) > '0.8'::double precision)
               ->  Custom Scan (DataNodeScan) on public.hyper
                     Output: hyper."time", hyper.device, hyper.temp
                     Data node: data_node_1
                     Chunks: _dist_hyper_1_1_chunk, _dist_hyper_1_4_chunk, _dist_hyper_1_8_chunk, _dist_hyper_1_12_chunk, _dist_hyper_1_13_chunk, _dist_hyper_1_15_chunk, _dist_hyper_1_17_chunk
                     Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST
         ->  GroupAggregate
               Output: hyper_1."time", hyper_1.device, avg(hyper_1.temp)
               Group Key: hyper_1."time", hyper_1.device
               Filter: ((avg(hyper_1.temp) * (custom_sum(hyper_1.device))::double precision) > '0.8'::double precision)
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_1
                     Output: hyper_1."time", hyper_1.device, hyper_1.temp
                     Data node: data_node_2
                     Chunks: _dist_hyper_1_2_chunk, _dist_hyper_1_5_chunk, _dist_hyper_1_7_chunk, _dist_hyper_1_9_chunk, _dist_hyper_1_11_chunk, _dist_hyper_1_14_chunk, _dist_hyper_1_18_chunk
                     Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST
         ->  GroupAggregate
               Output: hyper_2."time", hyper_2.device, avg(hyper_2.temp)
               Group Key: hyper_2."time", hyper_2.device
               Filter: ((avg(hyper_2.temp) * (custom_sum(hyper_2.device))::double precision) > '0.8'::double precision)
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                     Output: hyper_2."time", hyper_2.device, hyper_2.temp
                     Data node: data_node_3
                     Chunks: _dist_hyper_1_3_chunk, _dist_hyper_1_6_chunk, _dist_hyper_1_10_chunk, _dist_hyper_1_16_chunk
                     Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST
(31 rows)


######### No push down on some functions

EXPLAIN (verbose, costs off)
SELECT time, device, avg(temp), custom_sum(device)
FROM hyper
WHERE time >= '2019-01-01'
GROUP BY 1,2
ORDER BY 1,2

                                                                                                                                         QUERY PLAN                                                                                                                                         
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Custom Scan (AsyncAppend)
   Output: "time", device, (avg(temp)), (custom_sum(device))
   ->  Merge Append
         Sort Key: hyper."time", hyper.device
         ->  GroupAggregate
               Output: hyper."time", hyper.device, avg(hyper.temp), custom_sum(hyper.device)
               Group Key: hyper."time", hyper.device
               ->  Custom Scan (DataNodeScan) on public.hyper
                     Output: hyper."time", hyper.device, hyper.temp
                     Data node: data_node_1
                     Chunks: _dist_hyper_1_1_chunk, _dist_hyper_1_4_chunk, _dist_hyper_1_8_chunk, _dist_hyper_1_12_chunk, _dist_hyper_1_13_chunk, _dist_hyper_1_15_chunk, _dist_hyper_1_17_chunk
                     Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST
         ->  GroupAggregate
               Output: hyper_1."time", hyper_1.device, avg(hyper_1.temp), custom_sum(hyper_1.device)
               Group Key: hyper_1."time", hyper_1.device
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_1
                     Output: hyper_1."time", hyper_1.device, hyper_1.temp
                     Data node: data_node_2
                     Chunks: _dist_hyper_1_2_chunk, _dist_hyper_1_5_chunk, _dist_hyper_1_7_chunk, _dist_hyper_1_9_chunk, _dist_hyper_1_11_chunk, _dist_hyper_1_14_chunk, _dist_hyper_1_18_chunk
                     Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST
         ->  GroupAggregate
               Output: hyper_2."time", hyper_2.device, avg(hyper_2.temp), custom_sum(hyper_2.device)
               Group Key: hyper_2."time", hyper_2.device
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                     Output: hyper_2."time", hyper_2.device, hyper_2.temp
                     Data node: data_node_3
                     Chunks: _dist_hyper_1_3_chunk, _dist_hyper_1_6_chunk, _dist_hyper_1_10_chunk, _dist_hyper_1_16_chunk
                     Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST
(28 rows)


######### Constification and runtime push down of time-related functions

 tsl_override_current_timestamptz 
----------------------------------
 
(1 row)

                                                                                                                                               QUERY PLAN                                                                                                                                                
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Custom Scan (AsyncAppend)
   Output: "time", device, (avg(temp))
   ->  Merge Append
         Sort Key: hyper."time", hyper.device
         ->  Custom Scan (DataNodeScan)
               Output: hyper."time", hyper.device, (avg(hyper.temp))
               Relations: Aggregate on (public.hyper)
               Data node: data_node_1
               Chunks: _dist_hyper_1_1_chunk, _dist_hyper_1_4_chunk, _dist_hyper_1_8_chunk, _dist_hyper_1_12_chunk, _dist_hyper_1_13_chunk, _dist_hyper_1_15_chunk, _dist_hyper_1_17_chunk
               Remote SQL: SELECT "time", device, avg(temp) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) GROUP BY 1, 2 ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST
         ->  Custom Scan (DataNodeScan)
               Output: hyper_1."time", hyper_1.device, (avg(hyper_1.temp))
               Relations: Aggregate on (public.hyper)
               Data node: data_node_2
               Chunks: _dist_hyper_1_2_chunk, _dist_hyper_1_5_chunk, _dist_hyper_1_7_chunk, _dist_hyper_1_9_chunk, _dist_hyper_1_11_chunk, _dist_hyper_1_14_chunk, _dist_hyper_1_18_chunk
               Remote SQL: SELECT "time", device, avg(temp) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) GROUP BY 1, 2 ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST
         ->  Custom Scan (DataNodeScan)
               Output: hyper_2."time", hyper_2.device, (avg(hyper_2.temp))
               Relations: Aggregate on (public.hyper)
               Data node: data_node_3
               Chunks: _dist_hyper_1_3_chunk, _dist_hyper_1_6_chunk, _dist_hyper_1_10_chunk, _dist_hyper_1_16_chunk
               Remote SQL: SELECT "time", device, avg(temp) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) GROUP BY 1, 2 ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST
(22 rows)

                                                                                                                                               QUERY PLAN                                                                                                                                                
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Custom Scan (AsyncAppend)
   Output: "time", device, (avg(temp))
   ->  Merge Append
         Sort Key: hyper."time", hyper.device
         ->  Custom Scan (DataNodeScan)
               Output: hyper."time", hyper.device, (avg(hyper.temp))
               Relations: Aggregate on (public.hyper)
               Data node: data_node_1
               Chunks: _dist_hyper_1_1_chunk, _dist_hyper_1_4_chunk, _dist_hyper_1_8_chunk, _dist_hyper_1_12_chunk, _dist_hyper_1_13_chunk, _dist_hyper_1_15_chunk, _dist_hyper_1_17_chunk
               Remote SQL: SELECT "time", device, avg(temp) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) GROUP BY 1, 2 ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST
         ->  Custom Scan (DataNodeScan)
               Output: hyper_1."time", hyper_1.device, (avg(hyper_1.temp))
               Relations: Aggregate on (public.hyper)
               Data node: data_node_2
               Chunks: _dist_hyper_1_2_chunk, _dist_hyper_1_5_chunk, _dist_hyper_1_7_chunk, _dist_hyper_1_9_chunk, _dist_hyper_1_11_chunk, _dist_hyper_1_14_chunk, _dist_hyper_1_18_chunk
               Remote SQL: SELECT "time", device, avg(temp) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) GROUP BY 1, 2 ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST
         ->  Custom Scan (DataNodeScan)
               Output: hyper_2."time", hyper_2.device, (avg(hyper_2.temp))
               Relations: Aggregate on (public.hyper)
               Data node: data_node_3
               Chunks: _dist_hyper_1_3_chunk, _dist_hyper_1_6_chunk, _dist_hyper_1_10_chunk, _dist_hyper_1_16_chunk
               Remote SQL: SELECT "time", device, avg(temp) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) GROUP BY 1, 2 ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST
(22 rows)

 tsl_override_current_timestamptz 
----------------------------------
 
(1 row)

                                                                                                                                               QUERY PLAN                                                                                                                                                
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Custom Scan (AsyncAppend)
   Output: "time", device, (avg(temp))
   ->  Merge Append
         Sort Key: hyper."time", hyper.device
         ->  Custom Scan (DataNodeScan)
               Output: hyper."time", hyper.device, (avg(hyper.temp))
               Relations: Aggregate on (public.hyper)
               Data node: data_node_1
               Chunks: _dist_hyper_1_1_chunk, _dist_hyper_1_4_chunk, _dist_hyper_1_8_chunk, _dist_hyper_1_12_chunk, _dist_hyper_1_13_chunk, _dist_hyper_1_15_chunk, _dist_hyper_1_17_chunk
               Remote SQL: SELECT "time", device, avg(temp) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) GROUP BY 1, 2 ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST
         ->  Custom Scan (DataNodeScan)
               Output: hyper_1."time", hyper_1.device, (avg(hyper_1.temp))
               Relations: Aggregate on (public.hyper)
               Data node: data_node_2
               Chunks: _dist_hyper_1_2_chunk, _dist_hyper_1_5_chunk, _dist_hyper_1_7_chunk, _dist_hyper_1_9_chunk, _dist_hyper_1_11_chunk, _dist_hyper_1_14_chunk, _dist_hyper_1_18_chunk
               Remote SQL: SELECT "time", device, avg(temp) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) GROUP BY 1, 2 ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST
         ->  Custom Scan (DataNodeScan)
               Output: hyper_2."time", hyper_2.device, (avg(hyper_2.temp))
               Relations: Aggregate on (public.hyper)
               Data node: data_node_3
               Chunks: _dist_hyper_1_3_chunk, _dist_hyper_1_6_chunk, _dist_hyper_1_10_chunk, _dist_hyper_1_16_chunk
               Remote SQL: SELECT "time", device, avg(temp) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) GROUP BY 1, 2 ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST
(22 rows)


######### LIMIT push down cases

EXPLAIN (verbose, costs off)
SELECT time, device
FROM hyper
ORDER BY 1,2
LIMIT 10
                                                                                                        QUERY PLAN                                                                                                        
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit
   Output: hyper."time", hyper.device
   ->  Custom Scan (AsyncAppend)
         Output: hyper."time", hyper.device
         ->  Merge Append
               Sort Key: hyper_1."time", hyper_1.device
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_1
                     Output: hyper_1."time", hyper_1.device
                     Data node: data_node_1
                     Chunks: _dist_hyper_1_1_chunk, _dist_hyper_1_4_chunk, _dist_hyper_1_8_chunk, _dist_hyper_1_12_chunk, _dist_hyper_1_13_chunk, _dist_hyper_1_15_chunk, _dist_hyper_1_17_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST LIMIT 10
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                     Output: hyper_2."time", hyper_2.device
                     Data node: data_node_2
                     Chunks: _dist_hyper_1_2_chunk, _dist_hyper_1_5_chunk, _dist_hyper_1_7_chunk, _dist_hyper_1_9_chunk, _dist_hyper_1_11_chunk, _dist_hyper_1_14_chunk, _dist_hyper_1_18_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST LIMIT 10
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_3
                     Output: hyper_3."time", hyper_3.device
                     Data node: data_node_3
                     Chunks: _dist_hyper_1_3_chunk, _dist_hyper_1_6_chunk, _dist_hyper_1_10_chunk, _dist_hyper_1_16_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4]) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST LIMIT 10
(21 rows)


######### LIMIT push down cases

EXPLAIN (verbose, costs off)
SELECT time, device
FROM hyper
ORDER BY 1,2
LIMIT 5
OFFSET 5
                                                                                                        QUERY PLAN                                                                                                        
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit
   Output: hyper."time", hyper.device
   ->  Custom Scan (AsyncAppend)
         Output: hyper."time", hyper.device
         ->  Merge Append
               Sort Key: hyper_1."time", hyper_1.device
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_1
                     Output: hyper_1."time", hyper_1.device
                     Data node: data_node_1
                     Chunks: _dist_hyper_1_1_chunk, _dist_hyper_1_4_chunk, _dist_hyper_1_8_chunk, _dist_hyper_1_12_chunk, _dist_hyper_1_13_chunk, _dist_hyper_1_15_chunk, _dist_hyper_1_17_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST LIMIT 10
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                     Output: hyper_2."time", hyper_2.device
                     Data node: data_node_2
                     Chunks: _dist_hyper_1_2_chunk, _dist_hyper_1_5_chunk, _dist_hyper_1_7_chunk, _dist_hyper_1_9_chunk, _dist_hyper_1_11_chunk, _dist_hyper_1_14_chunk, _dist_hyper_1_18_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST LIMIT 10
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_3
                     Output: hyper_3."time", hyper_3.device
                     Data node: data_node_3
                     Chunks: _dist_hyper_1_3_chunk, _dist_hyper_1_6_chunk, _dist_hyper_1_10_chunk, _dist_hyper_1_16_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4]) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST LIMIT 10
(21 rows)


######### LIMIT push down cases

EXPLAIN (verbose, costs off)
SELECT time, device
FROM hyper
ORDER BY 1,2
LIMIT 0
                                                                                                       QUERY PLAN                                                                                                        
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit
   Output: hyper."time", hyper.device
   ->  Custom Scan (AsyncAppend)
         Output: hyper."time", hyper.device
         ->  Merge Append
               Sort Key: hyper_1."time", hyper_1.device
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_1
                     Output: hyper_1."time", hyper_1.device
                     Data node: data_node_1
                     Chunks: _dist_hyper_1_1_chunk, _dist_hyper_1_4_chunk, _dist_hyper_1_8_chunk, _dist_hyper_1_12_chunk, _dist_hyper_1_13_chunk, _dist_hyper_1_15_chunk, _dist_hyper_1_17_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST LIMIT 1
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                     Output: hyper_2."time", hyper_2.device
                     Data node: data_node_2
                     Chunks: _dist_hyper_1_2_chunk, _dist_hyper_1_5_chunk, _dist_hyper_1_7_chunk, _dist_hyper_1_9_chunk, _dist_hyper_1_11_chunk, _dist_hyper_1_14_chunk, _dist_hyper_1_18_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST LIMIT 1
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_3
                     Output: hyper_3."time", hyper_3.device
                     Data node: data_node_3
                     Chunks: _dist_hyper_1_3_chunk, _dist_hyper_1_6_chunk, _dist_hyper_1_10_chunk, _dist_hyper_1_16_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4]) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST LIMIT 1
(21 rows)


######### LIMIT push down cases

EXPLAIN (verbose, costs off)
SELECT time, device
FROM hyper
ORDER BY 1,2
LIMIT extract(year from date '2000-01-01')
                                                                                                         QUERY PLAN                                                                                                         
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit
   Output: hyper."time", hyper.device
   ->  Custom Scan (AsyncAppend)
         Output: hyper."time", hyper.device
         ->  Merge Append
               Sort Key: hyper_1."time", hyper_1.device
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_1
                     Output: hyper_1."time", hyper_1.device
                     Data node: data_node_1
                     Chunks: _dist_hyper_1_1_chunk, _dist_hyper_1_4_chunk, _dist_hyper_1_8_chunk, _dist_hyper_1_12_chunk, _dist_hyper_1_13_chunk, _dist_hyper_1_15_chunk, _dist_hyper_1_17_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST LIMIT 2000
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                     Output: hyper_2."time", hyper_2.device
                     Data node: data_node_2
                     Chunks: _dist_hyper_1_2_chunk, _dist_hyper_1_5_chunk, _dist_hyper_1_7_chunk, _dist_hyper_1_9_chunk, _dist_hyper_1_11_chunk, _dist_hyper_1_14_chunk, _dist_hyper_1_18_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST LIMIT 2000
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_3
                     Output: hyper_3."time", hyper_3.device
                     Data node: data_node_3
                     Chunks: _dist_hyper_1_3_chunk, _dist_hyper_1_6_chunk, _dist_hyper_1_10_chunk, _dist_hyper_1_16_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4]) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST LIMIT 2000
(21 rows)


######### LIMIT push down cases

EXPLAIN (verbose, costs off)
SELECT time, device
FROM hyper
ORDER BY 1,2
LIMIT greatest(random(), 10.0)
                                                                                                   QUERY PLAN                                                                                                    
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit
   Output: hyper."time", hyper.device
   ->  Custom Scan (AsyncAppend)
         Output: hyper."time", hyper.device
         ->  Merge Append
               Sort Key: hyper_1."time", hyper_1.device
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_1
                     Output: hyper_1."time", hyper_1.device
                     Data node: data_node_1
                     Chunks: _dist_hyper_1_1_chunk, _dist_hyper_1_4_chunk, _dist_hyper_1_8_chunk, _dist_hyper_1_12_chunk, _dist_hyper_1_13_chunk, _dist_hyper_1_15_chunk, _dist_hyper_1_17_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                     Output: hyper_2."time", hyper_2.device
                     Data node: data_node_2
                     Chunks: _dist_hyper_1_2_chunk, _dist_hyper_1_5_chunk, _dist_hyper_1_7_chunk, _dist_hyper_1_9_chunk, _dist_hyper_1_11_chunk, _dist_hyper_1_14_chunk, _dist_hyper_1_18_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST
               ->  Custom Scan (DataNodeScan) on public.hyper hyper_3
                     Output: hyper_3."time", hyper_3.device
                     Data node: data_node_3
                     Chunks: _dist_hyper_1_3_chunk, _dist_hyper_1_6_chunk, _dist_hyper_1_10_chunk, _dist_hyper_1_16_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4]) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST
(21 rows)


######### LIMIT push down cases

EXPLAIN (verbose, costs off)
SELECT time, device, avg(temp) OVER (PARTITION BY device)
FROM hyper
ORDER BY 1,2
LIMIT 10
                                                                                                 QUERY PLAN                                                                                                  
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit
   Output: hyper."time", hyper.device, (avg(hyper.temp) OVER (?))
   ->  Sort
         Output: hyper."time", hyper.device, (avg(hyper.temp) OVER (?))
         Sort Key: hyper."time", hyper.device
         ->  WindowAgg
               Output: hyper."time", hyper.device, avg(hyper.temp) OVER (?)
               ->  Custom Scan (AsyncAppend)
                     Output: hyper.device, hyper."time", hyper.temp
                     ->  Merge Append
                           Sort Key: hyper_1.device
                           ->  Custom Scan (DataNodeScan) on public.hyper hyper_1
                                 Output: hyper_1.device, hyper_1."time", hyper_1.temp
                                 Data node: data_node_1
                                 Chunks: _dist_hyper_1_1_chunk, _dist_hyper_1_4_chunk, _dist_hyper_1_8_chunk, _dist_hyper_1_12_chunk, _dist_hyper_1_13_chunk, _dist_hyper_1_15_chunk, _dist_hyper_1_17_chunk
                                 Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) ORDER BY device ASC NULLS LAST
                           ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                                 Output: hyper_2.device, hyper_2."time", hyper_2.temp
                                 Data node: data_node_2
                                 Chunks: _dist_hyper_1_2_chunk, _dist_hyper_1_5_chunk, _dist_hyper_1_7_chunk, _dist_hyper_1_9_chunk, _dist_hyper_1_11_chunk, _dist_hyper_1_14_chunk, _dist_hyper_1_18_chunk
                                 Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) ORDER BY device ASC NULLS LAST
                           ->  Custom Scan (DataNodeScan) on public.hyper hyper_3
                                 Output: hyper_3.device, hyper_3."time", hyper_3.temp
                                 Data node: data_node_3
                                 Chunks: _dist_hyper_1_3_chunk, _dist_hyper_1_6_chunk, _dist_hyper_1_10_chunk, _dist_hyper_1_16_chunk
                                 Remote SQL: SELECT "time", device, temp FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4]) ORDER BY device ASC NULLS LAST
(26 rows)


######### LIMIT push down cases

EXPLAIN (verbose, costs off)
SELECT DISTINCT device, time
FROM hyper
ORDER BY 1,2
LIMIT 10
                                                                                                      QUERY PLAN                                                                                                       
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit
   Output: hyper.device, hyper."time"
   ->  Unique
         Output: hyper.device, hyper."time"
         ->  Custom Scan (AsyncAppend)
               Output: hyper.device, hyper."time"
               ->  Merge Append
                     Sort Key: hyper_1.device, hyper_1."time"
                     ->  Custom Scan (DataNodeScan) on public.hyper hyper_1
                           Output: hyper_1.device, hyper_1."time"
                           Data node: data_node_1
                           Chunks: _dist_hyper_1_1_chunk, _dist_hyper_1_4_chunk, _dist_hyper_1_8_chunk, _dist_hyper_1_12_chunk, _dist_hyper_1_13_chunk, _dist_hyper_1_15_chunk, _dist_hyper_1_17_chunk
                           Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) ORDER BY device ASC NULLS LAST, "time" ASC NULLS LAST
                     ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                           Output: hyper_2.device, hyper_2."time"
                           Data node: data_node_2
                           Chunks: _dist_hyper_1_2_chunk, _dist_hyper_1_5_chunk, _dist_hyper_1_7_chunk, _dist_hyper_1_9_chunk, _dist_hyper_1_11_chunk, _dist_hyper_1_14_chunk, _dist_hyper_1_18_chunk
                           Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) ORDER BY device ASC NULLS LAST, "time" ASC NULLS LAST
                     ->  Custom Scan (DataNodeScan) on public.hyper hyper_3
                           Output: hyper_3.device, hyper_3."time"
                           Data node: data_node_3
                           Chunks: _dist_hyper_1_3_chunk, _dist_hyper_1_6_chunk, _dist_hyper_1_10_chunk, _dist_hyper_1_16_chunk
                           Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4]) ORDER BY device ASC NULLS LAST, "time" ASC NULLS LAST
(23 rows)


######### LIMIT push down cases

EXPLAIN (verbose, costs off)
SELECT DISTINCT ON (device) device, time
FROM hyper
ORDER BY 1,2
LIMIT 10
                                                                                                      QUERY PLAN                                                                                                       
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit
   Output: hyper.device, hyper."time"
   ->  Unique
         Output: hyper.device, hyper."time"
         ->  Custom Scan (AsyncAppend)
               Output: hyper.device, hyper."time"
               ->  Merge Append
                     Sort Key: hyper_1.device, hyper_1."time"
                     ->  Custom Scan (DataNodeScan) on public.hyper hyper_1
                           Output: hyper_1.device, hyper_1."time"
                           Data node: data_node_1
                           Chunks: _dist_hyper_1_1_chunk, _dist_hyper_1_4_chunk, _dist_hyper_1_8_chunk, _dist_hyper_1_12_chunk, _dist_hyper_1_13_chunk, _dist_hyper_1_15_chunk, _dist_hyper_1_17_chunk
                           Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) ORDER BY device ASC NULLS LAST, "time" ASC NULLS LAST
                     ->  Custom Scan (DataNodeScan) on public.hyper hyper_2
                           Output: hyper_2.device, hyper_2."time"
                           Data node: data_node_2
                           Chunks: _dist_hyper_1_2_chunk, _dist_hyper_1_5_chunk, _dist_hyper_1_7_chunk, _dist_hyper_1_9_chunk, _dist_hyper_1_11_chunk, _dist_hyper_1_14_chunk, _dist_hyper_1_18_chunk
                           Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7]) ORDER BY device ASC NULLS LAST, "time" ASC NULLS LAST
                     ->  Custom Scan (DataNodeScan) on public.hyper hyper_3
                           Output: hyper_3.device, hyper_3."time"
                           Data node: data_node_3
                           Chunks: _dist_hyper_1_3_chunk, _dist_hyper_1_6_chunk, _dist_hyper_1_10_chunk, _dist_hyper_1_16_chunk
                           Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4]) ORDER BY device ASC NULLS LAST, "time" ASC NULLS LAST
(23 rows)


######### LIMIT push down cases

                                                                                              QUERY PLAN                                                                                               
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit
   Output: t."time"
   ->  Nested Loop
         Output: t."time"
         Join Filter: (t.device = join_test.device)
         ->  Custom Scan (AsyncAppend)
               Output: t."time", t.device
               ->  Append
                     ->  Custom Scan (DataNodeScan) on public.hyper t_1
                           Output: t_1."time", t_1.device
                           Data node: data_node_1
                           Chunks: _dist_hyper_1_1_chunk, _dist_hyper_1_4_chunk, _dist_hyper_1_8_chunk, _dist_hyper_1_12_chunk, _dist_hyper_1_13_chunk, _dist_hyper_1_15_chunk, _dist_hyper_1_17_chunk
                           Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7])
                     ->  Custom Scan (DataNodeScan) on public.hyper t_2
                           Output: t_2."time", t_2.device
                           Data node: data_node_2
                           Chunks: _dist_hyper_1_2_chunk, _dist_hyper_1_5_chunk, _dist_hyper_1_7_chunk, _dist_hyper_1_9_chunk, _dist_hyper_1_11_chunk, _dist_hyper_1_14_chunk, _dist_hyper_1_18_chunk
                           Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4, 5, 6, 7])
                     ->  Custom Scan (DataNodeScan) on public.hyper t_3
                           Output: t_3."time", t_3.device
                           Data node: data_node_3
                           Chunks: _dist_hyper_1_3_chunk, _dist_hyper_1_6_chunk, _dist_hyper_1_10_chunk, _dist_hyper_1_16_chunk
                           Remote SQL: SELECT "time", device FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[1, 2, 3, 4])
         ->  Materialize
               Output: join_test.device
               ->  Seq Scan on public.join_test
                     Output: join_test.device
(27 rows)

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% RUNNING TESTS on table: hyper1d
%%% PREFIX: EXPLAIN (verbose, costs off)
%%% WHERE_CLAUSE: :REPARTITIONED_TIME_RANGE
%%% ORDER_BY_1: ORDER BY 1
%%% ORDER_BY_1_2: 
%%% LIMIT: 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
 setseed 
---------
 
(1 row)


######### Grouping on time only (partial aggregation)

EXPLAIN (verbose, costs off)
SELECT time, avg(temp)
FROM hyper1d
WHERE time >= '2019-01-01'
GROUP BY 1
ORDER BY 1

                                                                                                                       QUERY PLAN                                                                                                                        
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Custom Scan (AsyncAppend)
   Output: "time", (avg(temp))
   ->  Merge Append
         Sort Key: hyper1d."time"
         ->  Custom Scan (DataNodeScan)
               Output: hyper1d."time", (avg(hyper1d.temp))
               Relations: Aggregate on (public.hyper1d)
               Data node: data_node_1
               Chunks: _dist_hyper_2_19_chunk
               Remote SQL: SELECT "time", avg(temp) FROM public.hyper1d WHERE _timescaledb_internal.chunks_in(public.hyper1d.*, ARRAY[8]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) GROUP BY 1 ORDER BY "time" ASC NULLS LAST
         ->  Custom Scan (DataNodeScan)
               Output: hyper1d_1."time", (avg(hyper1d_1.temp))
               Relations: Aggregate on (public.hyper1d)
               Data node: data_node_2
               Chunks: _dist_hyper_2_20_chunk
               Remote SQL: SELECT "time", avg(temp) FROM public.hyper1d WHERE _timescaledb_internal.chunks_in(public.hyper1d.*, ARRAY[8]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) GROUP BY 1 ORDER BY "time" ASC NULLS LAST
         ->  Custom Scan (DataNodeScan)
               Output: hyper1d_2."time", (avg(hyper1d_2.temp))
               Relations: Aggregate on (public.hyper1d)
               Data node: data_node_3
               Chunks: _dist_hyper_2_21_chunk
               Remote SQL: SELECT "time", avg(temp) FROM public.hyper1d WHERE _timescaledb_internal.chunks_in(public.hyper1d.*, ARRAY[5]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) GROUP BY 1 ORDER BY "time" ASC NULLS LAST
(22 rows)


######### Grouping on time only (partial aggregation)

EXPLAIN (verbose, costs off)
SELECT time_bucket('2 days', time) AS time, avg(temp)
FROM hyper1d
WHERE time >= '2019-01-01'
GROUP BY 1
ORDER BY 1

                                                                                                                                                                                      QUERY PLAN                                                                                                                                                                                       
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Finalize GroupAggregate
   Output: (time_bucket('@ 2 days'::interval, "time")), avg(temp)
   Group Key: (time_bucket('@ 2 days'::interval, "time"))
   ->  Custom Scan (AsyncAppend)
         Output: (time_bucket('@ 2 days'::interval, "time")), (PARTIAL avg(temp))
         ->  Merge Append
               Sort Key: (time_bucket('@ 2 days'::interval, hyper1d."time"))
               ->  Custom Scan (DataNodeScan)
                     Output: (time_bucket('@ 2 days'::interval, hyper1d."time")), (PARTIAL avg(hyper1d.temp))
                     Relations: Aggregate on (public.hyper1d)
                     Data node: data_node_1
                     Chunks: _dist_hyper_2_19_chunk
                     Remote SQL: SELECT public.time_bucket('@ 2 days'::interval, "time"), _timescaledb_internal.partialize_agg(avg(temp)) FROM public.hyper1d WHERE _timescaledb_internal.chunks_in(public.hyper1d.*, ARRAY[8]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) GROUP BY 1 ORDER BY public.time_bucket('2 days'::interval, "time") ASC NULLS LAST
               ->  Custom Scan (DataNodeScan)
                     Output: (time_bucket('@ 2 days'::interval, hyper1d_1."time")), (PARTIAL avg(hyper1d_1.temp))
                     Relations: Aggregate on (public.hyper1d)
                     Data node: data_node_2
                     Chunks: _dist_hyper_2_20_chunk
                     Remote SQL: SELECT public.time_bucket('@ 2 days'::interval, "time"), _timescaledb_internal.partialize_agg(avg(temp)) FROM public.hyper1d WHERE _timescaledb_internal.chunks_in(public.hyper1d.*, ARRAY[8]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) GROUP BY 1 ORDER BY public.time_bucket('2 days'::interval, "time") ASC NULLS LAST
               ->  Custom Scan (DataNodeScan)
                     Output: (time_bucket('@ 2 days'::interval, hyper1d_2."time")), (PARTIAL avg(hyper1d_2.temp))
                     Relations: Aggregate on (public.hyper1d)
                     Data node: data_node_3
                     Chunks: _dist_hyper_2_21_chunk
                     Remote SQL: SELECT public.time_bucket('@ 2 days'::interval, "time"), _timescaledb_internal.partialize_agg(avg(temp)) FROM public.hyper1d WHERE _timescaledb_internal.chunks_in(public.hyper1d.*, ARRAY[5]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) GROUP BY 1 ORDER BY public.time_bucket('2 days'::interval, "time") ASC NULLS LAST
(25 rows)


######### Grouping on time and device (full aggregation)

EXPLAIN (verbose, costs off)
SELECT time, device, avg(temp)
FROM hyper
WHERE time >= '2019-01-01'
GROUP BY 1,2


                                                                                                                    QUERY PLAN                                                                                                                     
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Custom Scan (AsyncAppend)
   Output: "time", device, (avg(temp))
   ->  Append
         ->  Custom Scan (DataNodeScan)
               Output: hyper."time", hyper.device, (avg(hyper.temp))
               Relations: Aggregate on (public.hyper)
               Data node: data_node_1
               Chunks: _dist_hyper_1_8_chunk, _dist_hyper_1_12_chunk, _dist_hyper_1_17_chunk, _dist_hyper_1_1_chunk, _dist_hyper_1_15_chunk, _dist_hyper_1_4_chunk, _dist_hyper_1_13_chunk
               Remote SQL: SELECT "time", device, avg(temp) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[3, 4, 7, 1, 6, 2, 5]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) GROUP BY 1, 2
         ->  Custom Scan (DataNodeScan)
               Output: hyper_1."time", hyper_1.device, (avg(hyper_1.temp))
               Relations: Aggregate on (public.hyper)
               Data node: data_node_2
               Chunks: _dist_hyper_1_14_chunk, _dist_hyper_1_11_chunk, _dist_hyper_1_18_chunk, _dist_hyper_1_2_chunk, _dist_hyper_1_5_chunk, _dist_hyper_1_9_chunk, _dist_hyper_1_7_chunk
               Remote SQL: SELECT "time", device, avg(temp) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[6, 5, 7, 1, 2, 4, 3]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) GROUP BY 1, 2
         ->  Custom Scan (DataNodeScan)
               Output: hyper_2."time", hyper_2.device, (avg(hyper_2.temp))
               Relations: Aggregate on (public.hyper)
               Data node: data_node_3
               Chunks: _dist_hyper_1_10_chunk, _dist_hyper_1_16_chunk, _dist_hyper_1_6_chunk, _dist_hyper_1_3_chunk
               Remote SQL: SELECT "time", device, avg(temp) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[3, 4, 2, 1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) GROUP BY 1, 2
(21 rows)


######### Grouping on time and device (full aggregation)

EXPLAIN (verbose, costs off)
SELECT time_bucket('2 days', time) AS time, device, avg(temp)
FROM hyper1d
WHERE time >= '2019-01-01'
GROUP BY 1,2


                                                                                                                                                        QUERY PLAN                                                                                                                                                         
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Finalize HashAggregate
   Output: (time_bucket('@ 2 days'::interval, "time")), device, avg(temp)
   Group Key: (time_bucket('@ 2 days'::interval, "time")), device
   ->  Custom Scan (AsyncAppend)
         Output: (time_bucket('@ 2 days'::interval, "time")), device, (PARTIAL avg(temp))
         ->  Append
               ->  Custom Scan (DataNodeScan)
                     Output: (time_bucket('@ 2 days'::interval, hyper1d."time")), hyper1d.device, (PARTIAL avg(hyper1d.temp))
                     Relations: Aggregate on (public.hyper1d)
                     Data node: data_node_1
                     Chunks: _dist_hyper_2_19_chunk
                     Remote SQL: SELECT public.time_bucket('@ 2 days'::interval, "time"), device, _timescaledb_internal.partialize_agg(avg(temp)) FROM public.hyper1d WHERE _timescaledb_internal.chunks_in(public.hyper1d.*, ARRAY[8]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) GROUP BY 1, 2
               ->  Custom Scan (DataNodeScan)
                     Output: (time_bucket('@ 2 days'::interval, hyper1d_1."time")), hyper1d_1.device, (PARTIAL avg(hyper1d_1.temp))
                     Relations: Aggregate on (public.hyper1d)
                     Data node: data_node_2
                     Chunks: _dist_hyper_2_20_chunk
                     Remote SQL: SELECT public.time_bucket('@ 2 days'::interval, "time"), device, _timescaledb_internal.partialize_agg(avg(temp)) FROM public.hyper1d WHERE _timescaledb_internal.chunks_in(public.hyper1d.*, ARRAY[8]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) GROUP BY 1, 2
               ->  Custom Scan (DataNodeScan)
                     Output: (time_bucket('@ 2 days'::interval, hyper1d_2."time")), hyper1d_2.device, (PARTIAL avg(hyper1d_2.temp))
                     Relations: Aggregate on (public.hyper1d)
                     Data node: data_node_3
                     Chunks: _dist_hyper_2_21_chunk
                     Remote SQL: SELECT public.time_bucket('@ 2 days'::interval, "time"), device, _timescaledb_internal.partialize_agg(avg(temp)) FROM public.hyper1d WHERE _timescaledb_internal.chunks_in(public.hyper1d.*, ARRAY[5]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) GROUP BY 1, 2
(24 rows)


######### Grouping on time and device (full aggregation)

EXPLAIN (verbose, costs off)
SELECT date_trunc('month', time) AS time, device, avg(temp)
FROM hyper1d
WHERE time >= '2019-01-01'
GROUP BY 1,2


                                                                                                                                                 QUERY PLAN                                                                                                                                                 
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Finalize HashAggregate
   Output: (date_trunc('month'::text, "time")), device, avg(temp)
   Group Key: (date_trunc('month'::text, "time")), device
   ->  Custom Scan (AsyncAppend)
         Output: (date_trunc('month'::text, "time")), device, (PARTIAL avg(temp))
         ->  Append
               ->  Custom Scan (DataNodeScan)
                     Output: (date_trunc('month'::text, hyper1d."time")), hyper1d.device, (PARTIAL avg(hyper1d.temp))
                     Relations: Aggregate on (public.hyper1d)
                     Data node: data_node_1
                     Chunks: _dist_hyper_2_19_chunk
                     Remote SQL: SELECT date_trunc('month'::text, "time"), device, _timescaledb_internal.partialize_agg(avg(temp)) FROM public.hyper1d WHERE _timescaledb_internal.chunks_in(public.hyper1d.*, ARRAY[8]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) GROUP BY 1, 2
               ->  Custom Scan (DataNodeScan)
                     Output: (date_trunc('month'::text, hyper1d_1."time")), hyper1d_1.device, (PARTIAL avg(hyper1d_1.temp))
                     Relations: Aggregate on (public.hyper1d)
                     Data node: data_node_2
                     Chunks: _dist_hyper_2_20_chunk
                     Remote SQL: SELECT date_trunc('month'::text, "time"), device, _timescaledb_internal.partialize_agg(avg(temp)) FROM public.hyper1d WHERE _timescaledb_internal.chunks_in(public.hyper1d.*, ARRAY[8]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) GROUP BY 1, 2
               ->  Custom Scan (DataNodeScan)
                     Output: (date_trunc('month'::text, hyper1d_2."time")), hyper1d_2.device, (PARTIAL avg(hyper1d_2.temp))
                     Relations: Aggregate on (public.hyper1d)
                     Data node: data_node_3
                     Chunks: _dist_hyper_2_21_chunk
                     Remote SQL: SELECT date_trunc('month'::text, "time"), device, _timescaledb_internal.partialize_agg(avg(temp)) FROM public.hyper1d WHERE _timescaledb_internal.chunks_in(public.hyper1d.*, ARRAY[5]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) GROUP BY 1, 2
(24 rows)


######### Grouping on time and device (full aggregation)

EXPLAIN (verbose, costs off)
SELECT time_bucket('2 days', time) AS time, device, avg(temp)
FROM hyper1d
WHERE time >= '2019-01-01'
GROUP BY 1,2
HAVING device > 4


                                                                                                                                                                  QUERY PLAN                                                                                                                                                                  
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Finalize HashAggregate
   Output: (time_bucket('@ 2 days'::interval, "time")), device, avg(temp)
   Group Key: (time_bucket('@ 2 days'::interval, "time")), device
   ->  Custom Scan (AsyncAppend)
         Output: (time_bucket('@ 2 days'::interval, "time")), device, (PARTIAL avg(temp))
         ->  Append
               ->  Custom Scan (DataNodeScan)
                     Output: (time_bucket('@ 2 days'::interval, hyper1d."time")), hyper1d.device, (PARTIAL avg(hyper1d.temp))
                     Relations: Aggregate on (public.hyper1d)
                     Data node: data_node_1
                     Chunks: _dist_hyper_2_19_chunk
                     Remote SQL: SELECT public.time_bucket('@ 2 days'::interval, "time"), device, _timescaledb_internal.partialize_agg(avg(temp)) FROM public.hyper1d WHERE _timescaledb_internal.chunks_in(public.hyper1d.*, ARRAY[8]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND ((device > 4)) GROUP BY 1, 2
               ->  Custom Scan (DataNodeScan)
                     Output: (time_bucket('@ 2 days'::interval, hyper1d_1."time")), hyper1d_1.device, (PARTIAL avg(hyper1d_1.temp))
                     Relations: Aggregate on (public.hyper1d)
                     Data node: data_node_2
                     Chunks: _dist_hyper_2_20_chunk
                     Remote SQL: SELECT public.time_bucket('@ 2 days'::interval, "time"), device, _timescaledb_internal.partialize_agg(avg(temp)) FROM public.hyper1d WHERE _timescaledb_internal.chunks_in(public.hyper1d.*, ARRAY[8]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND ((device > 4)) GROUP BY 1, 2
               ->  Custom Scan (DataNodeScan)
                     Output: (time_bucket('@ 2 days'::interval, hyper1d_2."time")), hyper1d_2.device, (PARTIAL avg(hyper1d_2.temp))
                     Relations: Aggregate on (public.hyper1d)
                     Data node: data_node_3
                     Chunks: _dist_hyper_2_21_chunk
                     Remote SQL: SELECT public.time_bucket('@ 2 days'::interval, "time"), device, _timescaledb_internal.partialize_agg(avg(temp)) FROM public.hyper1d WHERE _timescaledb_internal.chunks_in(public.hyper1d.*, ARRAY[5]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) AND ((device > 4)) GROUP BY 1, 2
(24 rows)

EXPLAIN (verbose, costs off)
SELECT time_bucket('2 days', time) AS time, device, avg(temp)
FROM hyper1d
WHERE time >= '2019-01-01'
GROUP BY 1,2
HAVING avg(temp) > 40 AND max(temp) < 70


                                                                                                                                                                                 QUERY PLAN                                                                                                                                                                                 
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Finalize HashAggregate
   Output: (time_bucket('@ 2 days'::interval, "time")), device, avg(temp)
   Group Key: (time_bucket('@ 2 days'::interval, "time")), device
   Filter: ((avg(temp) > '40'::double precision) AND (max(temp) < '70'::double precision))
   ->  Custom Scan (AsyncAppend)
         Output: (time_bucket('@ 2 days'::interval, "time")), device, (PARTIAL avg(temp)), (PARTIAL max(temp))
         ->  Append
               ->  Custom Scan (DataNodeScan)
                     Output: (time_bucket('@ 2 days'::interval, hyper1d."time")), hyper1d.device, (PARTIAL avg(hyper1d.temp)), (PARTIAL max(hyper1d.temp))
                     Relations: Aggregate on (public.hyper1d)
                     Data node: data_node_1
                     Chunks: _dist_hyper_2_19_chunk
                     Remote SQL: SELECT public.time_bucket('@ 2 days'::interval, "time"), device, _timescaledb_internal.partialize_agg(avg(temp)), _timescaledb_internal.partialize_agg(max(temp)) FROM public.hyper1d WHERE _timescaledb_internal.chunks_in(public.hyper1d.*, ARRAY[8]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) GROUP BY 1, 2
               ->  Custom Scan (DataNodeScan)
                     Output: (time_bucket('@ 2 days'::interval, hyper1d_1."time")), hyper1d_1.device, (PARTIAL avg(hyper1d_1.temp)), (PARTIAL max(hyper1d_1.temp))
                     Relations: Aggregate on (public.hyper1d)
                     Data node: data_node_2
                     Chunks: _dist_hyper_2_20_chunk
                     Remote SQL: SELECT public.time_bucket('@ 2 days'::interval, "time"), device, _timescaledb_internal.partialize_agg(avg(temp)), _timescaledb_internal.partialize_agg(max(temp)) FROM public.hyper1d WHERE _timescaledb_internal.chunks_in(public.hyper1d.*, ARRAY[8]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) GROUP BY 1, 2
               ->  Custom Scan (DataNodeScan)
                     Output: (time_bucket('@ 2 days'::interval, hyper1d_2."time")), hyper1d_2.device, (PARTIAL avg(hyper1d_2.temp)), (PARTIAL max(hyper1d_2.temp))
                     Relations: Aggregate on (public.hyper1d)
                     Data node: data_node_3
                     Chunks: _dist_hyper_2_21_chunk
                     Remote SQL: SELECT public.time_bucket('@ 2 days'::interval, "time"), device, _timescaledb_internal.partialize_agg(avg(temp)), _timescaledb_internal.partialize_agg(max(temp)) FROM public.hyper1d WHERE _timescaledb_internal.chunks_in(public.hyper1d.*, ARRAY[5]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) GROUP BY 1, 2
(25 rows)


######### Grouping on device only (full aggregation)

EXPLAIN (verbose, costs off)
SELECT device, avg(temp)
FROM hyper
WHERE time >= '2019-01-01'
GROUP BY 1
ORDER BY 1

                                                                                                                                                    QUERY PLAN                                                                                                                                                     
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Finalize GroupAggregate
   Output: device, avg(temp)
   Group Key: device
   ->  Custom Scan (AsyncAppend)
         Output: device, (PARTIAL avg(temp))
         ->  Merge Append
               Sort Key: hyper.device
               ->  Custom Scan (DataNodeScan)
                     Output: hyper.device, (PARTIAL avg(hyper.temp))
                     Relations: Aggregate on (public.hyper)
                     Data node: data_node_1
                     Chunks: _dist_hyper_1_8_chunk, _dist_hyper_1_12_chunk, _dist_hyper_1_17_chunk, _dist_hyper_1_1_chunk, _dist_hyper_1_15_chunk, _dist_hyper_1_4_chunk, _dist_hyper_1_13_chunk
                     Remote SQL: SELECT device, _timescaledb_internal.partialize_agg(avg(temp)) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[3, 4, 7, 1, 6, 2, 5]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) GROUP BY 1 ORDER BY device ASC NULLS LAST
               ->  Custom Scan (DataNodeScan)
                     Output: hyper_1.device, (PARTIAL avg(hyper_1.temp))
                     Relations: Aggregate on (public.hyper)
                     Data node: data_node_2
                     Chunks: _dist_hyper_1_14_chunk, _dist_hyper_1_11_chunk, _dist_hyper_1_18_chunk, _dist_hyper_1_2_chunk, _dist_hyper_1_5_chunk, _dist_hyper_1_9_chunk, _dist_hyper_1_7_chunk
                     Remote SQL: SELECT device, _timescaledb_internal.partialize_agg(avg(temp)) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[6, 5, 7, 1, 2, 4, 3]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) GROUP BY 1 ORDER BY device ASC NULLS LAST
               ->  Custom Scan (DataNodeScan)
                     Output: hyper_2.device, (PARTIAL avg(hyper_2.temp))
                     Relations: Aggregate on (public.hyper)
                     Data node: data_node_3
                     Chunks: _dist_hyper_1_10_chunk, _dist_hyper_1_16_chunk, _dist_hyper_1_6_chunk, _dist_hyper_1_3_chunk
                     Remote SQL: SELECT device, _timescaledb_internal.partialize_agg(avg(temp)) FROM public.hyper WHERE _timescaledb_internal.chunks_in(public.hyper.*, ARRAY[3, 4, 2, 1]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) GROUP BY 1 ORDER BY device ASC NULLS LAST
(25 rows)


######### No push down on some functions

EXPLAIN (verbose, costs off)
SELECT location, avg(temp)
FROM hyper1d
WHERE time >= '2019-01-01' AND (temp * random() >= 0)
GROUP BY 1
ORDER BY 1

                                                                                                                       QUERY PLAN                                                                                                                        
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Finalize GroupAggregate
   Output: location, avg(temp)
   Group Key: location
   ->  Custom Scan (AsyncAppend)
         Output: location, (PARTIAL avg(temp))
         ->  Merge Append
               Sort Key: hyper1d.location
               ->  Partial GroupAggregate
                     Output: hyper1d.location, PARTIAL avg(hyper1d.temp)
                     Group Key: hyper1d.location
                     ->  Custom Scan (DataNodeScan) on public.hyper1d
                           Output: hyper1d.location, hyper1d.temp
                           Filter: ((hyper1d.temp * random()) >= '0'::double precision)
                           Data node: data_node_1
                           Chunks: _dist_hyper_2_19_chunk
                           Remote SQL: SELECT location, temp FROM public.hyper1d WHERE _timescaledb_internal.chunks_in(public.hyper1d.*, ARRAY[8]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) ORDER BY location ASC NULLS LAST
               ->  Partial GroupAggregate
                     Output: hyper1d_1.location, PARTIAL avg(hyper1d_1.temp)
                     Group Key: hyper1d_1.location
                     ->  Custom Scan (DataNodeScan) on public.hyper1d hyper1d_1
                           Output: hyper1d_1.location, hyper1d_1.temp
                           Filter: ((hyper1d_1.temp * random()) >= '0'::double precision)
                           Data node: data_node_2
                           Chunks: _dist_hyper_2_20_chunk
                           Remote SQL: SELECT location, temp FROM public.hyper1d WHERE _timescaledb_internal.chunks_in(public.hyper1d.*, ARRAY[8]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) ORDER BY location ASC NULLS LAST
               ->  Partial GroupAggregate
                     Output: hyper1d_2.location, PARTIAL avg(hyper1d_2.temp)
                     Group Key: hyper1d_2.location
                     ->  Custom Scan (DataNodeScan) on public.hyper1d hyper1d_2
                           Output: hyper1d_2.location, hyper1d_2.temp
                           Filter: ((hyper1d_2.temp * random()) >= '0'::double precision)
                           Data node: data_node_3
                           Chunks: _dist_hyper_2_21_chunk
                           Remote SQL: SELECT location, temp FROM public.hyper1d WHERE _timescaledb_internal.chunks_in(public.hyper1d.*, ARRAY[5]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) ORDER BY location ASC NULLS LAST
(34 rows)


######### No push down on some functions

EXPLAIN (verbose, costs off)
SELECT time_bucket('2 days', time) AS time, device, avg(temp), sum(temp * (random() <= 1)::int) as sum
FROM hyper1d
WHERE time >= '2019-01-01'
GROUP BY 1,2


                                                                                                                                                      QUERY PLAN                                                                                                                                                      
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Finalize GroupAggregate
   Output: (time_bucket('@ 2 days'::interval, hyper1d."time")), hyper1d.device, avg(hyper1d.temp), sum((hyper1d.temp * (((random() <= '1'::double precision))::integer)::double precision))
   Group Key: (time_bucket('@ 2 days'::interval, hyper1d."time")), hyper1d.device
   ->  Merge Append
         Sort Key: (time_bucket('@ 2 days'::interval, hyper1d."time")), hyper1d.device
         ->  Partial GroupAggregate
               Output: (time_bucket('@ 2 days'::interval, hyper1d."time")), hyper1d.device, PARTIAL avg(hyper1d.temp), PARTIAL sum((hyper1d.temp * (((random() <= '1'::double precision))::integer)::double precision))
               Group Key: time_bucket('@ 2 days'::interval, hyper1d."time"), hyper1d.device
               ->  Custom Scan (DataNodeScan) on public.hyper1d
                     Output: time_bucket('@ 2 days'::interval, hyper1d."time"), hyper1d.device, hyper1d.temp
                     Data node: data_node_1
                     Chunks: _dist_hyper_2_19_chunk
                     Remote SQL: SELECT "time", device, temp FROM public.hyper1d WHERE _timescaledb_internal.chunks_in(public.hyper1d.*, ARRAY[8]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) ORDER BY public.time_bucket('2 days'::interval, "time") ASC NULLS LAST, device ASC NULLS LAST
         ->  Partial GroupAggregate
               Output: (time_bucket('@ 2 days'::interval, hyper1d_1."time")), hyper1d_1.device, PARTIAL avg(hyper1d_1.temp), PARTIAL sum((hyper1d_1.temp * (((random() <= '1'::double precision))::integer)::double precision))
               Group Key: time_bucket('@ 2 days'::interval, hyper1d_1."time"), hyper1d_1.device
               ->  Custom Scan (DataNodeScan) on public.hyper1d hyper1d_1
                     Output: time_bucket('@ 2 days'::interval, hyper1d_1."time"), hyper1d_1.device, hyper1d_1.temp
                     Data node: data_node_2
                     Chunks: _dist_hyper_2_20_chunk
                     Remote SQL: SELECT "time", device, temp FROM public.hyper1d WHERE _timescaledb_internal.chunks_in(public.hyper1d.*, ARRAY[8]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) ORDER BY public.time_bucket('2 days'::interval, "time") ASC NULLS LAST, device ASC NULLS LAST
         ->  Partial GroupAggregate
               Output: (time_bucket('@ 2 days'::interval, hyper1d_2."time")), hyper1d_2.device, PARTIAL avg(hyper1d_2.temp), PARTIAL sum((hyper1d_2.temp * (((random() <= '1'::double precision))::integer)::double precision))
               Group Key: time_bucket('@ 2 days'::interval, hyper1d_2."time"), hyper1d_2.device
               ->  Custom Scan (DataNodeScan) on public.hyper1d hyper1d_2
                     Output: time_bucket('@ 2 days'::interval, hyper1d_2."time"), hyper1d_2.device, hyper1d_2.temp
                     Data node: data_node_3
                     Chunks: _dist_hyper_2_21_chunk
                     Remote SQL: SELECT "time", device, temp FROM public.hyper1d WHERE _timescaledb_internal.chunks_in(public.hyper1d.*, ARRAY[5]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) ORDER BY public.time_bucket('2 days'::interval, "time") ASC NULLS LAST, device ASC NULLS LAST
(29 rows)


######### No push down on some functions

EXPLAIN (verbose, costs off)
SELECT time, device, avg(temp)
FROM hyper1d
WHERE time >= '2019-01-01'
GROUP BY 1,2
HAVING avg(temp) * custom_sum(device) > 0.8


                                                                                                                                  QUERY PLAN                                                                                                                                  
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Custom Scan (AsyncAppend)
   Output: "time", device, (avg(temp))
   ->  Append
         ->  GroupAggregate
               Output: hyper1d."time", hyper1d.device, avg(hyper1d.temp)
               Group Key: hyper1d."time", hyper1d.device
               Filter: ((avg(hyper1d.temp) * (custom_sum(hyper1d.device))::double precision) > '0.8'::double precision)
               ->  Custom Scan (DataNodeScan) on public.hyper1d
                     Output: hyper1d."time", hyper1d.device, hyper1d.temp
                     Data node: data_node_1
                     Chunks: _dist_hyper_2_19_chunk
                     Remote SQL: SELECT "time", device, temp FROM public.hyper1d WHERE _timescaledb_internal.chunks_in(public.hyper1d.*, ARRAY[8]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST
         ->  GroupAggregate
               Output: hyper1d_1."time", hyper1d_1.device, avg(hyper1d_1.temp)
               Group Key: hyper1d_1."time", hyper1d_1.device
               Filter: ((avg(hyper1d_1.temp) * (custom_sum(hyper1d_1.device))::double precision) > '0.8'::double precision)
               ->  Custom Scan (DataNodeScan) on public.hyper1d hyper1d_1
                     Output: hyper1d_1."time", hyper1d_1.device, hyper1d_1.temp
                     Data node: data_node_2
                     Chunks: _dist_hyper_2_20_chunk
                     Remote SQL: SELECT "time", device, temp FROM public.hyper1d WHERE _timescaledb_internal.chunks_in(public.hyper1d.*, ARRAY[8]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST
         ->  GroupAggregate
               Output: hyper1d_2."time", hyper1d_2.device, avg(hyper1d_2.temp)
               Group Key: hyper1d_2."time", hyper1d_2.device
               Filter: ((avg(hyper1d_2.temp) * (custom_sum(hyper1d_2.device))::double precision) > '0.8'::double precision)
               ->  Custom Scan (DataNodeScan) on public.hyper1d hyper1d_2
                     Output: hyper1d_2."time", hyper1d_2.device, hyper1d_2.temp
                     Data node: data_node_3
                     Chunks: _dist_hyper_2_21_chunk
                     Remote SQL: SELECT "time", device, temp FROM public.hyper1d WHERE _timescaledb_internal.chunks_in(public.hyper1d.*, ARRAY[5]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST
(30 rows)


######### No push down on some functions

EXPLAIN (verbose, costs off)
SELECT time, device, avg(temp), custom_sum(device)
FROM hyper1d
WHERE time >= '2019-01-01'
GROUP BY 1,2


                                                                                                                                  QUERY PLAN                                                                                                                                  
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Custom Scan (AsyncAppend)
   Output: "time", device, (avg(temp)), (custom_sum(device))
   ->  Append
         ->  GroupAggregate
               Output: hyper1d."time", hyper1d.device, avg(hyper1d.temp), custom_sum(hyper1d.device)
               Group Key: hyper1d."time", hyper1d.device
               ->  Custom Scan (DataNodeScan) on public.hyper1d
                     Output: hyper1d."time", hyper1d.device, hyper1d.temp
                     Data node: data_node_1
                     Chunks: _dist_hyper_2_19_chunk
                     Remote SQL: SELECT "time", device, temp FROM public.hyper1d WHERE _timescaledb_internal.chunks_in(public.hyper1d.*, ARRAY[8]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST
         ->  GroupAggregate
               Output: hyper1d_1."time", hyper1d_1.device, avg(hyper1d_1.temp), custom_sum(hyper1d_1.device)
               Group Key: hyper1d_1."time", hyper1d_1.device
               ->  Custom Scan (DataNodeScan) on public.hyper1d hyper1d_1
                     Output: hyper1d_1."time", hyper1d_1.device, hyper1d_1.temp
                     Data node: data_node_2
                     Chunks: _dist_hyper_2_20_chunk
                     Remote SQL: SELECT "time", device, temp FROM public.hyper1d WHERE _timescaledb_internal.chunks_in(public.hyper1d.*, ARRAY[8]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST
         ->  GroupAggregate
               Output: hyper1d_2."time", hyper1d_2.device, avg(hyper1d_2.temp), custom_sum(hyper1d_2.device)
               Group Key: hyper1d_2."time", hyper1d_2.device
               ->  Custom Scan (DataNodeScan) on public.hyper1d hyper1d_2
                     Output: hyper1d_2."time", hyper1d_2.device, hyper1d_2.temp
                     Data node: data_node_3
                     Chunks: _dist_hyper_2_21_chunk
                     Remote SQL: SELECT "time", device, temp FROM public.hyper1d WHERE _timescaledb_internal.chunks_in(public.hyper1d.*, ARRAY[5]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) ORDER BY "time" ASC NULLS LAST, device ASC NULLS LAST
(27 rows)


######### Constification and runtime push down of time-related functions

 tsl_override_current_timestamptz 
----------------------------------
 
(1 row)

                                                                                                             QUERY PLAN                                                                                                              
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Custom Scan (AsyncAppend)
   Output: "time", device, (avg(temp))
   ->  Append
         ->  Custom Scan (DataNodeScan)
               Output: hyper1d."time", hyper1d.device, (avg(hyper1d.temp))
               Relations: Aggregate on (public.hyper1d)
               Data node: data_node_1
               Chunks: _dist_hyper_2_19_chunk
               Remote SQL: SELECT "time", device, avg(temp) FROM public.hyper1d WHERE _timescaledb_internal.chunks_in(public.hyper1d.*, ARRAY[8]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) GROUP BY 1, 2
         ->  Custom Scan (DataNodeScan)
               Output: hyper1d_1."time", hyper1d_1.device, (avg(hyper1d_1.temp))
               Relations: Aggregate on (public.hyper1d)
               Data node: data_node_2
               Chunks: _dist_hyper_2_20_chunk
               Remote SQL: SELECT "time", device, avg(temp) FROM public.hyper1d WHERE _timescaledb_internal.chunks_in(public.hyper1d.*, ARRAY[8]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) GROUP BY 1, 2
         ->  Custom Scan (DataNodeScan)
               Output: hyper1d_2."time", hyper1d_2.device, (avg(hyper1d_2.temp))
               Relations: Aggregate on (public.hyper1d)
               Data node: data_node_3
               Chunks: _dist_hyper_2_21_chunk
               Remote SQL: SELECT "time", device, avg(temp) FROM public.hyper1d WHERE _timescaledb_internal.chunks_in(public.hyper1d.*, ARRAY[5]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) GROUP BY 1, 2
(21 rows)

                                                                                                             QUERY PLAN                                                                                                              
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Custom Scan (AsyncAppend)
   Output: "time", device, (avg(temp))
   ->  Append
         ->  Custom Scan (DataNodeScan)
               Output: hyper1d."time", hyper1d.device, (avg(hyper1d.temp))
               Relations: Aggregate on (public.hyper1d)
               Data node: data_node_1
               Chunks: _dist_hyper_2_19_chunk
               Remote SQL: SELECT "time", device, avg(temp) FROM public.hyper1d WHERE _timescaledb_internal.chunks_in(public.hyper1d.*, ARRAY[8]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) GROUP BY 1, 2
         ->  Custom Scan (DataNodeScan)
               Output: hyper1d_1."time", hyper1d_1.device, (avg(hyper1d_1.temp))
               Relations: Aggregate on (public.hyper1d)
               Data node: data_node_2
               Chunks: _dist_hyper_2_20_chunk
               Remote SQL: SELECT "time", device, avg(temp) FROM public.hyper1d WHERE _timescaledb_internal.chunks_in(public.hyper1d.*, ARRAY[8]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) GROUP BY 1, 2
         ->  Custom Scan (DataNodeScan)
               Output: hyper1d_2."time", hyper1d_2.device, (avg(hyper1d_2.temp))
               Relations: Aggregate on (public.hyper1d)
               Data node: data_node_3
               Chunks: _dist_hyper_2_21_chunk
               Remote SQL: SELECT "time", device, avg(temp) FROM public.hyper1d WHERE _timescaledb_internal.chunks_in(public.hyper1d.*, ARRAY[5]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) GROUP BY 1, 2
(21 rows)

 tsl_override_current_timestamptz 
----------------------------------
 
(1 row)

                                                                                                             QUERY PLAN                                                                                                              
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Custom Scan (AsyncAppend)
   Output: "time", device, (avg(temp))
   ->  Append
         ->  Custom Scan (DataNodeScan)
               Output: hyper1d."time", hyper1d.device, (avg(hyper1d.temp))
               Relations: Aggregate on (public.hyper1d)
               Data node: data_node_1
               Chunks: _dist_hyper_2_19_chunk
               Remote SQL: SELECT "time", device, avg(temp) FROM public.hyper1d WHERE _timescaledb_internal.chunks_in(public.hyper1d.*, ARRAY[8]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) GROUP BY 1, 2
         ->  Custom Scan (DataNodeScan)
               Output: hyper1d_1."time", hyper1d_1.device, (avg(hyper1d_1.temp))
               Relations: Aggregate on (public.hyper1d)
               Data node: data_node_2
               Chunks: _dist_hyper_2_20_chunk
               Remote SQL: SELECT "time", device, avg(temp) FROM public.hyper1d WHERE _timescaledb_internal.chunks_in(public.hyper1d.*, ARRAY[8]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) GROUP BY 1, 2
         ->  Custom Scan (DataNodeScan)
               Output: hyper1d_2."time", hyper1d_2.device, (avg(hyper1d_2.temp))
               Relations: Aggregate on (public.hyper1d)
               Data node: data_node_3
               Chunks: _dist_hyper_2_21_chunk
               Remote SQL: SELECT "time", device, avg(temp) FROM public.hyper1d WHERE _timescaledb_internal.chunks_in(public.hyper1d.*, ARRAY[5]) AND (("time" >= '2019-01-01 00:00:00-08'::timestamp with time zone)) GROUP BY 1, 2
(21 rows)


######### LIMIT push down cases

EXPLAIN (verbose, costs off)
SELECT time, device
FROM hyper1d

LIMIT 10
                                                                      QUERY PLAN                                                                      
------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit
   Output: hyper1d."time", hyper1d.device
   ->  Custom Scan (AsyncAppend)
         Output: hyper1d."time", hyper1d.device
         ->  Append
               ->  Custom Scan (DataNodeScan) on public.hyper1d hyper1d_1
                     Output: hyper1d_1."time", hyper1d_1.device
                     Data node: data_node_1
                     Chunks: _dist_hyper_2_19_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper1d WHERE _timescaledb_internal.chunks_in(public.hyper1d.*, ARRAY[8]) LIMIT 10
               ->  Custom Scan (DataNodeScan) on public.hyper1d hyper1d_2
                     Output: hyper1d_2."time", hyper1d_2.device
                     Data node: data_node_2
                     Chunks: _dist_hyper_2_20_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper1d WHERE _timescaledb_internal.chunks_in(public.hyper1d.*, ARRAY[8]) LIMIT 10
               ->  Custom Scan (DataNodeScan) on public.hyper1d hyper1d_3
                     Output: hyper1d_3."time", hyper1d_3.device
                     Data node: data_node_3
                     Chunks: _dist_hyper_2_21_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper1d WHERE _timescaledb_internal.chunks_in(public.hyper1d.*, ARRAY[5]) LIMIT 10
(20 rows)


######### LIMIT push down cases

EXPLAIN (verbose, costs off)
SELECT time, device
FROM hyper1d

LIMIT 5
OFFSET 5
                                                                      QUERY PLAN                                                                      
------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit
   Output: hyper1d."time", hyper1d.device
   ->  Custom Scan (AsyncAppend)
         Output: hyper1d."time", hyper1d.device
         ->  Append
               ->  Custom Scan (DataNodeScan) on public.hyper1d hyper1d_1
                     Output: hyper1d_1."time", hyper1d_1.device
                     Data node: data_node_1
                     Chunks: _dist_hyper_2_19_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper1d WHERE _timescaledb_internal.chunks_in(public.hyper1d.*, ARRAY[8]) LIMIT 10
               ->  Custom Scan (DataNodeScan) on public.hyper1d hyper1d_2
                     Output: hyper1d_2."time", hyper1d_2.device
                     Data node: data_node_2
                     Chunks: _dist_hyper_2_20_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper1d WHERE _timescaledb_internal.chunks_in(public.hyper1d.*, ARRAY[8]) LIMIT 10
               ->  Custom Scan (DataNodeScan) on public.hyper1d hyper1d_3
                     Output: hyper1d_3."time", hyper1d_3.device
                     Data node: data_node_3
                     Chunks: _dist_hyper_2_21_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper1d WHERE _timescaledb_internal.chunks_in(public.hyper1d.*, ARRAY[5]) LIMIT 10
(20 rows)


######### LIMIT push down cases

EXPLAIN (verbose, costs off)
SELECT time, device
FROM hyper1d

LIMIT 0
                                                                     QUERY PLAN                                                                      
-----------------------------------------------------------------------------------------------------------------------------------------------------
 Limit
   Output: hyper1d."time", hyper1d.device
   ->  Custom Scan (AsyncAppend)
         Output: hyper1d."time", hyper1d.device
         ->  Append
               ->  Custom Scan (DataNodeScan) on public.hyper1d hyper1d_1
                     Output: hyper1d_1."time", hyper1d_1.device
                     Data node: data_node_1
                     Chunks: _dist_hyper_2_19_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper1d WHERE _timescaledb_internal.chunks_in(public.hyper1d.*, ARRAY[8]) LIMIT 1
               ->  Custom Scan (DataNodeScan) on public.hyper1d hyper1d_2
                     Output: hyper1d_2."time", hyper1d_2.device
                     Data node: data_node_2
                     Chunks: _dist_hyper_2_20_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper1d WHERE _timescaledb_internal.chunks_in(public.hyper1d.*, ARRAY[8]) LIMIT 1
               ->  Custom Scan (DataNodeScan) on public.hyper1d hyper1d_3
                     Output: hyper1d_3."time", hyper1d_3.device
                     Data node: data_node_3
                     Chunks: _dist_hyper_2_21_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper1d WHERE _timescaledb_internal.chunks_in(public.hyper1d.*, ARRAY[5]) LIMIT 1
(20 rows)


######### LIMIT push down cases

EXPLAIN (verbose, costs off)
SELECT time, device
FROM hyper1d

LIMIT extract(year from date '2000-01-01')
                                                                       QUERY PLAN                                                                       
--------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit
   Output: hyper1d."time", hyper1d.device
   ->  Custom Scan (AsyncAppend)
         Output: hyper1d."time", hyper1d.device
         ->  Append
               ->  Custom Scan (DataNodeScan) on public.hyper1d hyper1d_1
                     Output: hyper1d_1."time", hyper1d_1.device
                     Data node: data_node_1
                     Chunks: _dist_hyper_2_19_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper1d WHERE _timescaledb_internal.chunks_in(public.hyper1d.*, ARRAY[8]) LIMIT 2000
               ->  Custom Scan (DataNodeScan) on public.hyper1d hyper1d_2
                     Output: hyper1d_2."time", hyper1d_2.device
                     Data node: data_node_2
                     Chunks: _dist_hyper_2_20_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper1d WHERE _timescaledb_internal.chunks_in(public.hyper1d.*, ARRAY[8]) LIMIT 2000
               ->  Custom Scan (DataNodeScan) on public.hyper1d hyper1d_3
                     Output: hyper1d_3."time", hyper1d_3.device
                     Data node: data_node_3
                     Chunks: _dist_hyper_2_21_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper1d WHERE _timescaledb_internal.chunks_in(public.hyper1d.*, ARRAY[5]) LIMIT 2000
(20 rows)


######### LIMIT push down cases

EXPLAIN (verbose, costs off)
SELECT time, device
FROM hyper1d

LIMIT greatest(random(), 10.0)
                                                                 QUERY PLAN                                                                  
---------------------------------------------------------------------------------------------------------------------------------------------
 Limit
   Output: hyper1d."time", hyper1d.device
   ->  Custom Scan (AsyncAppend)
         Output: hyper1d."time", hyper1d.device
         ->  Append
               ->  Custom Scan (DataNodeScan) on public.hyper1d hyper1d_1
                     Output: hyper1d_1."time", hyper1d_1.device
                     Data node: data_node_1
                     Chunks: _dist_hyper_2_19_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper1d WHERE _timescaledb_internal.chunks_in(public.hyper1d.*, ARRAY[8])
               ->  Custom Scan (DataNodeScan) on public.hyper1d hyper1d_2
                     Output: hyper1d_2."time", hyper1d_2.device
                     Data node: data_node_2
                     Chunks: _dist_hyper_2_20_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper1d WHERE _timescaledb_internal.chunks_in(public.hyper1d.*, ARRAY[8])
               ->  Custom Scan (DataNodeScan) on public.hyper1d hyper1d_3
                     Output: hyper1d_3."time", hyper1d_3.device
                     Data node: data_node_3
                     Chunks: _dist_hyper_2_21_chunk
                     Remote SQL: SELECT "time", device FROM public.hyper1d WHERE _timescaledb_internal.chunks_in(public.hyper1d.*, ARRAY[5])
(20 rows)


######### LIMIT push down cases

EXPLAIN (verbose, costs off)
SELECT time, device, avg(temp) OVER (PARTITION BY device)
FROM hyper1d

LIMIT 10
                                                                                       QUERY PLAN                                                                                       
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit
   Output: hyper1d."time", hyper1d.device, (avg(hyper1d.temp) OVER (?))
   ->  WindowAgg
         Output: hyper1d."time", hyper1d.device, avg(hyper1d.temp) OVER (?)
         ->  Custom Scan (AsyncAppend)
               Output: hyper1d.device, hyper1d."time", hyper1d.temp
               ->  Merge Append
                     Sort Key: hyper1d_1.device
                     ->  Custom Scan (DataNodeScan) on public.hyper1d hyper1d_1
                           Output: hyper1d_1.device, hyper1d_1."time", hyper1d_1.temp
                           Data node: data_node_1
                           Chunks: _dist_hyper_2_19_chunk
                           Remote SQL: SELECT "time", device, temp FROM public.hyper1d WHERE _timescaledb_internal.chunks_in(public.hyper1d.*, ARRAY[8]) ORDER BY device ASC NULLS LAST
                     ->  Custom Scan (DataNodeScan) on public.hyper1d hyper1d_2
                           Output: hyper1d_2.device, hyper1d_2."time", hyper1d_2.temp
                           Data node: data_node_2
                           Chunks: _dist_hyper_2_20_chunk
                           Remote SQL: SELECT "time", device, temp FROM public.hyper1d WHERE _timescaledb_internal.chunks_in(public.hyper1d.*, ARRAY[8]) ORDER BY device ASC NULLS LAST
                     ->  Custom Scan (DataNodeScan) on public.hyper1d hyper1d_3
                           Output: hyper1d_3.device, hyper1d_3."time", hyper1d_3.temp
                           Data node: data_node_3
                           Chunks: _dist_hyper_2_21_chunk
                           Remote SQL: SELECT "time", device, temp FROM public.hyper1d WHERE _timescaledb_internal.chunks_in(public.hyper1d.*, ARRAY[5]) ORDER BY device ASC NULLS LAST
(23 rows)


######### LIMIT push down cases

EXPLAIN (verbose, costs off)
SELECT DISTINCT device, time
FROM hyper1d

LIMIT 10
                                                                                               QUERY PLAN                                                                                                
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit
   Output: hyper1d.device, hyper1d."time"
   ->  Unique
         Output: hyper1d.device, hyper1d."time"
         ->  Custom Scan (AsyncAppend)
               Output: hyper1d.device, hyper1d."time"
               ->  Merge Append
                     Sort Key: hyper1d_1.device, hyper1d_1."time"
                     ->  Custom Scan (DataNodeScan) on public.hyper1d hyper1d_1
                           Output: hyper1d_1.device, hyper1d_1."time"
                           Data node: data_node_1
                           Chunks: _dist_hyper_2_19_chunk
                           Remote SQL: SELECT "time", device FROM public.hyper1d WHERE _timescaledb_internal.chunks_in(public.hyper1d.*, ARRAY[8]) ORDER BY device ASC NULLS LAST, "time" ASC NULLS LAST
                     ->  Custom Scan (DataNodeScan) on public.hyper1d hyper1d_2
                           Output: hyper1d_2.device, hyper1d_2."time"
                           Data node: data_node_2
                           Chunks: _dist_hyper_2_20_chunk
                           Remote SQL: SELECT "time", device FROM public.hyper1d WHERE _timescaledb_internal.chunks_in(public.hyper1d.*, ARRAY[8]) ORDER BY device ASC NULLS LAST, "time" ASC NULLS LAST
                     ->  Custom Scan (DataNodeScan) on public.hyper1d hyper1d_3
                           Output: hyper1d_3.device, hyper1d_3."time"
                           Data node: data_node_3
                           Chunks: _dist_hyper_2_21_chunk
                           Remote SQL: SELECT "time", device FROM public.hyper1d WHERE _timescaledb_internal.chunks_in(public.hyper1d.*, ARRAY[5]) ORDER BY device ASC NULLS LAST, "time" ASC NULLS LAST
(23 rows)


######### LIMIT push down cases

EXPLAIN (verbose, costs off)
SELECT DISTINCT ON (device) device, time
FROM hyper1d

LIMIT 10
                                                                                    QUERY PLAN                                                                                    
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit
   Output: hyper1d.device, hyper1d."time"
   ->  Unique
         Output: hyper1d.device, hyper1d."time"
         ->  Custom Scan (AsyncAppend)
               Output: hyper1d.device, hyper1d."time"
               ->  Merge Append
                     Sort Key: hyper1d_1.device
                     ->  Custom Scan (DataNodeScan) on public.hyper1d hyper1d_1
                           Output: hyper1d_1.device, hyper1d_1."time"
                           Data node: data_node_1
                           Chunks: _dist_hyper_2_19_chunk
                           Remote SQL: SELECT "time", device FROM public.hyper1d WHERE _timescaledb_internal.chunks_in(public.hyper1d.*, ARRAY[8]) ORDER BY device ASC NULLS LAST
                     ->  Custom Scan (DataNodeScan) on public.hyper1d hyper1d_2
                           Output: hyper1d_2.device, hyper1d_2."time"
                           Data node: data_node_2
                           Chunks: _dist_hyper_2_20_chunk
                           Remote SQL: SELECT "time", device FROM public.hyper1d WHERE _timescaledb_internal.chunks_in(public.hyper1d.*, ARRAY[8]) ORDER BY device ASC NULLS LAST
                     ->  Custom Scan (DataNodeScan) on public.hyper1d hyper1d_3
                           Output: hyper1d_3.device, hyper1d_3."time"
                           Data node: data_node_3
                           Chunks: _dist_hyper_2_21_chunk
                           Remote SQL: SELECT "time", device FROM public.hyper1d WHERE _timescaledb_internal.chunks_in(public.hyper1d.*, ARRAY[5]) ORDER BY device ASC NULLS LAST
(23 rows)


######### LIMIT push down cases

                                                                    QUERY PLAN                                                                     
---------------------------------------------------------------------------------------------------------------------------------------------------
 Limit
   Output: t."time"
   ->  Nested Loop
         Output: t."time"
         Join Filter: (t.device = join_test.device)
         ->  Custom Scan (AsyncAppend)
               Output: t."time", t.device
               ->  Append
                     ->  Custom Scan (DataNodeScan) on public.hyper1d t_1
                           Output: t_1."time", t_1.device
                           Data node: data_node_1
                           Chunks: _dist_hyper_2_19_chunk
                           Remote SQL: SELECT "time", device FROM public.hyper1d WHERE _timescaledb_internal.chunks_in(public.hyper1d.*, ARRAY[8])
                     ->  Custom Scan (DataNodeScan) on public.hyper1d t_2
                           Output: t_2."time", t_2.device
                           Data node: data_node_2
                           Chunks: _dist_hyper_2_20_chunk
                           Remote SQL: SELECT "time", device FROM public.hyper1d WHERE _timescaledb_internal.chunks_in(public.hyper1d.*, ARRAY[8])
                     ->  Custom Scan (DataNodeScan) on public.hyper1d t_3
                           Output: t_3."time", t_3.device
                           Data node: data_node_3
                           Chunks: _dist_hyper_2_21_chunk
                           Remote SQL: SELECT "time", device FROM public.hyper1d WHERE _timescaledb_internal.chunks_in(public.hyper1d.*, ARRAY[5])
         ->  Materialize
               Output: join_test.device
               ->  Seq Scan on public.join_test
                     Output: join_test.device
(27 rows)

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% RUNNING TESTS on table: reference
%%% PREFIX: 
%%% WHERE_CLAUSE: :REPARTITIONED_TIME_RANGE
%%% ORDER_BY_1: ORDER BY 1
%%% ORDER_BY_1_2: ORDER BY 1,2
%%% LIMIT: 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% RUNNING TESTS on table: hyper
%%% PREFIX: 
%%% WHERE_CLAUSE: :REPARTITIONED_TIME_RANGE
%%% ORDER_BY_1: ORDER BY 1
%%% ORDER_BY_1_2: ORDER BY 1,2
%%% LIMIT: 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% RUNNING TESTS on table: reference
%%% PREFIX: 
%%% WHERE_CLAUSE: :CLEAN_PARTITIONING_TIME_RANGE
%%% ORDER_BY_1: ORDER BY 1
%%% ORDER_BY_1_2: ORDER BY 1,2
%%% LIMIT: 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% RUNNING TESTS on table: hyper
%%% PREFIX: 
%%% WHERE_CLAUSE: :CLEAN_PARTITIONING_TIME_RANGE
%%% ORDER_BY_1: ORDER BY 1
%%% ORDER_BY_1_2: ORDER BY 1,2
%%% LIMIT: 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% RUNNING TESTS on table: hyper
%%% PREFIX: 
%%% WHERE_CLAUSE: :CLEAN_PARTITIONING_TIME_RANGE
%%% ORDER_BY_1: ORDER BY 1
%%% ORDER_BY_1_2: ORDER BY 1,2
%%% LIMIT: 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% RUNNING TESTS on table: hyper1d
%%% PREFIX: 
%%% WHERE_CLAUSE: :REPARTITIONED_TIME_RANGE
%%% ORDER_BY_1: ORDER BY 1
%%% ORDER_BY_1_2: ORDER BY 1,2
%%% LIMIT: 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
:DIFF_CMD_UNOPT
:DIFF_CMD_OPT
:DIFF_CMD_REPART
:DIFF_CMD_1DIM
