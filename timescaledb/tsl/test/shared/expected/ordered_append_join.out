-- This file and its contents are licensed under the Timescale License.
-- Please see the included NOTICE for copyright information and
-- LICENSE-TIMESCALE for a copy of the license.
SELECT
       format('include/%s.sql', :'TEST_BASE_NAME') as "TEST_QUERY_NAME",
       format('%s/shared/results/%s_results_uncompressed.out', :'TEST_OUTPUT_DIR', :'TEST_BASE_NAME') as "TEST_RESULTS_UNCOMPRESSED",
       format('%s/shared/results/%s_results_compressed.out', :'TEST_OUTPUT_DIR', :'TEST_BASE_NAME') as "TEST_RESULTS_COMPRESSED"
\gset
SELECT format('\! diff -u --label "Uncompressed results" --label "Compressed results" %s %s', :'TEST_RESULTS_UNCOMPRESSED', :'TEST_RESULTS_COMPRESSED') as "DIFF_CMD"
\gset
-- get EXPLAIN output for all variations
\set PREFIX 'EXPLAIN (analyze, costs off, timing off, summary off)'
\set PREFIX_VERBOSE 'EXPLAIN (analyze, costs off, timing off, summary off, verbose)'
set work_mem to '64MB';
set max_parallel_workers_per_gather to 0;
\set TEST_TABLE 'metrics'
\ir :TEST_QUERY_NAME
-- This file and its contents are licensed under the Timescale License.
-- Please see the included NOTICE for copyright information and
-- LICENSE-TIMESCALE for a copy of the license.
-- test LATERAL with ordered append in the outer query
:PREFIX
SELECT time,
  pg_typeof(l)
FROM :TEST_TABLE,
  LATERAL (
    SELECT *
    FROM (
      VALUES (1),
        (2)) v) l
ORDER BY time DESC
LIMIT 2;
                                                      QUERY PLAN                                                       
-----------------------------------------------------------------------------------------------------------------------
 Limit (actual rows=2 loops=1)
   ->  Nested Loop (actual rows=2 loops=1)
         ->  Custom Scan (ChunkAppend) on metrics (actual rows=1 loops=1)
               Order: metrics."time" DESC
               ->  Index Only Scan using _hyper_1_3_chunk_metrics_time_idx on _hyper_1_3_chunk (actual rows=1 loops=1)
                     Heap Fetches: 1
               ->  Index Only Scan using _hyper_1_2_chunk_metrics_time_idx on _hyper_1_2_chunk (never executed)
                     Heap Fetches: 0
               ->  Index Only Scan using _hyper_1_1_chunk_metrics_time_idx on _hyper_1_1_chunk (never executed)
                     Heap Fetches: 0
         ->  Materialize (actual rows=2 loops=1)
               ->  Values Scan on "*VALUES*" (actual rows=2 loops=1)
(12 rows)

-- test LATERAL with ordered append in the lateral query
:PREFIX
SELECT time,
  pg_typeof(v)
FROM (
  VALUES (1),
    (2)) v,
  LATERAL (
    SELECT *
    FROM :TEST_TABLE
    ORDER BY time DESC
    LIMIT 2) l;
                                                            QUERY PLAN                                                             
-----------------------------------------------------------------------------------------------------------------------------------
 Nested Loop (actual rows=4 loops=1)
   ->  Values Scan on "*VALUES*" (actual rows=2 loops=1)
   ->  Materialize (actual rows=2 loops=2)
         ->  Subquery Scan on l (actual rows=2 loops=1)
               ->  Limit (actual rows=2 loops=1)
                     ->  Custom Scan (ChunkAppend) on metrics (actual rows=2 loops=1)
                           Order: metrics."time" DESC
                           ->  Index Only Scan using _hyper_1_3_chunk_metrics_time_idx on _hyper_1_3_chunk (actual rows=2 loops=1)
                                 Heap Fetches: 2
                           ->  Index Only Scan using _hyper_1_2_chunk_metrics_time_idx on _hyper_1_2_chunk (never executed)
                                 Heap Fetches: 0
                           ->  Index Only Scan using _hyper_1_1_chunk_metrics_time_idx on _hyper_1_1_chunk (never executed)
                                 Heap Fetches: 0
(13 rows)

-- test plan with best index is chosen
-- this should use device_id, time index
:PREFIX
SELECT time,
  device_id
FROM :TEST_TABLE
WHERE device_id = 1
ORDER BY time DESC
LIMIT 1;
                                                        QUERY PLAN                                                         
---------------------------------------------------------------------------------------------------------------------------
 Limit (actual rows=1 loops=1)
   ->  Custom Scan (ChunkAppend) on metrics (actual rows=1 loops=1)
         Order: metrics."time" DESC
         ->  Index Only Scan using _hyper_1_3_chunk_metrics_device_id_time_idx on _hyper_1_3_chunk (actual rows=1 loops=1)
               Index Cond: (device_id = 1)
               Heap Fetches: 1
         ->  Index Only Scan using _hyper_1_2_chunk_metrics_device_id_time_idx on _hyper_1_2_chunk (never executed)
               Index Cond: (device_id = 1)
               Heap Fetches: 0
         ->  Index Only Scan using _hyper_1_1_chunk_metrics_device_id_time_idx on _hyper_1_1_chunk (never executed)
               Index Cond: (device_id = 1)
               Heap Fetches: 0
(12 rows)

-- test plan with best index is chosen
-- this should use time index
:PREFIX
SELECT time
FROM :TEST_TABLE
ORDER BY time DESC
LIMIT 1;
                                                   QUERY PLAN                                                    
-----------------------------------------------------------------------------------------------------------------
 Limit (actual rows=1 loops=1)
   ->  Custom Scan (ChunkAppend) on metrics (actual rows=1 loops=1)
         Order: metrics."time" DESC
         ->  Index Only Scan using _hyper_1_3_chunk_metrics_time_idx on _hyper_1_3_chunk (actual rows=1 loops=1)
               Heap Fetches: 1
         ->  Index Only Scan using _hyper_1_2_chunk_metrics_time_idx on _hyper_1_2_chunk (never executed)
               Heap Fetches: 0
         ->  Index Only Scan using _hyper_1_1_chunk_metrics_time_idx on _hyper_1_1_chunk (never executed)
               Heap Fetches: 0
(9 rows)

-- test LATERAL with correlated query
-- only last chunk should be executed
:PREFIX
SELECT g.time,
  l.time
FROM generate_series('2000-01-01'::timestamptz, '2000-01-03', '1d') AS g (time)
  LEFT OUTER JOIN LATERAL (
  SELECT *
  FROM :TEST_TABLE o
  WHERE o.time >= g.time
    AND o.time < g.time + '1d'::interval
  ORDER BY time DESC
  LIMIT 1) l ON TRUE;
                                                        QUERY PLAN                                                         
---------------------------------------------------------------------------------------------------------------------------
 Nested Loop Left Join (actual rows=3 loops=1)
   ->  Function Scan on generate_series g (actual rows=3 loops=1)
   ->  Limit (actual rows=1 loops=3)
         ->  Custom Scan (ChunkAppend) on metrics o (actual rows=1 loops=3)
               Order: o."time" DESC
               Chunks excluded during startup: 0
               Chunks excluded during runtime: 2
               ->  Index Only Scan using _hyper_1_3_chunk_metrics_time_idx on _hyper_1_3_chunk o_1 (never executed)
                     Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                     Heap Fetches: 0
               ->  Index Only Scan using _hyper_1_2_chunk_metrics_time_idx on _hyper_1_2_chunk o_2 (never executed)
                     Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                     Heap Fetches: 0
               ->  Index Only Scan using _hyper_1_1_chunk_metrics_time_idx on _hyper_1_1_chunk o_3 (actual rows=1 loops=3)
                     Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                     Heap Fetches: 3
(16 rows)

-- test LATERAL with correlated query
-- only 2nd chunk should be executed
:PREFIX
SELECT g.time,
  l.time
FROM generate_series('2000-01-10'::timestamptz, '2000-01-11', '1d') AS g (time)
  LEFT OUTER JOIN LATERAL (
  SELECT *
  FROM :TEST_TABLE o
  WHERE o.time >= g.time
    AND o.time < g.time + '1d'::interval
  ORDER BY time
  LIMIT 1) l ON TRUE;
                                                             QUERY PLAN                                                             
------------------------------------------------------------------------------------------------------------------------------------
 Nested Loop Left Join (actual rows=2 loops=1)
   ->  Function Scan on generate_series g (actual rows=2 loops=1)
   ->  Limit (actual rows=1 loops=2)
         ->  Custom Scan (ChunkAppend) on metrics o (actual rows=1 loops=2)
               Order: o."time"
               Chunks excluded during startup: 0
               Chunks excluded during runtime: 2
               ->  Index Only Scan Backward using _hyper_1_1_chunk_metrics_time_idx on _hyper_1_1_chunk o_1 (never executed)
                     Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                     Heap Fetches: 0
               ->  Index Only Scan Backward using _hyper_1_2_chunk_metrics_time_idx on _hyper_1_2_chunk o_2 (actual rows=1 loops=2)
                     Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                     Heap Fetches: 2
               ->  Index Only Scan Backward using _hyper_1_3_chunk_metrics_time_idx on _hyper_1_3_chunk o_3 (never executed)
                     Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                     Heap Fetches: 0
(16 rows)

-- test startup and runtime exclusion together
:PREFIX
SELECT g.time,
  l.time
FROM generate_series('2000-01-01'::timestamptz, '2000-01-03', '1d') AS g (time)
  LEFT OUTER JOIN LATERAL (
  SELECT *
  FROM :TEST_TABLE o
  WHERE o.time >= g.time
    AND o.time < g.time + '1d'::interval
    AND o.time < now()
  ORDER BY time DESC
  LIMIT 1) l ON TRUE;
                                                         QUERY PLAN                                                          
-----------------------------------------------------------------------------------------------------------------------------
 Nested Loop Left Join (actual rows=3 loops=1)
   ->  Function Scan on generate_series g (actual rows=3 loops=1)
   ->  Limit (actual rows=1 loops=3)
         ->  Custom Scan (ChunkAppend) on metrics o (actual rows=1 loops=3)
               Order: o."time" DESC
               Chunks excluded during startup: 0
               Chunks excluded during runtime: 2
               ->  Index Only Scan using _hyper_1_3_chunk_metrics_time_idx on _hyper_1_3_chunk o_1 (never executed)
                     Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)) AND ("time" < now()))
                     Heap Fetches: 0
               ->  Index Only Scan using _hyper_1_2_chunk_metrics_time_idx on _hyper_1_2_chunk o_2 (never executed)
                     Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)) AND ("time" < now()))
                     Heap Fetches: 0
               ->  Index Only Scan using _hyper_1_1_chunk_metrics_time_idx on _hyper_1_1_chunk o_3 (actual rows=1 loops=3)
                     Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)) AND ("time" < now()))
                     Heap Fetches: 3
(16 rows)

-- test startup and runtime exclusion together
-- all chunks should be filtered
:PREFIX
SELECT g.time,
  l.time
FROM generate_series('2000-01-01'::timestamptz, '2000-01-03', '1d') AS g (time)
  LEFT OUTER JOIN LATERAL (
  SELECT *
  FROM :TEST_TABLE o
  WHERE o.time >= g.time
    AND o.time < g.time + '1d'::interval
    AND o.time > now()
  ORDER BY time DESC
  LIMIT 1) l ON TRUE;
                                 QUERY PLAN                                 
----------------------------------------------------------------------------
 Nested Loop Left Join (actual rows=3 loops=1)
   ->  Function Scan on generate_series g (actual rows=3 loops=1)
   ->  Limit (actual rows=0 loops=3)
         ->  Custom Scan (ChunkAppend) on metrics o (actual rows=0 loops=3)
               Order: o."time" DESC
               Chunks excluded during startup: 3
(6 rows)

-- test JOIN
-- no exclusion on joined table because quals are not propagated yet
:PREFIX
SELECT o1.time,
  o2.time
FROM :TEST_TABLE o1
  INNER JOIN :TEST_TABLE o2 ON o1.time = o2.time
WHERE o1.time < '2000-02-01'
  AND o1.device_id = 1
  AND o2.device_id = 2
ORDER BY o1.time;
                                                                    QUERY PLAN                                                                    
--------------------------------------------------------------------------------------------------------------------------------------------------
 Merge Join (actual rows=13674 loops=1)
   Merge Cond: (o1."time" = o2."time")
   ->  Custom Scan (ChunkAppend) on metrics o1 (actual rows=13674 loops=1)
         Order: o1."time"
         ->  Index Only Scan Backward using _hyper_1_1_chunk_metrics_device_id_time_idx on _hyper_1_1_chunk o1_1 (actual rows=3598 loops=1)
               Index Cond: ((device_id = 1) AND ("time" < 'Tue Feb 01 00:00:00 2000 PST'::timestamp with time zone))
               Heap Fetches: 3598
         ->  Index Only Scan Backward using _hyper_1_2_chunk_metrics_device_id_time_idx on _hyper_1_2_chunk o1_2 (actual rows=5038 loops=1)
               Index Cond: ((device_id = 1) AND ("time" < 'Tue Feb 01 00:00:00 2000 PST'::timestamp with time zone))
               Heap Fetches: 5038
         ->  Index Only Scan Backward using _hyper_1_3_chunk_metrics_device_id_time_idx on _hyper_1_3_chunk o1_3 (actual rows=5038 loops=1)
               Index Cond: ((device_id = 1) AND ("time" < 'Tue Feb 01 00:00:00 2000 PST'::timestamp with time zone))
               Heap Fetches: 5038
   ->  Materialize (actual rows=13674 loops=1)
         ->  Custom Scan (ChunkAppend) on metrics o2 (actual rows=13674 loops=1)
               Order: o2."time"
               ->  Index Only Scan Backward using _hyper_1_1_chunk_metrics_device_id_time_idx on _hyper_1_1_chunk o2_1 (actual rows=3598 loops=1)
                     Index Cond: ((device_id = 2) AND ("time" < 'Tue Feb 01 00:00:00 2000 PST'::timestamp with time zone))
                     Heap Fetches: 3598
               ->  Index Only Scan Backward using _hyper_1_2_chunk_metrics_device_id_time_idx on _hyper_1_2_chunk o2_2 (actual rows=5038 loops=1)
                     Index Cond: ((device_id = 2) AND ("time" < 'Tue Feb 01 00:00:00 2000 PST'::timestamp with time zone))
                     Heap Fetches: 5038
               ->  Index Only Scan Backward using _hyper_1_3_chunk_metrics_device_id_time_idx on _hyper_1_3_chunk o2_3 (actual rows=5038 loops=1)
                     Index Cond: ((device_id = 2) AND ("time" < 'Tue Feb 01 00:00:00 2000 PST'::timestamp with time zone))
                     Heap Fetches: 5038
(25 rows)

-- test JOIN
-- last chunk of o2 should not be executed
:PREFIX
SELECT o1.time,
  o2.time
FROM :TEST_TABLE o1
  INNER JOIN (
    SELECT *
    FROM :TEST_TABLE o2
    ORDER BY time) o2 ON o1.time = o2.time
WHERE o1.time < '2000-01-08'
ORDER BY o1.time
LIMIT 10;
                                                                QUERY PLAN                                                                 
-------------------------------------------------------------------------------------------------------------------------------------------
 Limit (actual rows=10 loops=1)
   ->  Merge Join (actual rows=10 loops=1)
         Merge Cond: (o1."time" = o2."time")
         ->  Custom Scan (ChunkAppend) on metrics o1 (actual rows=2 loops=1)
               Order: o1."time"
               ->  Index Only Scan Backward using _hyper_1_1_chunk_metrics_time_idx on _hyper_1_1_chunk o1_1 (actual rows=2 loops=1)
                     Index Cond: ("time" < 'Sat Jan 08 00:00:00 2000 PST'::timestamp with time zone)
                     Heap Fetches: 2
               ->  Index Only Scan Backward using _hyper_1_2_chunk_metrics_time_idx on _hyper_1_2_chunk o1_2 (never executed)
                     Index Cond: ("time" < 'Sat Jan 08 00:00:00 2000 PST'::timestamp with time zone)
                     Heap Fetches: 0
         ->  Materialize (actual rows=10 loops=1)
               ->  Custom Scan (ChunkAppend) on metrics o2 (actual rows=6 loops=1)
                     Order: o2."time"
                     ->  Index Only Scan Backward using _hyper_1_1_chunk_metrics_time_idx on _hyper_1_1_chunk o2_1 (actual rows=6 loops=1)
                           Heap Fetches: 6
                     ->  Index Only Scan Backward using _hyper_1_2_chunk_metrics_time_idx on _hyper_1_2_chunk o2_2 (never executed)
                           Heap Fetches: 0
                     ->  Index Only Scan Backward using _hyper_1_3_chunk_metrics_time_idx on _hyper_1_3_chunk o2_3 (never executed)
                           Heap Fetches: 0
(20 rows)

-- test join against max query
-- not ChunkAppend so no chunk exclusion
SET enable_hashjoin = FALSE;
:PREFIX
SELECT o1.time,
  o2.*
FROM :TEST_TABLE o1
  INNER JOIN (
    SELECT max(time) AS max_time
    FROM :TEST_TABLE) o2 ON o1.time = o2.max_time
WHERE o1.device_id = 1
ORDER BY time;
                                                              QUERY PLAN                                                              
--------------------------------------------------------------------------------------------------------------------------------------
 Sort (actual rows=1 loops=1)
   Sort Key: o1."time"
   Sort Method: quicksort 
   ->  Nested Loop (actual rows=1 loops=1)
         ->  Result (actual rows=1 loops=1)
               InitPlan 1 (returns $0)
                 ->  Limit (actual rows=1 loops=1)
                       ->  Custom Scan (ChunkAppend) on metrics (actual rows=1 loops=1)
                             Order: metrics."time" DESC
                             ->  Index Only Scan using _hyper_1_3_chunk_metrics_time_idx on _hyper_1_3_chunk (actual rows=1 loops=1)
                                   Index Cond: ("time" IS NOT NULL)
                                   Heap Fetches: 1
                             ->  Index Only Scan using _hyper_1_2_chunk_metrics_time_idx on _hyper_1_2_chunk (never executed)
                                   Index Cond: ("time" IS NOT NULL)
                                   Heap Fetches: 0
                             ->  Index Only Scan using _hyper_1_1_chunk_metrics_time_idx on _hyper_1_1_chunk (never executed)
                                   Index Cond: ("time" IS NOT NULL)
                                   Heap Fetches: 0
         ->  Append (actual rows=1 loops=1)
               ->  Index Only Scan using _hyper_1_1_chunk_metrics_device_id_time_idx on _hyper_1_1_chunk o1 (actual rows=0 loops=1)
                     Index Cond: ((device_id = 1) AND ("time" = ($0)))
                     Heap Fetches: 0
               ->  Index Only Scan using _hyper_1_2_chunk_metrics_device_id_time_idx on _hyper_1_2_chunk o1_1 (actual rows=0 loops=1)
                     Index Cond: ((device_id = 1) AND ("time" = ($0)))
                     Heap Fetches: 0
               ->  Index Only Scan using _hyper_1_3_chunk_metrics_device_id_time_idx on _hyper_1_3_chunk o1_2 (actual rows=1 loops=1)
                     Index Cond: ((device_id = 1) AND ("time" = ($0)))
                     Heap Fetches: 1
(28 rows)

RESET enable_hashjoin;
SET enable_seqscan TO false;
-- test JOIN on time column
-- should use 2 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  INNER JOIN :TEST_TABLE o2 ON o1.time = o2.time
WHERE o1.device_id = 1
  AND o2.device_id = 2
ORDER BY o1.time
LIMIT 100;
                                                                      QUERY PLAN                                                                       
-------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit (actual rows=100 loops=1)
   ->  Merge Join (actual rows=100 loops=1)
         Merge Cond: (o1."time" = o2."time")
         ->  Custom Scan (ChunkAppend) on metrics o1 (actual rows=100 loops=1)
               Order: o1."time"
               ->  Index Only Scan Backward using _hyper_1_1_chunk_metrics_device_id_time_idx on _hyper_1_1_chunk o1_1 (actual rows=100 loops=1)
                     Index Cond: (device_id = 1)
                     Heap Fetches: 100
               ->  Index Only Scan Backward using _hyper_1_2_chunk_metrics_device_id_time_idx on _hyper_1_2_chunk o1_2 (never executed)
                     Index Cond: (device_id = 1)
                     Heap Fetches: 0
               ->  Index Only Scan Backward using _hyper_1_3_chunk_metrics_device_id_time_idx on _hyper_1_3_chunk o1_3 (never executed)
                     Index Cond: (device_id = 1)
                     Heap Fetches: 0
         ->  Materialize (actual rows=100 loops=1)
               ->  Custom Scan (ChunkAppend) on metrics o2 (actual rows=100 loops=1)
                     Order: o2."time"
                     ->  Index Only Scan Backward using _hyper_1_1_chunk_metrics_device_id_time_idx on _hyper_1_1_chunk o2_1 (actual rows=100 loops=1)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 100
                     ->  Index Only Scan Backward using _hyper_1_2_chunk_metrics_device_id_time_idx on _hyper_1_2_chunk o2_2 (never executed)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 0
                     ->  Index Only Scan Backward using _hyper_1_3_chunk_metrics_device_id_time_idx on _hyper_1_3_chunk o2_3 (never executed)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 0
(26 rows)

-- test JOIN on time column with USING
-- should use 2 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  INNER JOIN :TEST_TABLE o2 USING (time)
WHERE o1.device_id = 1
  AND o2.device_id = 2
ORDER BY o1.time
LIMIT 100;
                                                                      QUERY PLAN                                                                       
-------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit (actual rows=100 loops=1)
   ->  Merge Join (actual rows=100 loops=1)
         Merge Cond: (o1."time" = o2."time")
         ->  Custom Scan (ChunkAppend) on metrics o1 (actual rows=100 loops=1)
               Order: o1."time"
               ->  Index Only Scan Backward using _hyper_1_1_chunk_metrics_device_id_time_idx on _hyper_1_1_chunk o1_1 (actual rows=100 loops=1)
                     Index Cond: (device_id = 1)
                     Heap Fetches: 100
               ->  Index Only Scan Backward using _hyper_1_2_chunk_metrics_device_id_time_idx on _hyper_1_2_chunk o1_2 (never executed)
                     Index Cond: (device_id = 1)
                     Heap Fetches: 0
               ->  Index Only Scan Backward using _hyper_1_3_chunk_metrics_device_id_time_idx on _hyper_1_3_chunk o1_3 (never executed)
                     Index Cond: (device_id = 1)
                     Heap Fetches: 0
         ->  Materialize (actual rows=100 loops=1)
               ->  Custom Scan (ChunkAppend) on metrics o2 (actual rows=100 loops=1)
                     Order: o2."time"
                     ->  Index Only Scan Backward using _hyper_1_1_chunk_metrics_device_id_time_idx on _hyper_1_1_chunk o2_1 (actual rows=100 loops=1)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 100
                     ->  Index Only Scan Backward using _hyper_1_2_chunk_metrics_device_id_time_idx on _hyper_1_2_chunk o2_2 (never executed)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 0
                     ->  Index Only Scan Backward using _hyper_1_3_chunk_metrics_device_id_time_idx on _hyper_1_3_chunk o2_3 (never executed)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 0
(26 rows)

-- test NATURAL JOIN on time column
-- should use 2 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  NATURAL INNER JOIN :TEST_TABLE o2
WHERE o1.device_id = 1
  AND o2.device_id = 2
ORDER BY o1.time
LIMIT 100;
                  QUERY PLAN                  
----------------------------------------------
 Limit (actual rows=0 loops=1)
   ->  Sort (actual rows=0 loops=1)
         Sort Key: o1."time"
         Sort Method: quicksort 
         ->  Result (actual rows=0 loops=1)
               One-Time Filter: false
(6 rows)

-- test LEFT JOIN on time column
-- should use 2 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  LEFT JOIN :TEST_TABLE o2 ON o1.time = o2.time
WHERE o1.device_id = 1
  AND o2.device_id = 2
ORDER BY o1.time
LIMIT 100;
                                                                      QUERY PLAN                                                                       
-------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit (actual rows=100 loops=1)
   ->  Merge Join (actual rows=100 loops=1)
         Merge Cond: (o1."time" = o2."time")
         ->  Custom Scan (ChunkAppend) on metrics o1 (actual rows=100 loops=1)
               Order: o1."time"
               ->  Index Only Scan Backward using _hyper_1_1_chunk_metrics_device_id_time_idx on _hyper_1_1_chunk o1_1 (actual rows=100 loops=1)
                     Index Cond: (device_id = 1)
                     Heap Fetches: 100
               ->  Index Only Scan Backward using _hyper_1_2_chunk_metrics_device_id_time_idx on _hyper_1_2_chunk o1_2 (never executed)
                     Index Cond: (device_id = 1)
                     Heap Fetches: 0
               ->  Index Only Scan Backward using _hyper_1_3_chunk_metrics_device_id_time_idx on _hyper_1_3_chunk o1_3 (never executed)
                     Index Cond: (device_id = 1)
                     Heap Fetches: 0
         ->  Materialize (actual rows=100 loops=1)
               ->  Custom Scan (ChunkAppend) on metrics o2 (actual rows=100 loops=1)
                     Order: o2."time"
                     ->  Index Only Scan Backward using _hyper_1_1_chunk_metrics_device_id_time_idx on _hyper_1_1_chunk o2_1 (actual rows=100 loops=1)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 100
                     ->  Index Only Scan Backward using _hyper_1_2_chunk_metrics_device_id_time_idx on _hyper_1_2_chunk o2_2 (never executed)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 0
                     ->  Index Only Scan Backward using _hyper_1_3_chunk_metrics_device_id_time_idx on _hyper_1_3_chunk o2_3 (never executed)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 0
(26 rows)

-- test RIGHT JOIN on time column
-- should use 2 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  RIGHT JOIN :TEST_TABLE o2 ON o1.time = o2.time
WHERE o1.device_id = 1
  AND o2.device_id = 2
ORDER BY o2.time
LIMIT 100;
                                                                      QUERY PLAN                                                                       
-------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit (actual rows=100 loops=1)
   ->  Merge Join (actual rows=100 loops=1)
         Merge Cond: (o1."time" = o2."time")
         ->  Custom Scan (ChunkAppend) on metrics o1 (actual rows=100 loops=1)
               Order: o1."time"
               ->  Index Only Scan Backward using _hyper_1_1_chunk_metrics_device_id_time_idx on _hyper_1_1_chunk o1_1 (actual rows=100 loops=1)
                     Index Cond: (device_id = 1)
                     Heap Fetches: 100
               ->  Index Only Scan Backward using _hyper_1_2_chunk_metrics_device_id_time_idx on _hyper_1_2_chunk o1_2 (never executed)
                     Index Cond: (device_id = 1)
                     Heap Fetches: 0
               ->  Index Only Scan Backward using _hyper_1_3_chunk_metrics_device_id_time_idx on _hyper_1_3_chunk o1_3 (never executed)
                     Index Cond: (device_id = 1)
                     Heap Fetches: 0
         ->  Materialize (actual rows=100 loops=1)
               ->  Custom Scan (ChunkAppend) on metrics o2 (actual rows=100 loops=1)
                     Order: o2."time"
                     ->  Index Only Scan Backward using _hyper_1_1_chunk_metrics_device_id_time_idx on _hyper_1_1_chunk o2_1 (actual rows=100 loops=1)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 100
                     ->  Index Only Scan Backward using _hyper_1_2_chunk_metrics_device_id_time_idx on _hyper_1_2_chunk o2_2 (never executed)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 0
                     ->  Index Only Scan Backward using _hyper_1_3_chunk_metrics_device_id_time_idx on _hyper_1_3_chunk o2_3 (never executed)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 0
(26 rows)

-- test JOIN on time column with ON clause expression order switched
-- should use 2 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  INNER JOIN :TEST_TABLE o2 ON o2.time = o1.time
WHERE o1.device_id = 1
  AND o2.device_id = 2
ORDER BY o1.time
LIMIT 100;
                                                                      QUERY PLAN                                                                       
-------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit (actual rows=100 loops=1)
   ->  Merge Join (actual rows=100 loops=1)
         Merge Cond: (o1."time" = o2."time")
         ->  Custom Scan (ChunkAppend) on metrics o1 (actual rows=100 loops=1)
               Order: o1."time"
               ->  Index Only Scan Backward using _hyper_1_1_chunk_metrics_device_id_time_idx on _hyper_1_1_chunk o1_1 (actual rows=100 loops=1)
                     Index Cond: (device_id = 1)
                     Heap Fetches: 100
               ->  Index Only Scan Backward using _hyper_1_2_chunk_metrics_device_id_time_idx on _hyper_1_2_chunk o1_2 (never executed)
                     Index Cond: (device_id = 1)
                     Heap Fetches: 0
               ->  Index Only Scan Backward using _hyper_1_3_chunk_metrics_device_id_time_idx on _hyper_1_3_chunk o1_3 (never executed)
                     Index Cond: (device_id = 1)
                     Heap Fetches: 0
         ->  Materialize (actual rows=100 loops=1)
               ->  Custom Scan (ChunkAppend) on metrics o2 (actual rows=100 loops=1)
                     Order: o2."time"
                     ->  Index Only Scan Backward using _hyper_1_1_chunk_metrics_device_id_time_idx on _hyper_1_1_chunk o2_1 (actual rows=100 loops=1)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 100
                     ->  Index Only Scan Backward using _hyper_1_2_chunk_metrics_device_id_time_idx on _hyper_1_2_chunk o2_2 (never executed)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 0
                     ->  Index Only Scan Backward using _hyper_1_3_chunk_metrics_device_id_time_idx on _hyper_1_3_chunk o2_3 (never executed)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 0
(26 rows)

-- test JOIN on time column with equality condition in WHERE clause
-- should use 2 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  INNER JOIN :TEST_TABLE o2 ON TRUE
WHERE o1.time = o2.time
  AND o1.device_id = 1
  AND o2.device_id = 2
ORDER BY o1.time
LIMIT 100;
                                                                      QUERY PLAN                                                                       
-------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit (actual rows=100 loops=1)
   ->  Merge Join (actual rows=100 loops=1)
         Merge Cond: (o1."time" = o2."time")
         ->  Custom Scan (ChunkAppend) on metrics o1 (actual rows=100 loops=1)
               Order: o1."time"
               ->  Index Only Scan Backward using _hyper_1_1_chunk_metrics_device_id_time_idx on _hyper_1_1_chunk o1_1 (actual rows=100 loops=1)
                     Index Cond: (device_id = 1)
                     Heap Fetches: 100
               ->  Index Only Scan Backward using _hyper_1_2_chunk_metrics_device_id_time_idx on _hyper_1_2_chunk o1_2 (never executed)
                     Index Cond: (device_id = 1)
                     Heap Fetches: 0
               ->  Index Only Scan Backward using _hyper_1_3_chunk_metrics_device_id_time_idx on _hyper_1_3_chunk o1_3 (never executed)
                     Index Cond: (device_id = 1)
                     Heap Fetches: 0
         ->  Materialize (actual rows=100 loops=1)
               ->  Custom Scan (ChunkAppend) on metrics o2 (actual rows=100 loops=1)
                     Order: o2."time"
                     ->  Index Only Scan Backward using _hyper_1_1_chunk_metrics_device_id_time_idx on _hyper_1_1_chunk o2_1 (actual rows=100 loops=1)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 100
                     ->  Index Only Scan Backward using _hyper_1_2_chunk_metrics_device_id_time_idx on _hyper_1_2_chunk o2_2 (never executed)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 0
                     ->  Index Only Scan Backward using _hyper_1_3_chunk_metrics_device_id_time_idx on _hyper_1_3_chunk o2_3 (never executed)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 0
(26 rows)

-- test JOIN on time column with ORDER BY 2nd hypertable
-- should use 2 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  INNER JOIN :TEST_TABLE o2 ON o1.time = o2.time
WHERE o1.device_id = 1
  AND o2.device_id = 2
ORDER BY o2.time
LIMIT 100;
                                                                      QUERY PLAN                                                                       
-------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit (actual rows=100 loops=1)
   ->  Merge Join (actual rows=100 loops=1)
         Merge Cond: (o1."time" = o2."time")
         ->  Custom Scan (ChunkAppend) on metrics o1 (actual rows=100 loops=1)
               Order: o1."time"
               ->  Index Only Scan Backward using _hyper_1_1_chunk_metrics_device_id_time_idx on _hyper_1_1_chunk o1_1 (actual rows=100 loops=1)
                     Index Cond: (device_id = 1)
                     Heap Fetches: 100
               ->  Index Only Scan Backward using _hyper_1_2_chunk_metrics_device_id_time_idx on _hyper_1_2_chunk o1_2 (never executed)
                     Index Cond: (device_id = 1)
                     Heap Fetches: 0
               ->  Index Only Scan Backward using _hyper_1_3_chunk_metrics_device_id_time_idx on _hyper_1_3_chunk o1_3 (never executed)
                     Index Cond: (device_id = 1)
                     Heap Fetches: 0
         ->  Materialize (actual rows=100 loops=1)
               ->  Custom Scan (ChunkAppend) on metrics o2 (actual rows=100 loops=1)
                     Order: o2."time"
                     ->  Index Only Scan Backward using _hyper_1_1_chunk_metrics_device_id_time_idx on _hyper_1_1_chunk o2_1 (actual rows=100 loops=1)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 100
                     ->  Index Only Scan Backward using _hyper_1_2_chunk_metrics_device_id_time_idx on _hyper_1_2_chunk o2_2 (never executed)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 0
                     ->  Index Only Scan Backward using _hyper_1_3_chunk_metrics_device_id_time_idx on _hyper_1_3_chunk o2_3 (never executed)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 0
(26 rows)

-- test JOIN on time column and device_id
-- should use 2 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  INNER JOIN :TEST_TABLE o2 ON o1.device_id = o2.device_id
    AND o1.time = o2.time
  ORDER BY o1.time
  LIMIT 100;
                                                               QUERY PLAN                                                               
----------------------------------------------------------------------------------------------------------------------------------------
 Limit (actual rows=100 loops=1)
   ->  Merge Join (actual rows=100 loops=1)
         Merge Cond: (o1."time" = o2."time")
         Join Filter: (o1.device_id = o2.device_id)
         Rows Removed by Join Filter: 400
         ->  Custom Scan (ChunkAppend) on metrics o1 (actual rows=100 loops=1)
               Order: o1."time"
               ->  Index Scan Backward using _hyper_1_1_chunk_metrics_time_idx on _hyper_1_1_chunk o1_1 (actual rows=100 loops=1)
               ->  Index Scan Backward using _hyper_1_2_chunk_metrics_time_idx on _hyper_1_2_chunk o1_2 (never executed)
               ->  Index Scan Backward using _hyper_1_3_chunk_metrics_time_idx on _hyper_1_3_chunk o1_3 (never executed)
         ->  Materialize (actual rows=500 loops=1)
               ->  Custom Scan (ChunkAppend) on metrics o2 (actual rows=101 loops=1)
                     Order: o2."time"
                     ->  Index Scan Backward using _hyper_1_1_chunk_metrics_time_idx on _hyper_1_1_chunk o2_1 (actual rows=101 loops=1)
                     ->  Index Scan Backward using _hyper_1_2_chunk_metrics_time_idx on _hyper_1_2_chunk o2_2 (never executed)
                     ->  Index Scan Backward using _hyper_1_3_chunk_metrics_time_idx on _hyper_1_3_chunk o2_3 (never executed)
(16 rows)

-- test JOIN on device_id
-- should not use ordered append for 2nd hypertable
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  INNER JOIN :TEST_TABLE o2 ON o1.device_id = o2.device_id
WHERE o1.device_id = 1
ORDER BY o1.time
LIMIT 100;
                                                                  QUERY PLAN                                                                   
-----------------------------------------------------------------------------------------------------------------------------------------------
 Limit (actual rows=100 loops=1)
   ->  Nested Loop (actual rows=100 loops=1)
         ->  Custom Scan (ChunkAppend) on metrics o1 (actual rows=1 loops=1)
               Order: o1."time"
               ->  Index Only Scan Backward using _hyper_1_1_chunk_metrics_device_id_time_idx on _hyper_1_1_chunk o1_1 (actual rows=1 loops=1)
                     Index Cond: (device_id = 1)
                     Heap Fetches: 1
               ->  Index Only Scan Backward using _hyper_1_2_chunk_metrics_device_id_time_idx on _hyper_1_2_chunk o1_2 (never executed)
                     Index Cond: (device_id = 1)
                     Heap Fetches: 0
               ->  Index Only Scan Backward using _hyper_1_3_chunk_metrics_device_id_time_idx on _hyper_1_3_chunk o1_3 (never executed)
                     Index Cond: (device_id = 1)
                     Heap Fetches: 0
         ->  Materialize (actual rows=100 loops=1)
               ->  Append (actual rows=100 loops=1)
                     ->  Index Only Scan using _hyper_1_1_chunk_metrics_device_id_time_idx on _hyper_1_1_chunk o2 (actual rows=100 loops=1)
                           Index Cond: (device_id = 1)
                           Heap Fetches: 100
                     ->  Index Only Scan using _hyper_1_2_chunk_metrics_device_id_time_idx on _hyper_1_2_chunk o2_1 (never executed)
                           Index Cond: (device_id = 1)
                           Heap Fetches: 0
                     ->  Index Only Scan using _hyper_1_3_chunk_metrics_device_id_time_idx on _hyper_1_3_chunk o2_2 (never executed)
                           Index Cond: (device_id = 1)
                           Heap Fetches: 0
(24 rows)

-- test JOIN on time column with implicit join
-- should use 2 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1,
  :TEST_TABLE o2
WHERE o1.time = o2.time
  AND o1.device_id = 1
  AND o2.device_id = 2
ORDER BY o1.time
LIMIT 100;
                                                                      QUERY PLAN                                                                       
-------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit (actual rows=100 loops=1)
   ->  Merge Join (actual rows=100 loops=1)
         Merge Cond: (o1."time" = o2."time")
         ->  Custom Scan (ChunkAppend) on metrics o1 (actual rows=100 loops=1)
               Order: o1."time"
               ->  Index Only Scan Backward using _hyper_1_1_chunk_metrics_device_id_time_idx on _hyper_1_1_chunk o1_1 (actual rows=100 loops=1)
                     Index Cond: (device_id = 1)
                     Heap Fetches: 100
               ->  Index Only Scan Backward using _hyper_1_2_chunk_metrics_device_id_time_idx on _hyper_1_2_chunk o1_2 (never executed)
                     Index Cond: (device_id = 1)
                     Heap Fetches: 0
               ->  Index Only Scan Backward using _hyper_1_3_chunk_metrics_device_id_time_idx on _hyper_1_3_chunk o1_3 (never executed)
                     Index Cond: (device_id = 1)
                     Heap Fetches: 0
         ->  Materialize (actual rows=100 loops=1)
               ->  Custom Scan (ChunkAppend) on metrics o2 (actual rows=100 loops=1)
                     Order: o2."time"
                     ->  Index Only Scan Backward using _hyper_1_1_chunk_metrics_device_id_time_idx on _hyper_1_1_chunk o2_1 (actual rows=100 loops=1)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 100
                     ->  Index Only Scan Backward using _hyper_1_2_chunk_metrics_device_id_time_idx on _hyper_1_2_chunk o2_2 (never executed)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 0
                     ->  Index Only Scan Backward using _hyper_1_3_chunk_metrics_device_id_time_idx on _hyper_1_3_chunk o2_3 (never executed)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 0
(26 rows)

-- test JOIN on time column with 3 hypertables
-- should use 3 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  INNER JOIN :TEST_TABLE o2 ON o1.time = o2.time
  INNER JOIN :TEST_TABLE o3 ON o1.time = o3.time
WHERE o1.device_id = 1
  AND o2.device_id = 2
  AND o3.device_id = 3
ORDER BY o1.time
LIMIT 100;
                                                                            QUERY PLAN                                                                             
-------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit (actual rows=100 loops=1)
   ->  Merge Join (actual rows=100 loops=1)
         Merge Cond: (o3."time" = o1."time")
         ->  Custom Scan (ChunkAppend) on metrics o3 (actual rows=100 loops=1)
               Order: o3."time"
               ->  Index Only Scan Backward using _hyper_1_1_chunk_metrics_device_id_time_idx on _hyper_1_1_chunk o3_1 (actual rows=100 loops=1)
                     Index Cond: (device_id = 3)
                     Heap Fetches: 100
               ->  Index Only Scan Backward using _hyper_1_2_chunk_metrics_device_id_time_idx on _hyper_1_2_chunk o3_2 (never executed)
                     Index Cond: (device_id = 3)
                     Heap Fetches: 0
               ->  Index Only Scan Backward using _hyper_1_3_chunk_metrics_device_id_time_idx on _hyper_1_3_chunk o3_3 (never executed)
                     Index Cond: (device_id = 3)
                     Heap Fetches: 0
         ->  Materialize (actual rows=100 loops=1)
               ->  Merge Join (actual rows=100 loops=1)
                     Merge Cond: (o1."time" = o2."time")
                     ->  Custom Scan (ChunkAppend) on metrics o1 (actual rows=100 loops=1)
                           Order: o1."time"
                           ->  Index Only Scan Backward using _hyper_1_1_chunk_metrics_device_id_time_idx on _hyper_1_1_chunk o1_1 (actual rows=100 loops=1)
                                 Index Cond: (device_id = 1)
                                 Heap Fetches: 100
                           ->  Index Only Scan Backward using _hyper_1_2_chunk_metrics_device_id_time_idx on _hyper_1_2_chunk o1_2 (never executed)
                                 Index Cond: (device_id = 1)
                                 Heap Fetches: 0
                           ->  Index Only Scan Backward using _hyper_1_3_chunk_metrics_device_id_time_idx on _hyper_1_3_chunk o1_3 (never executed)
                                 Index Cond: (device_id = 1)
                                 Heap Fetches: 0
                     ->  Materialize (actual rows=100 loops=1)
                           ->  Custom Scan (ChunkAppend) on metrics o2 (actual rows=100 loops=1)
                                 Order: o2."time"
                                 ->  Index Only Scan Backward using _hyper_1_1_chunk_metrics_device_id_time_idx on _hyper_1_1_chunk o2_1 (actual rows=100 loops=1)
                                       Index Cond: (device_id = 2)
                                       Heap Fetches: 100
                                 ->  Index Only Scan Backward using _hyper_1_2_chunk_metrics_device_id_time_idx on _hyper_1_2_chunk o2_2 (never executed)
                                       Index Cond: (device_id = 2)
                                       Heap Fetches: 0
                                 ->  Index Only Scan Backward using _hyper_1_3_chunk_metrics_device_id_time_idx on _hyper_1_3_chunk o2_3 (never executed)
                                       Index Cond: (device_id = 2)
                                       Heap Fetches: 0
(40 rows)

RESET enable_seqscan;
\set TEST_TABLE 'metrics_space'
\ir :TEST_QUERY_NAME
-- This file and its contents are licensed under the Timescale License.
-- Please see the included NOTICE for copyright information and
-- LICENSE-TIMESCALE for a copy of the license.
-- test LATERAL with ordered append in the outer query
:PREFIX
SELECT time,
  pg_typeof(l)
FROM :TEST_TABLE,
  LATERAL (
    SELECT *
    FROM (
      VALUES (1),
        (2)) v) l
ORDER BY time DESC
LIMIT 2;
                                                                  QUERY PLAN                                                                  
----------------------------------------------------------------------------------------------------------------------------------------------
 Limit (actual rows=2 loops=1)
   ->  Nested Loop (actual rows=2 loops=1)
         ->  Custom Scan (ChunkAppend) on metrics_space (actual rows=1 loops=1)
               Order: metrics_space."time" DESC
               ->  Merge Append (actual rows=1 loops=1)
                     Sort Key: _hyper_2_12_chunk."time" DESC
                     ->  Index Only Scan Backward using _hyper_2_12_chunk_metrics_space_time_idx on _hyper_2_12_chunk (actual rows=1 loops=1)
                           Heap Fetches: 1
                     ->  Index Only Scan Backward using _hyper_2_11_chunk_metrics_space_time_idx on _hyper_2_11_chunk (actual rows=1 loops=1)
                           Heap Fetches: 1
                     ->  Index Only Scan Backward using _hyper_2_10_chunk_metrics_space_time_idx on _hyper_2_10_chunk (actual rows=1 loops=1)
                           Heap Fetches: 1
               ->  Merge Append (never executed)
                     Sort Key: _hyper_2_9_chunk."time" DESC
                     ->  Index Only Scan Backward using _hyper_2_9_chunk_metrics_space_time_idx on _hyper_2_9_chunk (never executed)
                           Heap Fetches: 0
                     ->  Index Only Scan Backward using _hyper_2_8_chunk_metrics_space_time_idx on _hyper_2_8_chunk (never executed)
                           Heap Fetches: 0
                     ->  Index Only Scan Backward using _hyper_2_7_chunk_metrics_space_time_idx on _hyper_2_7_chunk (never executed)
                           Heap Fetches: 0
               ->  Merge Append (never executed)
                     Sort Key: _hyper_2_6_chunk."time" DESC
                     ->  Index Only Scan Backward using _hyper_2_6_chunk_metrics_space_time_idx on _hyper_2_6_chunk (never executed)
                           Heap Fetches: 0
                     ->  Index Only Scan Backward using _hyper_2_5_chunk_metrics_space_time_idx on _hyper_2_5_chunk (never executed)
                           Heap Fetches: 0
                     ->  Index Only Scan Backward using _hyper_2_4_chunk_metrics_space_time_idx on _hyper_2_4_chunk (never executed)
                           Heap Fetches: 0
         ->  Materialize (actual rows=2 loops=1)
               ->  Values Scan on "*VALUES*" (actual rows=2 loops=1)
(30 rows)

-- test LATERAL with ordered append in the lateral query
:PREFIX
SELECT time,
  pg_typeof(v)
FROM (
  VALUES (1),
    (2)) v,
  LATERAL (
    SELECT *
    FROM :TEST_TABLE
    ORDER BY time DESC
    LIMIT 2) l;
                                                                        QUERY PLAN                                                                        
----------------------------------------------------------------------------------------------------------------------------------------------------------
 Nested Loop (actual rows=4 loops=1)
   ->  Values Scan on "*VALUES*" (actual rows=2 loops=1)
   ->  Materialize (actual rows=2 loops=2)
         ->  Subquery Scan on l (actual rows=2 loops=1)
               ->  Limit (actual rows=2 loops=1)
                     ->  Custom Scan (ChunkAppend) on metrics_space (actual rows=2 loops=1)
                           Order: metrics_space."time" DESC
                           ->  Merge Append (actual rows=2 loops=1)
                                 Sort Key: _hyper_2_12_chunk."time" DESC
                                 ->  Index Only Scan Backward using _hyper_2_12_chunk_metrics_space_time_idx on _hyper_2_12_chunk (actual rows=2 loops=1)
                                       Heap Fetches: 2
                                 ->  Index Only Scan Backward using _hyper_2_11_chunk_metrics_space_time_idx on _hyper_2_11_chunk (actual rows=1 loops=1)
                                       Heap Fetches: 1
                                 ->  Index Only Scan Backward using _hyper_2_10_chunk_metrics_space_time_idx on _hyper_2_10_chunk (actual rows=1 loops=1)
                                       Heap Fetches: 1
                           ->  Merge Append (never executed)
                                 Sort Key: _hyper_2_9_chunk."time" DESC
                                 ->  Index Only Scan Backward using _hyper_2_9_chunk_metrics_space_time_idx on _hyper_2_9_chunk (never executed)
                                       Heap Fetches: 0
                                 ->  Index Only Scan Backward using _hyper_2_8_chunk_metrics_space_time_idx on _hyper_2_8_chunk (never executed)
                                       Heap Fetches: 0
                                 ->  Index Only Scan Backward using _hyper_2_7_chunk_metrics_space_time_idx on _hyper_2_7_chunk (never executed)
                                       Heap Fetches: 0
                           ->  Merge Append (never executed)
                                 Sort Key: _hyper_2_6_chunk."time" DESC
                                 ->  Index Only Scan Backward using _hyper_2_6_chunk_metrics_space_time_idx on _hyper_2_6_chunk (never executed)
                                       Heap Fetches: 0
                                 ->  Index Only Scan Backward using _hyper_2_5_chunk_metrics_space_time_idx on _hyper_2_5_chunk (never executed)
                                       Heap Fetches: 0
                                 ->  Index Only Scan Backward using _hyper_2_4_chunk_metrics_space_time_idx on _hyper_2_4_chunk (never executed)
                                       Heap Fetches: 0
(31 rows)

-- test plan with best index is chosen
-- this should use device_id, time index
:PREFIX
SELECT time,
  device_id
FROM :TEST_TABLE
WHERE device_id = 1
ORDER BY time DESC
LIMIT 1;
                                                         QUERY PLAN                                                          
-----------------------------------------------------------------------------------------------------------------------------
 Limit (actual rows=1 loops=1)
   ->  Custom Scan (ChunkAppend) on metrics_space (actual rows=1 loops=1)
         Order: metrics_space."time" DESC
         ->  Index Scan Backward using _hyper_2_10_chunk_metrics_space_time_idx on _hyper_2_10_chunk (actual rows=1 loops=1)
               Filter: (device_id = 1)
         ->  Index Scan Backward using _hyper_2_7_chunk_metrics_space_time_idx on _hyper_2_7_chunk (never executed)
               Filter: (device_id = 1)
         ->  Index Scan Backward using _hyper_2_4_chunk_metrics_space_time_idx on _hyper_2_4_chunk (never executed)
               Filter: (device_id = 1)
(9 rows)

-- test plan with best index is chosen
-- this should use time index
:PREFIX
SELECT time
FROM :TEST_TABLE
ORDER BY time DESC
LIMIT 1;
                                                               QUERY PLAN                                                               
----------------------------------------------------------------------------------------------------------------------------------------
 Limit (actual rows=1 loops=1)
   ->  Custom Scan (ChunkAppend) on metrics_space (actual rows=1 loops=1)
         Order: metrics_space."time" DESC
         ->  Merge Append (actual rows=1 loops=1)
               Sort Key: _hyper_2_12_chunk."time" DESC
               ->  Index Only Scan Backward using _hyper_2_12_chunk_metrics_space_time_idx on _hyper_2_12_chunk (actual rows=1 loops=1)
                     Heap Fetches: 1
               ->  Index Only Scan Backward using _hyper_2_11_chunk_metrics_space_time_idx on _hyper_2_11_chunk (actual rows=1 loops=1)
                     Heap Fetches: 1
               ->  Index Only Scan Backward using _hyper_2_10_chunk_metrics_space_time_idx on _hyper_2_10_chunk (actual rows=1 loops=1)
                     Heap Fetches: 1
         ->  Merge Append (never executed)
               Sort Key: _hyper_2_9_chunk."time" DESC
               ->  Index Only Scan Backward using _hyper_2_9_chunk_metrics_space_time_idx on _hyper_2_9_chunk (never executed)
                     Heap Fetches: 0
               ->  Index Only Scan Backward using _hyper_2_8_chunk_metrics_space_time_idx on _hyper_2_8_chunk (never executed)
                     Heap Fetches: 0
               ->  Index Only Scan Backward using _hyper_2_7_chunk_metrics_space_time_idx on _hyper_2_7_chunk (never executed)
                     Heap Fetches: 0
         ->  Merge Append (never executed)
               Sort Key: _hyper_2_6_chunk."time" DESC
               ->  Index Only Scan Backward using _hyper_2_6_chunk_metrics_space_time_idx on _hyper_2_6_chunk (never executed)
                     Heap Fetches: 0
               ->  Index Only Scan Backward using _hyper_2_5_chunk_metrics_space_time_idx on _hyper_2_5_chunk (never executed)
                     Heap Fetches: 0
               ->  Index Only Scan Backward using _hyper_2_4_chunk_metrics_space_time_idx on _hyper_2_4_chunk (never executed)
                     Heap Fetches: 0
(27 rows)

-- test LATERAL with correlated query
-- only last chunk should be executed
:PREFIX
SELECT g.time,
  l.time
FROM generate_series('2000-01-01'::timestamptz, '2000-01-03', '1d') AS g (time)
  LEFT OUTER JOIN LATERAL (
  SELECT *
  FROM :TEST_TABLE o
  WHERE o.time >= g.time
    AND o.time < g.time + '1d'::interval
  ORDER BY time DESC
  LIMIT 1) l ON TRUE;
                                                                    QUERY PLAN                                                                    
--------------------------------------------------------------------------------------------------------------------------------------------------
 Nested Loop Left Join (actual rows=3 loops=1)
   ->  Function Scan on generate_series g (actual rows=3 loops=1)
   ->  Limit (actual rows=1 loops=3)
         ->  Custom Scan (ChunkAppend) on metrics_space o (actual rows=1 loops=3)
               Order: o."time" DESC
               ->  Merge Append (actual rows=0 loops=3)
                     Sort Key: o_1."time" DESC
                     ->  Index Only Scan Backward using _hyper_2_12_chunk_metrics_space_time_idx on _hyper_2_12_chunk o_1 (actual rows=0 loops=3)
                           Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                           Heap Fetches: 0
                     ->  Index Only Scan Backward using _hyper_2_11_chunk_metrics_space_time_idx on _hyper_2_11_chunk o_2 (actual rows=0 loops=3)
                           Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                           Heap Fetches: 0
                     ->  Index Only Scan Backward using _hyper_2_10_chunk_metrics_space_time_idx on _hyper_2_10_chunk o_3 (actual rows=0 loops=3)
                           Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                           Heap Fetches: 0
               ->  Merge Append (actual rows=0 loops=3)
                     Sort Key: o_4."time" DESC
                     ->  Index Only Scan Backward using _hyper_2_9_chunk_metrics_space_time_idx on _hyper_2_9_chunk o_4 (actual rows=0 loops=3)
                           Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                           Heap Fetches: 0
                     ->  Index Only Scan Backward using _hyper_2_8_chunk_metrics_space_time_idx on _hyper_2_8_chunk o_5 (actual rows=0 loops=3)
                           Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                           Heap Fetches: 0
                     ->  Index Only Scan Backward using _hyper_2_7_chunk_metrics_space_time_idx on _hyper_2_7_chunk o_6 (actual rows=0 loops=3)
                           Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                           Heap Fetches: 0
               ->  Merge Append (actual rows=1 loops=3)
                     Sort Key: o_7."time" DESC
                     ->  Index Only Scan Backward using _hyper_2_6_chunk_metrics_space_time_idx on _hyper_2_6_chunk o_7 (actual rows=1 loops=3)
                           Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                           Heap Fetches: 3
                     ->  Index Only Scan Backward using _hyper_2_5_chunk_metrics_space_time_idx on _hyper_2_5_chunk o_8 (actual rows=1 loops=3)
                           Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                           Heap Fetches: 3
                     ->  Index Only Scan Backward using _hyper_2_4_chunk_metrics_space_time_idx on _hyper_2_4_chunk o_9 (actual rows=1 loops=3)
                           Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                           Heap Fetches: 3
(38 rows)

-- test LATERAL with correlated query
-- only 2nd chunk should be executed
:PREFIX
SELECT g.time,
  l.time
FROM generate_series('2000-01-10'::timestamptz, '2000-01-11', '1d') AS g (time)
  LEFT OUTER JOIN LATERAL (
  SELECT *
  FROM :TEST_TABLE o
  WHERE o.time >= g.time
    AND o.time < g.time + '1d'::interval
  ORDER BY time
  LIMIT 1) l ON TRUE;
                                                              QUERY PLAN                                                               
---------------------------------------------------------------------------------------------------------------------------------------
 Nested Loop Left Join (actual rows=2 loops=1)
   ->  Function Scan on generate_series g (actual rows=2 loops=1)
   ->  Limit (actual rows=1 loops=2)
         ->  Custom Scan (ChunkAppend) on metrics_space o (actual rows=1 loops=2)
               Order: o."time"
               ->  Merge Append (actual rows=0 loops=2)
                     Sort Key: o_1."time"
                     ->  Index Only Scan using _hyper_2_4_chunk_metrics_space_time_idx on _hyper_2_4_chunk o_1 (actual rows=0 loops=2)
                           Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                           Heap Fetches: 0
                     ->  Index Only Scan using _hyper_2_5_chunk_metrics_space_time_idx on _hyper_2_5_chunk o_2 (actual rows=0 loops=2)
                           Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                           Heap Fetches: 0
                     ->  Index Only Scan using _hyper_2_6_chunk_metrics_space_time_idx on _hyper_2_6_chunk o_3 (actual rows=0 loops=2)
                           Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                           Heap Fetches: 0
               ->  Merge Append (actual rows=1 loops=2)
                     Sort Key: o_4."time"
                     ->  Index Only Scan using _hyper_2_7_chunk_metrics_space_time_idx on _hyper_2_7_chunk o_4 (actual rows=1 loops=2)
                           Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                           Heap Fetches: 2
                     ->  Index Only Scan using _hyper_2_8_chunk_metrics_space_time_idx on _hyper_2_8_chunk o_5 (actual rows=1 loops=2)
                           Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                           Heap Fetches: 2
                     ->  Index Only Scan using _hyper_2_9_chunk_metrics_space_time_idx on _hyper_2_9_chunk o_6 (actual rows=1 loops=2)
                           Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                           Heap Fetches: 2
               ->  Merge Append (never executed)
                     Sort Key: o_7."time"
                     ->  Index Only Scan using _hyper_2_10_chunk_metrics_space_time_idx on _hyper_2_10_chunk o_7 (never executed)
                           Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                           Heap Fetches: 0
                     ->  Index Only Scan using _hyper_2_11_chunk_metrics_space_time_idx on _hyper_2_11_chunk o_8 (never executed)
                           Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                           Heap Fetches: 0
                     ->  Index Only Scan using _hyper_2_12_chunk_metrics_space_time_idx on _hyper_2_12_chunk o_9 (never executed)
                           Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                           Heap Fetches: 0
(38 rows)

-- test startup and runtime exclusion together
:PREFIX
SELECT g.time,
  l.time
FROM generate_series('2000-01-01'::timestamptz, '2000-01-03', '1d') AS g (time)
  LEFT OUTER JOIN LATERAL (
  SELECT *
  FROM :TEST_TABLE o
  WHERE o.time >= g.time
    AND o.time < g.time + '1d'::interval
    AND o.time < now()
  ORDER BY time DESC
  LIMIT 1) l ON TRUE;
                                                                    QUERY PLAN                                                                    
--------------------------------------------------------------------------------------------------------------------------------------------------
 Nested Loop Left Join (actual rows=3 loops=1)
   ->  Function Scan on generate_series g (actual rows=3 loops=1)
   ->  Limit (actual rows=1 loops=3)
         ->  Custom Scan (ChunkAppend) on metrics_space o (actual rows=1 loops=3)
               Order: o."time" DESC
               ->  Merge Append (actual rows=0 loops=3)
                     Sort Key: o_1."time" DESC
                     ->  Index Only Scan Backward using _hyper_2_12_chunk_metrics_space_time_idx on _hyper_2_12_chunk o_1 (actual rows=0 loops=3)
                           Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)) AND ("time" < now()))
                           Heap Fetches: 0
                     ->  Index Only Scan Backward using _hyper_2_11_chunk_metrics_space_time_idx on _hyper_2_11_chunk o_2 (actual rows=0 loops=3)
                           Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)) AND ("time" < now()))
                           Heap Fetches: 0
                     ->  Index Only Scan Backward using _hyper_2_10_chunk_metrics_space_time_idx on _hyper_2_10_chunk o_3 (actual rows=0 loops=3)
                           Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)) AND ("time" < now()))
                           Heap Fetches: 0
               ->  Merge Append (actual rows=0 loops=3)
                     Sort Key: o_4."time" DESC
                     ->  Index Only Scan Backward using _hyper_2_9_chunk_metrics_space_time_idx on _hyper_2_9_chunk o_4 (actual rows=0 loops=3)
                           Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)) AND ("time" < now()))
                           Heap Fetches: 0
                     ->  Index Only Scan Backward using _hyper_2_8_chunk_metrics_space_time_idx on _hyper_2_8_chunk o_5 (actual rows=0 loops=3)
                           Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)) AND ("time" < now()))
                           Heap Fetches: 0
                     ->  Index Only Scan Backward using _hyper_2_7_chunk_metrics_space_time_idx on _hyper_2_7_chunk o_6 (actual rows=0 loops=3)
                           Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)) AND ("time" < now()))
                           Heap Fetches: 0
               ->  Merge Append (actual rows=1 loops=3)
                     Sort Key: o_7."time" DESC
                     ->  Index Only Scan Backward using _hyper_2_6_chunk_metrics_space_time_idx on _hyper_2_6_chunk o_7 (actual rows=1 loops=3)
                           Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)) AND ("time" < now()))
                           Heap Fetches: 3
                     ->  Index Only Scan Backward using _hyper_2_5_chunk_metrics_space_time_idx on _hyper_2_5_chunk o_8 (actual rows=1 loops=3)
                           Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)) AND ("time" < now()))
                           Heap Fetches: 3
                     ->  Index Only Scan Backward using _hyper_2_4_chunk_metrics_space_time_idx on _hyper_2_4_chunk o_9 (actual rows=1 loops=3)
                           Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)) AND ("time" < now()))
                           Heap Fetches: 3
(38 rows)

-- test startup and runtime exclusion together
-- all chunks should be filtered
:PREFIX
SELECT g.time,
  l.time
FROM generate_series('2000-01-01'::timestamptz, '2000-01-03', '1d') AS g (time)
  LEFT OUTER JOIN LATERAL (
  SELECT *
  FROM :TEST_TABLE o
  WHERE o.time >= g.time
    AND o.time < g.time + '1d'::interval
    AND o.time > now()
  ORDER BY time DESC
  LIMIT 1) l ON TRUE;
                                                                    QUERY PLAN                                                                    
--------------------------------------------------------------------------------------------------------------------------------------------------
 Nested Loop Left Join (actual rows=3 loops=1)
   ->  Function Scan on generate_series g (actual rows=3 loops=1)
   ->  Limit (actual rows=0 loops=3)
         ->  Custom Scan (ChunkAppend) on metrics_space o (actual rows=0 loops=3)
               Order: o."time" DESC
               ->  Merge Append (actual rows=0 loops=3)
                     Sort Key: o_1."time" DESC
                     ->  Index Only Scan Backward using _hyper_2_12_chunk_metrics_space_time_idx on _hyper_2_12_chunk o_1 (actual rows=0 loops=3)
                           Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)) AND ("time" > now()))
                           Heap Fetches: 0
                     ->  Index Only Scan Backward using _hyper_2_11_chunk_metrics_space_time_idx on _hyper_2_11_chunk o_2 (actual rows=0 loops=3)
                           Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)) AND ("time" > now()))
                           Heap Fetches: 0
                     ->  Index Only Scan Backward using _hyper_2_10_chunk_metrics_space_time_idx on _hyper_2_10_chunk o_3 (actual rows=0 loops=3)
                           Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)) AND ("time" > now()))
                           Heap Fetches: 0
               ->  Merge Append (actual rows=0 loops=3)
                     Sort Key: o_4."time" DESC
                     ->  Index Only Scan Backward using _hyper_2_9_chunk_metrics_space_time_idx on _hyper_2_9_chunk o_4 (actual rows=0 loops=3)
                           Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)) AND ("time" > now()))
                           Heap Fetches: 0
                     ->  Index Only Scan Backward using _hyper_2_8_chunk_metrics_space_time_idx on _hyper_2_8_chunk o_5 (actual rows=0 loops=3)
                           Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)) AND ("time" > now()))
                           Heap Fetches: 0
                     ->  Index Only Scan Backward using _hyper_2_7_chunk_metrics_space_time_idx on _hyper_2_7_chunk o_6 (actual rows=0 loops=3)
                           Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)) AND ("time" > now()))
                           Heap Fetches: 0
               ->  Merge Append (actual rows=0 loops=3)
                     Sort Key: o_7."time" DESC
                     ->  Index Only Scan Backward using _hyper_2_6_chunk_metrics_space_time_idx on _hyper_2_6_chunk o_7 (actual rows=0 loops=3)
                           Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)) AND ("time" > now()))
                           Heap Fetches: 0
                     ->  Index Only Scan Backward using _hyper_2_5_chunk_metrics_space_time_idx on _hyper_2_5_chunk o_8 (actual rows=0 loops=3)
                           Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)) AND ("time" > now()))
                           Heap Fetches: 0
                     ->  Index Only Scan Backward using _hyper_2_4_chunk_metrics_space_time_idx on _hyper_2_4_chunk o_9 (actual rows=0 loops=3)
                           Index Cond: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)) AND ("time" > now()))
                           Heap Fetches: 0
(38 rows)

-- test JOIN
-- no exclusion on joined table because quals are not propagated yet
:PREFIX
SELECT o1.time,
  o2.time
FROM :TEST_TABLE o1
  INNER JOIN :TEST_TABLE o2 ON o1.time = o2.time
WHERE o1.time < '2000-02-01'
  AND o1.device_id = 1
  AND o2.device_id = 2
ORDER BY o1.time;
                                                                   QUERY PLAN                                                                    
-------------------------------------------------------------------------------------------------------------------------------------------------
 Merge Join (actual rows=13674 loops=1)
   Merge Cond: (o1."time" = o2."time")
   ->  Custom Scan (ChunkAppend) on metrics_space o1 (actual rows=13674 loops=1)
         Order: o1."time"
         ->  Index Scan using _hyper_2_4_chunk_metrics_space_time_idx on _hyper_2_4_chunk o1_1 (actual rows=3598 loops=1)
               Index Cond: ("time" < 'Tue Feb 01 00:00:00 2000 PST'::timestamp with time zone)
               Filter: (device_id = 1)
         ->  Index Scan using _hyper_2_7_chunk_metrics_space_time_idx on _hyper_2_7_chunk o1_2 (actual rows=5038 loops=1)
               Index Cond: ("time" < 'Tue Feb 01 00:00:00 2000 PST'::timestamp with time zone)
               Filter: (device_id = 1)
         ->  Index Scan using _hyper_2_10_chunk_metrics_space_time_idx on _hyper_2_10_chunk o1_3 (actual rows=5038 loops=1)
               Index Cond: ("time" < 'Tue Feb 01 00:00:00 2000 PST'::timestamp with time zone)
               Filter: (device_id = 1)
   ->  Materialize (actual rows=13674 loops=1)
         ->  Custom Scan (ChunkAppend) on metrics_space o2 (actual rows=13674 loops=1)
               Order: o2."time"
               ->  Index Only Scan using _hyper_2_5_chunk_metrics_space_device_id_time_idx on _hyper_2_5_chunk o2_1 (actual rows=3598 loops=1)
                     Index Cond: ((device_id = 2) AND ("time" < 'Tue Feb 01 00:00:00 2000 PST'::timestamp with time zone))
                     Heap Fetches: 3598
               ->  Index Only Scan using _hyper_2_8_chunk_metrics_space_device_id_time_idx on _hyper_2_8_chunk o2_2 (actual rows=5038 loops=1)
                     Index Cond: ((device_id = 2) AND ("time" < 'Tue Feb 01 00:00:00 2000 PST'::timestamp with time zone))
                     Heap Fetches: 5038
               ->  Index Only Scan using _hyper_2_11_chunk_metrics_space_device_id_time_idx on _hyper_2_11_chunk o2_3 (actual rows=5038 loops=1)
                     Index Cond: ((device_id = 2) AND ("time" < 'Tue Feb 01 00:00:00 2000 PST'::timestamp with time zone))
                     Heap Fetches: 5038
(25 rows)

-- test JOIN
-- last chunk of o2 should not be executed
:PREFIX
SELECT o1.time,
  o2.time
FROM :TEST_TABLE o1
  INNER JOIN (
    SELECT *
    FROM :TEST_TABLE o2
    ORDER BY time) o2 ON o1.time = o2.time
WHERE o1.time < '2000-01-08'
ORDER BY o1.time
LIMIT 10;
                                                                  QUERY PLAN                                                                  
----------------------------------------------------------------------------------------------------------------------------------------------
 Limit (actual rows=10 loops=1)
   ->  Merge Join (actual rows=10 loops=1)
         Merge Cond: (o1."time" = o2."time")
         ->  Custom Scan (ChunkAppend) on metrics_space o1 (actual rows=2 loops=1)
               Order: o1."time"
               ->  Merge Append (actual rows=2 loops=1)
                     Sort Key: o1_1."time"
                     ->  Index Only Scan using _hyper_2_4_chunk_metrics_space_time_idx on _hyper_2_4_chunk o1_1 (actual rows=2 loops=1)
                           Index Cond: ("time" < 'Sat Jan 08 00:00:00 2000 PST'::timestamp with time zone)
                           Heap Fetches: 2
                     ->  Index Only Scan using _hyper_2_5_chunk_metrics_space_time_idx on _hyper_2_5_chunk o1_2 (actual rows=1 loops=1)
                           Index Cond: ("time" < 'Sat Jan 08 00:00:00 2000 PST'::timestamp with time zone)
                           Heap Fetches: 1
                     ->  Index Only Scan using _hyper_2_6_chunk_metrics_space_time_idx on _hyper_2_6_chunk o1_3 (actual rows=1 loops=1)
                           Index Cond: ("time" < 'Sat Jan 08 00:00:00 2000 PST'::timestamp with time zone)
                           Heap Fetches: 1
               ->  Merge Append (never executed)
                     Sort Key: o1_4."time"
                     ->  Index Only Scan using _hyper_2_7_chunk_metrics_space_time_idx on _hyper_2_7_chunk o1_4 (never executed)
                           Index Cond: ("time" < 'Sat Jan 08 00:00:00 2000 PST'::timestamp with time zone)
                           Heap Fetches: 0
                     ->  Index Only Scan using _hyper_2_8_chunk_metrics_space_time_idx on _hyper_2_8_chunk o1_5 (never executed)
                           Index Cond: ("time" < 'Sat Jan 08 00:00:00 2000 PST'::timestamp with time zone)
                           Heap Fetches: 0
                     ->  Index Only Scan using _hyper_2_9_chunk_metrics_space_time_idx on _hyper_2_9_chunk o1_6 (never executed)
                           Index Cond: ("time" < 'Sat Jan 08 00:00:00 2000 PST'::timestamp with time zone)
                           Heap Fetches: 0
         ->  Materialize (actual rows=10 loops=1)
               ->  Custom Scan (ChunkAppend) on metrics_space o2 (actual rows=6 loops=1)
                     Order: o2."time"
                     ->  Merge Append (actual rows=6 loops=1)
                           Sort Key: o2_1."time"
                           ->  Index Only Scan using _hyper_2_4_chunk_metrics_space_time_idx on _hyper_2_4_chunk o2_1 (actual rows=2 loops=1)
                                 Heap Fetches: 2
                           ->  Index Only Scan using _hyper_2_5_chunk_metrics_space_time_idx on _hyper_2_5_chunk o2_2 (actual rows=4 loops=1)
                                 Heap Fetches: 4
                           ->  Index Only Scan using _hyper_2_6_chunk_metrics_space_time_idx on _hyper_2_6_chunk o2_3 (actual rows=2 loops=1)
                                 Heap Fetches: 2
                     ->  Merge Append (never executed)
                           Sort Key: o2_4."time"
                           ->  Index Only Scan using _hyper_2_7_chunk_metrics_space_time_idx on _hyper_2_7_chunk o2_4 (never executed)
                                 Heap Fetches: 0
                           ->  Index Only Scan using _hyper_2_8_chunk_metrics_space_time_idx on _hyper_2_8_chunk o2_5 (never executed)
                                 Heap Fetches: 0
                           ->  Index Only Scan using _hyper_2_9_chunk_metrics_space_time_idx on _hyper_2_9_chunk o2_6 (never executed)
                                 Heap Fetches: 0
                     ->  Merge Append (never executed)
                           Sort Key: o2_7."time"
                           ->  Index Only Scan using _hyper_2_10_chunk_metrics_space_time_idx on _hyper_2_10_chunk o2_7 (never executed)
                                 Heap Fetches: 0
                           ->  Index Only Scan using _hyper_2_11_chunk_metrics_space_time_idx on _hyper_2_11_chunk o2_8 (never executed)
                                 Heap Fetches: 0
                           ->  Index Only Scan using _hyper_2_12_chunk_metrics_space_time_idx on _hyper_2_12_chunk o2_9 (never executed)
                                 Heap Fetches: 0
(54 rows)

-- test join against max query
-- not ChunkAppend so no chunk exclusion
SET enable_hashjoin = FALSE;
:PREFIX
SELECT o1.time,
  o2.*
FROM :TEST_TABLE o1
  INNER JOIN (
    SELECT max(time) AS max_time
    FROM :TEST_TABLE) o2 ON o1.time = o2.max_time
WHERE o1.device_id = 1
ORDER BY time;
                                                                         QUERY PLAN                                                                         
------------------------------------------------------------------------------------------------------------------------------------------------------------
 Sort (actual rows=1 loops=1)
   Sort Key: o1."time"
   Sort Method: quicksort 
   ->  Nested Loop (actual rows=1 loops=1)
         ->  Result (actual rows=1 loops=1)
               InitPlan 1 (returns $0)
                 ->  Limit (actual rows=1 loops=1)
                       ->  Custom Scan (ChunkAppend) on metrics_space (actual rows=1 loops=1)
                             Order: metrics_space."time" DESC
                             ->  Merge Append (actual rows=1 loops=1)
                                   Sort Key: _hyper_2_12_chunk."time" DESC
                                   ->  Index Only Scan Backward using _hyper_2_12_chunk_metrics_space_time_idx on _hyper_2_12_chunk (actual rows=1 loops=1)
                                         Index Cond: ("time" IS NOT NULL)
                                         Heap Fetches: 1
                                   ->  Index Only Scan Backward using _hyper_2_11_chunk_metrics_space_time_idx on _hyper_2_11_chunk (actual rows=1 loops=1)
                                         Index Cond: ("time" IS NOT NULL)
                                         Heap Fetches: 1
                                   ->  Index Only Scan Backward using _hyper_2_10_chunk_metrics_space_time_idx on _hyper_2_10_chunk (actual rows=1 loops=1)
                                         Index Cond: ("time" IS NOT NULL)
                                         Heap Fetches: 1
                             ->  Merge Append (never executed)
                                   Sort Key: _hyper_2_9_chunk."time" DESC
                                   ->  Index Only Scan Backward using _hyper_2_9_chunk_metrics_space_time_idx on _hyper_2_9_chunk (never executed)
                                         Index Cond: ("time" IS NOT NULL)
                                         Heap Fetches: 0
                                   ->  Index Only Scan Backward using _hyper_2_8_chunk_metrics_space_time_idx on _hyper_2_8_chunk (never executed)
                                         Index Cond: ("time" IS NOT NULL)
                                         Heap Fetches: 0
                                   ->  Index Only Scan Backward using _hyper_2_7_chunk_metrics_space_time_idx on _hyper_2_7_chunk (never executed)
                                         Index Cond: ("time" IS NOT NULL)
                                         Heap Fetches: 0
                             ->  Merge Append (never executed)
                                   Sort Key: _hyper_2_6_chunk."time" DESC
                                   ->  Index Only Scan Backward using _hyper_2_6_chunk_metrics_space_time_idx on _hyper_2_6_chunk (never executed)
                                         Index Cond: ("time" IS NOT NULL)
                                         Heap Fetches: 0
                                   ->  Index Only Scan Backward using _hyper_2_5_chunk_metrics_space_time_idx on _hyper_2_5_chunk (never executed)
                                         Index Cond: ("time" IS NOT NULL)
                                         Heap Fetches: 0
                                   ->  Index Only Scan Backward using _hyper_2_4_chunk_metrics_space_time_idx on _hyper_2_4_chunk (never executed)
                                         Index Cond: ("time" IS NOT NULL)
                                         Heap Fetches: 0
         ->  Append (actual rows=1 loops=1)
               ->  Index Only Scan using _hyper_2_4_chunk_metrics_space_device_id_time_idx on _hyper_2_4_chunk o1 (actual rows=0 loops=1)
                     Index Cond: ((device_id = 1) AND ("time" = ($0)))
                     Heap Fetches: 0
               ->  Index Only Scan using _hyper_2_7_chunk_metrics_space_device_id_time_idx on _hyper_2_7_chunk o1_1 (actual rows=0 loops=1)
                     Index Cond: ((device_id = 1) AND ("time" = ($0)))
                     Heap Fetches: 0
               ->  Index Only Scan using _hyper_2_10_chunk_metrics_space_device_id_time_idx on _hyper_2_10_chunk o1_2 (actual rows=1 loops=1)
                     Index Cond: ((device_id = 1) AND ("time" = ($0)))
                     Heap Fetches: 1
(52 rows)

RESET enable_hashjoin;
SET enable_seqscan TO false;
-- test JOIN on time column
-- should use 2 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  INNER JOIN :TEST_TABLE o2 ON o1.time = o2.time
WHERE o1.device_id = 1
  AND o2.device_id = 2
ORDER BY o1.time
LIMIT 100;
                                                                     QUERY PLAN                                                                     
----------------------------------------------------------------------------------------------------------------------------------------------------
 Limit (actual rows=100 loops=1)
   ->  Merge Join (actual rows=100 loops=1)
         Merge Cond: (o1."time" = o2."time")
         ->  Custom Scan (ChunkAppend) on metrics_space o1 (actual rows=100 loops=1)
               Order: o1."time"
               ->  Index Scan using _hyper_2_4_chunk_metrics_space_time_idx on _hyper_2_4_chunk o1_1 (actual rows=100 loops=1)
                     Filter: (device_id = 1)
               ->  Index Scan using _hyper_2_7_chunk_metrics_space_time_idx on _hyper_2_7_chunk o1_2 (never executed)
                     Filter: (device_id = 1)
               ->  Index Scan using _hyper_2_10_chunk_metrics_space_time_idx on _hyper_2_10_chunk o1_3 (never executed)
                     Filter: (device_id = 1)
         ->  Materialize (actual rows=100 loops=1)
               ->  Custom Scan (ChunkAppend) on metrics_space o2 (actual rows=100 loops=1)
                     Order: o2."time"
                     ->  Index Only Scan using _hyper_2_5_chunk_metrics_space_device_id_time_idx on _hyper_2_5_chunk o2_1 (actual rows=100 loops=1)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 100
                     ->  Index Only Scan using _hyper_2_8_chunk_metrics_space_device_id_time_idx on _hyper_2_8_chunk o2_2 (never executed)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 0
                     ->  Index Only Scan using _hyper_2_11_chunk_metrics_space_device_id_time_idx on _hyper_2_11_chunk o2_3 (never executed)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 0
(23 rows)

-- test JOIN on time column with USING
-- should use 2 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  INNER JOIN :TEST_TABLE o2 USING (time)
WHERE o1.device_id = 1
  AND o2.device_id = 2
ORDER BY o1.time
LIMIT 100;
                                                                     QUERY PLAN                                                                     
----------------------------------------------------------------------------------------------------------------------------------------------------
 Limit (actual rows=100 loops=1)
   ->  Merge Join (actual rows=100 loops=1)
         Merge Cond: (o1."time" = o2."time")
         ->  Custom Scan (ChunkAppend) on metrics_space o1 (actual rows=100 loops=1)
               Order: o1."time"
               ->  Index Scan using _hyper_2_4_chunk_metrics_space_time_idx on _hyper_2_4_chunk o1_1 (actual rows=100 loops=1)
                     Filter: (device_id = 1)
               ->  Index Scan using _hyper_2_7_chunk_metrics_space_time_idx on _hyper_2_7_chunk o1_2 (never executed)
                     Filter: (device_id = 1)
               ->  Index Scan using _hyper_2_10_chunk_metrics_space_time_idx on _hyper_2_10_chunk o1_3 (never executed)
                     Filter: (device_id = 1)
         ->  Materialize (actual rows=100 loops=1)
               ->  Custom Scan (ChunkAppend) on metrics_space o2 (actual rows=100 loops=1)
                     Order: o2."time"
                     ->  Index Only Scan using _hyper_2_5_chunk_metrics_space_device_id_time_idx on _hyper_2_5_chunk o2_1 (actual rows=100 loops=1)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 100
                     ->  Index Only Scan using _hyper_2_8_chunk_metrics_space_device_id_time_idx on _hyper_2_8_chunk o2_2 (never executed)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 0
                     ->  Index Only Scan using _hyper_2_11_chunk_metrics_space_device_id_time_idx on _hyper_2_11_chunk o2_3 (never executed)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 0
(23 rows)

-- test NATURAL JOIN on time column
-- should use 2 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  NATURAL INNER JOIN :TEST_TABLE o2
WHERE o1.device_id = 1
  AND o2.device_id = 2
ORDER BY o1.time
LIMIT 100;
                  QUERY PLAN                  
----------------------------------------------
 Limit (actual rows=0 loops=1)
   ->  Sort (actual rows=0 loops=1)
         Sort Key: o1."time"
         Sort Method: quicksort 
         ->  Result (actual rows=0 loops=1)
               One-Time Filter: false
(6 rows)

-- test LEFT JOIN on time column
-- should use 2 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  LEFT JOIN :TEST_TABLE o2 ON o1.time = o2.time
WHERE o1.device_id = 1
  AND o2.device_id = 2
ORDER BY o1.time
LIMIT 100;
                                                                     QUERY PLAN                                                                     
----------------------------------------------------------------------------------------------------------------------------------------------------
 Limit (actual rows=100 loops=1)
   ->  Merge Join (actual rows=100 loops=1)
         Merge Cond: (o1."time" = o2."time")
         ->  Custom Scan (ChunkAppend) on metrics_space o1 (actual rows=100 loops=1)
               Order: o1."time"
               ->  Index Scan using _hyper_2_4_chunk_metrics_space_time_idx on _hyper_2_4_chunk o1_1 (actual rows=100 loops=1)
                     Filter: (device_id = 1)
               ->  Index Scan using _hyper_2_7_chunk_metrics_space_time_idx on _hyper_2_7_chunk o1_2 (never executed)
                     Filter: (device_id = 1)
               ->  Index Scan using _hyper_2_10_chunk_metrics_space_time_idx on _hyper_2_10_chunk o1_3 (never executed)
                     Filter: (device_id = 1)
         ->  Materialize (actual rows=100 loops=1)
               ->  Custom Scan (ChunkAppend) on metrics_space o2 (actual rows=100 loops=1)
                     Order: o2."time"
                     ->  Index Only Scan using _hyper_2_5_chunk_metrics_space_device_id_time_idx on _hyper_2_5_chunk o2_1 (actual rows=100 loops=1)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 100
                     ->  Index Only Scan using _hyper_2_8_chunk_metrics_space_device_id_time_idx on _hyper_2_8_chunk o2_2 (never executed)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 0
                     ->  Index Only Scan using _hyper_2_11_chunk_metrics_space_device_id_time_idx on _hyper_2_11_chunk o2_3 (never executed)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 0
(23 rows)

-- test RIGHT JOIN on time column
-- should use 2 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  RIGHT JOIN :TEST_TABLE o2 ON o1.time = o2.time
WHERE o1.device_id = 1
  AND o2.device_id = 2
ORDER BY o2.time
LIMIT 100;
                                                                     QUERY PLAN                                                                     
----------------------------------------------------------------------------------------------------------------------------------------------------
 Limit (actual rows=100 loops=1)
   ->  Merge Join (actual rows=100 loops=1)
         Merge Cond: (o1."time" = o2."time")
         ->  Custom Scan (ChunkAppend) on metrics_space o1 (actual rows=100 loops=1)
               Order: o1."time"
               ->  Index Scan using _hyper_2_4_chunk_metrics_space_time_idx on _hyper_2_4_chunk o1_1 (actual rows=100 loops=1)
                     Filter: (device_id = 1)
               ->  Index Scan using _hyper_2_7_chunk_metrics_space_time_idx on _hyper_2_7_chunk o1_2 (never executed)
                     Filter: (device_id = 1)
               ->  Index Scan using _hyper_2_10_chunk_metrics_space_time_idx on _hyper_2_10_chunk o1_3 (never executed)
                     Filter: (device_id = 1)
         ->  Materialize (actual rows=100 loops=1)
               ->  Custom Scan (ChunkAppend) on metrics_space o2 (actual rows=100 loops=1)
                     Order: o2."time"
                     ->  Index Only Scan using _hyper_2_5_chunk_metrics_space_device_id_time_idx on _hyper_2_5_chunk o2_1 (actual rows=100 loops=1)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 100
                     ->  Index Only Scan using _hyper_2_8_chunk_metrics_space_device_id_time_idx on _hyper_2_8_chunk o2_2 (never executed)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 0
                     ->  Index Only Scan using _hyper_2_11_chunk_metrics_space_device_id_time_idx on _hyper_2_11_chunk o2_3 (never executed)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 0
(23 rows)

-- test JOIN on time column with ON clause expression order switched
-- should use 2 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  INNER JOIN :TEST_TABLE o2 ON o2.time = o1.time
WHERE o1.device_id = 1
  AND o2.device_id = 2
ORDER BY o1.time
LIMIT 100;
                                                                     QUERY PLAN                                                                     
----------------------------------------------------------------------------------------------------------------------------------------------------
 Limit (actual rows=100 loops=1)
   ->  Merge Join (actual rows=100 loops=1)
         Merge Cond: (o1."time" = o2."time")
         ->  Custom Scan (ChunkAppend) on metrics_space o1 (actual rows=100 loops=1)
               Order: o1."time"
               ->  Index Scan using _hyper_2_4_chunk_metrics_space_time_idx on _hyper_2_4_chunk o1_1 (actual rows=100 loops=1)
                     Filter: (device_id = 1)
               ->  Index Scan using _hyper_2_7_chunk_metrics_space_time_idx on _hyper_2_7_chunk o1_2 (never executed)
                     Filter: (device_id = 1)
               ->  Index Scan using _hyper_2_10_chunk_metrics_space_time_idx on _hyper_2_10_chunk o1_3 (never executed)
                     Filter: (device_id = 1)
         ->  Materialize (actual rows=100 loops=1)
               ->  Custom Scan (ChunkAppend) on metrics_space o2 (actual rows=100 loops=1)
                     Order: o2."time"
                     ->  Index Only Scan using _hyper_2_5_chunk_metrics_space_device_id_time_idx on _hyper_2_5_chunk o2_1 (actual rows=100 loops=1)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 100
                     ->  Index Only Scan using _hyper_2_8_chunk_metrics_space_device_id_time_idx on _hyper_2_8_chunk o2_2 (never executed)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 0
                     ->  Index Only Scan using _hyper_2_11_chunk_metrics_space_device_id_time_idx on _hyper_2_11_chunk o2_3 (never executed)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 0
(23 rows)

-- test JOIN on time column with equality condition in WHERE clause
-- should use 2 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  INNER JOIN :TEST_TABLE o2 ON TRUE
WHERE o1.time = o2.time
  AND o1.device_id = 1
  AND o2.device_id = 2
ORDER BY o1.time
LIMIT 100;
                                                                     QUERY PLAN                                                                     
----------------------------------------------------------------------------------------------------------------------------------------------------
 Limit (actual rows=100 loops=1)
   ->  Merge Join (actual rows=100 loops=1)
         Merge Cond: (o1."time" = o2."time")
         ->  Custom Scan (ChunkAppend) on metrics_space o1 (actual rows=100 loops=1)
               Order: o1."time"
               ->  Index Scan using _hyper_2_4_chunk_metrics_space_time_idx on _hyper_2_4_chunk o1_1 (actual rows=100 loops=1)
                     Filter: (device_id = 1)
               ->  Index Scan using _hyper_2_7_chunk_metrics_space_time_idx on _hyper_2_7_chunk o1_2 (never executed)
                     Filter: (device_id = 1)
               ->  Index Scan using _hyper_2_10_chunk_metrics_space_time_idx on _hyper_2_10_chunk o1_3 (never executed)
                     Filter: (device_id = 1)
         ->  Materialize (actual rows=100 loops=1)
               ->  Custom Scan (ChunkAppend) on metrics_space o2 (actual rows=100 loops=1)
                     Order: o2."time"
                     ->  Index Only Scan using _hyper_2_5_chunk_metrics_space_device_id_time_idx on _hyper_2_5_chunk o2_1 (actual rows=100 loops=1)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 100
                     ->  Index Only Scan using _hyper_2_8_chunk_metrics_space_device_id_time_idx on _hyper_2_8_chunk o2_2 (never executed)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 0
                     ->  Index Only Scan using _hyper_2_11_chunk_metrics_space_device_id_time_idx on _hyper_2_11_chunk o2_3 (never executed)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 0
(23 rows)

-- test JOIN on time column with ORDER BY 2nd hypertable
-- should use 2 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  INNER JOIN :TEST_TABLE o2 ON o1.time = o2.time
WHERE o1.device_id = 1
  AND o2.device_id = 2
ORDER BY o2.time
LIMIT 100;
                                                                     QUERY PLAN                                                                     
----------------------------------------------------------------------------------------------------------------------------------------------------
 Limit (actual rows=100 loops=1)
   ->  Merge Join (actual rows=100 loops=1)
         Merge Cond: (o1."time" = o2."time")
         ->  Custom Scan (ChunkAppend) on metrics_space o1 (actual rows=100 loops=1)
               Order: o1."time"
               ->  Index Scan using _hyper_2_4_chunk_metrics_space_time_idx on _hyper_2_4_chunk o1_1 (actual rows=100 loops=1)
                     Filter: (device_id = 1)
               ->  Index Scan using _hyper_2_7_chunk_metrics_space_time_idx on _hyper_2_7_chunk o1_2 (never executed)
                     Filter: (device_id = 1)
               ->  Index Scan using _hyper_2_10_chunk_metrics_space_time_idx on _hyper_2_10_chunk o1_3 (never executed)
                     Filter: (device_id = 1)
         ->  Materialize (actual rows=100 loops=1)
               ->  Custom Scan (ChunkAppend) on metrics_space o2 (actual rows=100 loops=1)
                     Order: o2."time"
                     ->  Index Only Scan using _hyper_2_5_chunk_metrics_space_device_id_time_idx on _hyper_2_5_chunk o2_1 (actual rows=100 loops=1)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 100
                     ->  Index Only Scan using _hyper_2_8_chunk_metrics_space_device_id_time_idx on _hyper_2_8_chunk o2_2 (never executed)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 0
                     ->  Index Only Scan using _hyper_2_11_chunk_metrics_space_device_id_time_idx on _hyper_2_11_chunk o2_3 (never executed)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 0
(23 rows)

-- test JOIN on time column and device_id
-- should use 2 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  INNER JOIN :TEST_TABLE o2 ON o1.device_id = o2.device_id
    AND o1.time = o2.time
  ORDER BY o1.time
  LIMIT 100;
                                                                QUERY PLAN                                                                
------------------------------------------------------------------------------------------------------------------------------------------
 Limit (actual rows=100 loops=1)
   ->  Merge Join (actual rows=100 loops=1)
         Merge Cond: (o1."time" = o2."time")
         Join Filter: (o1.device_id = o2.device_id)
         Rows Removed by Join Filter: 400
         ->  Custom Scan (ChunkAppend) on metrics_space o1 (actual rows=100 loops=1)
               Order: o1."time"
               ->  Merge Append (actual rows=100 loops=1)
                     Sort Key: o1_1."time"
                     ->  Index Scan using _hyper_2_4_chunk_metrics_space_time_idx on _hyper_2_4_chunk o1_1 (actual rows=21 loops=1)
                     ->  Index Scan using _hyper_2_5_chunk_metrics_space_time_idx on _hyper_2_5_chunk o1_2 (actual rows=60 loops=1)
                     ->  Index Scan using _hyper_2_6_chunk_metrics_space_time_idx on _hyper_2_6_chunk o1_3 (actual rows=21 loops=1)
               ->  Merge Append (never executed)
                     Sort Key: o1_4."time"
                     ->  Index Scan using _hyper_2_7_chunk_metrics_space_time_idx on _hyper_2_7_chunk o1_4 (never executed)
                     ->  Index Scan using _hyper_2_8_chunk_metrics_space_time_idx on _hyper_2_8_chunk o1_5 (never executed)
                     ->  Index Scan using _hyper_2_9_chunk_metrics_space_time_idx on _hyper_2_9_chunk o1_6 (never executed)
               ->  Merge Append (never executed)
                     Sort Key: o1_7."time"
                     ->  Index Scan using _hyper_2_10_chunk_metrics_space_time_idx on _hyper_2_10_chunk o1_7 (never executed)
                     ->  Index Scan using _hyper_2_11_chunk_metrics_space_time_idx on _hyper_2_11_chunk o1_8 (never executed)
                     ->  Index Scan using _hyper_2_12_chunk_metrics_space_time_idx on _hyper_2_12_chunk o1_9 (never executed)
         ->  Materialize (actual rows=500 loops=1)
               ->  Custom Scan (ChunkAppend) on metrics_space o2 (actual rows=101 loops=1)
                     Order: o2."time"
                     ->  Merge Append (actual rows=101 loops=1)
                           Sort Key: o2_1."time"
                           ->  Index Scan using _hyper_2_4_chunk_metrics_space_time_idx on _hyper_2_4_chunk o2_1 (actual rows=21 loops=1)
                           ->  Index Scan using _hyper_2_5_chunk_metrics_space_time_idx on _hyper_2_5_chunk o2_2 (actual rows=61 loops=1)
                           ->  Index Scan using _hyper_2_6_chunk_metrics_space_time_idx on _hyper_2_6_chunk o2_3 (actual rows=21 loops=1)
                     ->  Merge Append (never executed)
                           Sort Key: o2_4."time"
                           ->  Index Scan using _hyper_2_7_chunk_metrics_space_time_idx on _hyper_2_7_chunk o2_4 (never executed)
                           ->  Index Scan using _hyper_2_8_chunk_metrics_space_time_idx on _hyper_2_8_chunk o2_5 (never executed)
                           ->  Index Scan using _hyper_2_9_chunk_metrics_space_time_idx on _hyper_2_9_chunk o2_6 (never executed)
                     ->  Merge Append (never executed)
                           Sort Key: o2_7."time"
                           ->  Index Scan using _hyper_2_10_chunk_metrics_space_time_idx on _hyper_2_10_chunk o2_7 (never executed)
                           ->  Index Scan using _hyper_2_11_chunk_metrics_space_time_idx on _hyper_2_11_chunk o2_8 (never executed)
                           ->  Index Scan using _hyper_2_12_chunk_metrics_space_time_idx on _hyper_2_12_chunk o2_9 (never executed)
(40 rows)

-- test JOIN on device_id
-- should not use ordered append for 2nd hypertable
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  INNER JOIN :TEST_TABLE o2 ON o1.device_id = o2.device_id
WHERE o1.device_id = 1
ORDER BY o1.time
LIMIT 100;
                                                                     QUERY PLAN                                                                     
----------------------------------------------------------------------------------------------------------------------------------------------------
 Limit (actual rows=100 loops=1)
   ->  Nested Loop (actual rows=100 loops=1)
         ->  Custom Scan (ChunkAppend) on metrics_space o1 (actual rows=1 loops=1)
               Order: o1."time"
               ->  Index Scan using _hyper_2_4_chunk_metrics_space_time_idx on _hyper_2_4_chunk o1_1 (actual rows=1 loops=1)
                     Filter: (device_id = 1)
               ->  Index Scan using _hyper_2_7_chunk_metrics_space_time_idx on _hyper_2_7_chunk o1_2 (never executed)
                     Filter: (device_id = 1)
               ->  Index Scan using _hyper_2_10_chunk_metrics_space_time_idx on _hyper_2_10_chunk o1_3 (never executed)
                     Filter: (device_id = 1)
         ->  Materialize (actual rows=100 loops=1)
               ->  Append (actual rows=100 loops=1)
                     ->  Index Only Scan using _hyper_2_10_chunk_metrics_space_device_id_time_idx on _hyper_2_10_chunk o2 (actual rows=100 loops=1)
                           Index Cond: (device_id = 1)
                           Heap Fetches: 100
                     ->  Index Only Scan using _hyper_2_4_chunk_metrics_space_device_id_time_idx on _hyper_2_4_chunk o2_1 (never executed)
                           Index Cond: (device_id = 1)
                           Heap Fetches: 0
                     ->  Index Only Scan using _hyper_2_7_chunk_metrics_space_device_id_time_idx on _hyper_2_7_chunk o2_2 (never executed)
                           Index Cond: (device_id = 1)
                           Heap Fetches: 0
(21 rows)

-- test JOIN on time column with implicit join
-- should use 2 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1,
  :TEST_TABLE o2
WHERE o1.time = o2.time
  AND o1.device_id = 1
  AND o2.device_id = 2
ORDER BY o1.time
LIMIT 100;
                                                                     QUERY PLAN                                                                     
----------------------------------------------------------------------------------------------------------------------------------------------------
 Limit (actual rows=100 loops=1)
   ->  Merge Join (actual rows=100 loops=1)
         Merge Cond: (o1."time" = o2."time")
         ->  Custom Scan (ChunkAppend) on metrics_space o1 (actual rows=100 loops=1)
               Order: o1."time"
               ->  Index Scan using _hyper_2_4_chunk_metrics_space_time_idx on _hyper_2_4_chunk o1_1 (actual rows=100 loops=1)
                     Filter: (device_id = 1)
               ->  Index Scan using _hyper_2_7_chunk_metrics_space_time_idx on _hyper_2_7_chunk o1_2 (never executed)
                     Filter: (device_id = 1)
               ->  Index Scan using _hyper_2_10_chunk_metrics_space_time_idx on _hyper_2_10_chunk o1_3 (never executed)
                     Filter: (device_id = 1)
         ->  Materialize (actual rows=100 loops=1)
               ->  Custom Scan (ChunkAppend) on metrics_space o2 (actual rows=100 loops=1)
                     Order: o2."time"
                     ->  Index Only Scan using _hyper_2_5_chunk_metrics_space_device_id_time_idx on _hyper_2_5_chunk o2_1 (actual rows=100 loops=1)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 100
                     ->  Index Only Scan using _hyper_2_8_chunk_metrics_space_device_id_time_idx on _hyper_2_8_chunk o2_2 (never executed)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 0
                     ->  Index Only Scan using _hyper_2_11_chunk_metrics_space_device_id_time_idx on _hyper_2_11_chunk o2_3 (never executed)
                           Index Cond: (device_id = 2)
                           Heap Fetches: 0
(23 rows)

-- test JOIN on time column with 3 hypertables
-- should use 3 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  INNER JOIN :TEST_TABLE o2 ON o1.time = o2.time
  INNER JOIN :TEST_TABLE o3 ON o1.time = o3.time
WHERE o1.device_id = 1
  AND o2.device_id = 2
  AND o3.device_id = 3
ORDER BY o1.time
LIMIT 100;
                                                                           QUERY PLAN                                                                           
----------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit (actual rows=100 loops=1)
   ->  Merge Join (actual rows=100 loops=1)
         Merge Cond: (o3."time" = o1."time")
         ->  Custom Scan (ChunkAppend) on metrics_space o3 (actual rows=100 loops=1)
               Order: o3."time"
               ->  Index Scan using _hyper_2_6_chunk_metrics_space_time_idx on _hyper_2_6_chunk o3_1 (actual rows=100 loops=1)
                     Filter: (device_id = 3)
               ->  Index Scan using _hyper_2_9_chunk_metrics_space_time_idx on _hyper_2_9_chunk o3_2 (never executed)
                     Filter: (device_id = 3)
               ->  Index Scan using _hyper_2_12_chunk_metrics_space_time_idx on _hyper_2_12_chunk o3_3 (never executed)
                     Filter: (device_id = 3)
         ->  Materialize (actual rows=100 loops=1)
               ->  Merge Join (actual rows=100 loops=1)
                     Merge Cond: (o1."time" = o2."time")
                     ->  Custom Scan (ChunkAppend) on metrics_space o1 (actual rows=100 loops=1)
                           Order: o1."time"
                           ->  Index Scan using _hyper_2_4_chunk_metrics_space_time_idx on _hyper_2_4_chunk o1_1 (actual rows=100 loops=1)
                                 Filter: (device_id = 1)
                           ->  Index Scan using _hyper_2_7_chunk_metrics_space_time_idx on _hyper_2_7_chunk o1_2 (never executed)
                                 Filter: (device_id = 1)
                           ->  Index Scan using _hyper_2_10_chunk_metrics_space_time_idx on _hyper_2_10_chunk o1_3 (never executed)
                                 Filter: (device_id = 1)
                     ->  Materialize (actual rows=100 loops=1)
                           ->  Custom Scan (ChunkAppend) on metrics_space o2 (actual rows=100 loops=1)
                                 Order: o2."time"
                                 ->  Index Only Scan using _hyper_2_5_chunk_metrics_space_device_id_time_idx on _hyper_2_5_chunk o2_1 (actual rows=100 loops=1)
                                       Index Cond: (device_id = 2)
                                       Heap Fetches: 100
                                 ->  Index Only Scan using _hyper_2_8_chunk_metrics_space_device_id_time_idx on _hyper_2_8_chunk o2_2 (never executed)
                                       Index Cond: (device_id = 2)
                                       Heap Fetches: 0
                                 ->  Index Only Scan using _hyper_2_11_chunk_metrics_space_device_id_time_idx on _hyper_2_11_chunk o2_3 (never executed)
                                       Index Cond: (device_id = 2)
                                       Heap Fetches: 0
(34 rows)

RESET enable_seqscan;
\set TEST_TABLE 'metrics_compressed'
\ir :TEST_QUERY_NAME
-- This file and its contents are licensed under the Timescale License.
-- Please see the included NOTICE for copyright information and
-- LICENSE-TIMESCALE for a copy of the license.
-- test LATERAL with ordered append in the outer query
:PREFIX
SELECT time,
  pg_typeof(l)
FROM :TEST_TABLE,
  LATERAL (
    SELECT *
    FROM (
      VALUES (1),
        (2)) v) l
ORDER BY time DESC
LIMIT 2;
                                               QUERY PLAN                                               
--------------------------------------------------------------------------------------------------------
 Limit (actual rows=2 loops=1)
   ->  Sort (actual rows=2 loops=1)
         Sort Key: _hyper_3_15_chunk."time" DESC
         Sort Method: top-N heapsort 
         ->  Nested Loop (actual rows=136740 loops=1)
               ->  Append (actual rows=68370 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_3_15_chunk (actual rows=25190 loops=1)
                           ->  Seq Scan on compress_hyper_4_16_chunk (actual rows=30 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_3_14_chunk (actual rows=25190 loops=1)
                           ->  Seq Scan on compress_hyper_4_17_chunk (actual rows=30 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_3_13_chunk (actual rows=17990 loops=1)
                           ->  Seq Scan on compress_hyper_4_18_chunk (actual rows=20 loops=1)
               ->  Materialize (actual rows=2 loops=68370)
                     ->  Values Scan on "*VALUES*" (actual rows=2 loops=1)
(14 rows)

-- test LATERAL with ordered append in the lateral query
:PREFIX
SELECT time,
  pg_typeof(v)
FROM (
  VALUES (1),
    (2)) v,
  LATERAL (
    SELECT *
    FROM :TEST_TABLE
    ORDER BY time DESC
    LIMIT 2) l;
                                                        QUERY PLAN                                                        
--------------------------------------------------------------------------------------------------------------------------
 Nested Loop (actual rows=4 loops=1)
   ->  Values Scan on "*VALUES*" (actual rows=2 loops=1)
   ->  Materialize (actual rows=2 loops=2)
         ->  Subquery Scan on l (actual rows=2 loops=1)
               ->  Limit (actual rows=2 loops=1)
                     ->  Sort (actual rows=2 loops=1)
                           Sort Key: _hyper_3_15_chunk."time" DESC
                           Sort Method: top-N heapsort 
                           ->  Result (actual rows=68370 loops=1)
                                 ->  Append (actual rows=68370 loops=1)
                                       ->  Custom Scan (DecompressChunk) on _hyper_3_15_chunk (actual rows=25190 loops=1)
                                             ->  Seq Scan on compress_hyper_4_16_chunk (actual rows=30 loops=1)
                                       ->  Custom Scan (DecompressChunk) on _hyper_3_14_chunk (actual rows=25190 loops=1)
                                             ->  Seq Scan on compress_hyper_4_17_chunk (actual rows=30 loops=1)
                                       ->  Custom Scan (DecompressChunk) on _hyper_3_13_chunk (actual rows=17990 loops=1)
                                             ->  Seq Scan on compress_hyper_4_18_chunk (actual rows=20 loops=1)
(16 rows)

-- test plan with best index is chosen
-- this should use device_id, time index
:PREFIX
SELECT time,
  device_id
FROM :TEST_TABLE
WHERE device_id = 1
ORDER BY time DESC
LIMIT 1;
                                                                       QUERY PLAN                                                                        
---------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit (actual rows=1 loops=1)
   ->  Custom Scan (ChunkAppend) on metrics_compressed (actual rows=1 loops=1)
         Order: metrics_compressed."time" DESC
         ->  Custom Scan (DecompressChunk) on _hyper_3_15_chunk (actual rows=1 loops=1)
               ->  Index Scan using compress_hyper_4_16_chunk__compressed_hypertable_4_device_id__t on compress_hyper_4_16_chunk (actual rows=1 loops=1)
                     Index Cond: (device_id = 1)
         ->  Custom Scan (DecompressChunk) on _hyper_3_14_chunk (never executed)
               ->  Index Scan using compress_hyper_4_17_chunk__compressed_hypertable_4_device_id__t on compress_hyper_4_17_chunk (never executed)
                     Index Cond: (device_id = 1)
         ->  Custom Scan (DecompressChunk) on _hyper_3_13_chunk (never executed)
               ->  Index Scan using compress_hyper_4_18_chunk__compressed_hypertable_4_device_id__t on compress_hyper_4_18_chunk (never executed)
                     Index Cond: (device_id = 1)
(12 rows)

-- test plan with best index is chosen
-- this should use time index
:PREFIX
SELECT time
FROM :TEST_TABLE
ORDER BY time DESC
LIMIT 1;
                                            QUERY PLAN                                            
--------------------------------------------------------------------------------------------------
 Limit (actual rows=1 loops=1)
   ->  Sort (actual rows=1 loops=1)
         Sort Key: _hyper_3_15_chunk."time" DESC
         Sort Method: top-N heapsort 
         ->  Append (actual rows=68370 loops=1)
               ->  Custom Scan (DecompressChunk) on _hyper_3_15_chunk (actual rows=25190 loops=1)
                     ->  Seq Scan on compress_hyper_4_16_chunk (actual rows=30 loops=1)
               ->  Custom Scan (DecompressChunk) on _hyper_3_14_chunk (actual rows=25190 loops=1)
                     ->  Seq Scan on compress_hyper_4_17_chunk (actual rows=30 loops=1)
               ->  Custom Scan (DecompressChunk) on _hyper_3_13_chunk (actual rows=17990 loops=1)
                     ->  Seq Scan on compress_hyper_4_18_chunk (actual rows=20 loops=1)
(11 rows)

-- test LATERAL with correlated query
-- only last chunk should be executed
:PREFIX
SELECT g.time,
  l.time
FROM generate_series('2000-01-01'::timestamptz, '2000-01-03', '1d') AS g (time)
  LEFT OUTER JOIN LATERAL (
  SELECT *
  FROM :TEST_TABLE o
  WHERE o.time >= g.time
    AND o.time < g.time + '1d'::interval
  ORDER BY time DESC
  LIMIT 1) l ON TRUE;
                                                           QUERY PLAN                                                           
--------------------------------------------------------------------------------------------------------------------------------
 Nested Loop Left Join (actual rows=3 loops=1)
   ->  Function Scan on generate_series g (actual rows=3 loops=1)
   ->  Limit (actual rows=1 loops=3)
         ->  Sort (actual rows=1 loops=3)
               Sort Key: o."time" DESC
               Sort Method: top-N heapsort 
               ->  Custom Scan (ChunkAppend) on metrics_compressed o (actual rows=3600 loops=3)
                     Chunks excluded during startup: 0
                     Chunks excluded during runtime: 2
                     ->  Custom Scan (DecompressChunk) on _hyper_3_15_chunk o_1 (never executed)
                           Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                           ->  Seq Scan on compress_hyper_4_16_chunk (never executed)
                                 Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                     ->  Custom Scan (DecompressChunk) on _hyper_3_14_chunk o_2 (never executed)
                           Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                           ->  Seq Scan on compress_hyper_4_17_chunk (never executed)
                                 Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                     ->  Custom Scan (DecompressChunk) on _hyper_3_13_chunk o_3 (actual rows=3600 loops=3)
                           Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                           Rows Removed by Filter: 4063
                           ->  Seq Scan on compress_hyper_4_18_chunk (actual rows=8 loops=3)
                                 Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                                 Rows Removed by Filter: 12
(23 rows)

-- test LATERAL with correlated query
-- only 2nd chunk should be executed
:PREFIX
SELECT g.time,
  l.time
FROM generate_series('2000-01-10'::timestamptz, '2000-01-11', '1d') AS g (time)
  LEFT OUTER JOIN LATERAL (
  SELECT *
  FROM :TEST_TABLE o
  WHERE o.time >= g.time
    AND o.time < g.time + '1d'::interval
  ORDER BY time
  LIMIT 1) l ON TRUE;
                                                           QUERY PLAN                                                           
--------------------------------------------------------------------------------------------------------------------------------
 Nested Loop Left Join (actual rows=2 loops=1)
   ->  Function Scan on generate_series g (actual rows=2 loops=1)
   ->  Limit (actual rows=1 loops=2)
         ->  Sort (actual rows=1 loops=2)
               Sort Key: o."time"
               Sort Method: top-N heapsort 
               ->  Custom Scan (ChunkAppend) on metrics_compressed o (actual rows=3600 loops=2)
                     Chunks excluded during startup: 0
                     Chunks excluded during runtime: 2
                     ->  Custom Scan (DecompressChunk) on _hyper_3_13_chunk o_1 (never executed)
                           Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                           ->  Seq Scan on compress_hyper_4_18_chunk (never executed)
                                 Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                     ->  Custom Scan (DecompressChunk) on _hyper_3_14_chunk o_2 (actual rows=3600 loops=2)
                           Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                           Rows Removed by Filter: 3900
                           ->  Seq Scan on compress_hyper_4_17_chunk (actual rows=8 loops=2)
                                 Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                                 Rows Removed by Filter: 22
                     ->  Custom Scan (DecompressChunk) on _hyper_3_15_chunk o_3 (never executed)
                           Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                           ->  Seq Scan on compress_hyper_4_16_chunk (never executed)
                                 Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
(23 rows)

-- test startup and runtime exclusion together
:PREFIX
SELECT g.time,
  l.time
FROM generate_series('2000-01-01'::timestamptz, '2000-01-03', '1d') AS g (time)
  LEFT OUTER JOIN LATERAL (
  SELECT *
  FROM :TEST_TABLE o
  WHERE o.time >= g.time
    AND o.time < g.time + '1d'::interval
    AND o.time < now()
  ORDER BY time DESC
  LIMIT 1) l ON TRUE;
                                                           QUERY PLAN                                                           
--------------------------------------------------------------------------------------------------------------------------------
 Nested Loop Left Join (actual rows=3 loops=1)
   ->  Function Scan on generate_series g (actual rows=3 loops=1)
   ->  Limit (actual rows=1 loops=3)
         ->  Sort (actual rows=1 loops=3)
               Sort Key: o."time" DESC
               Sort Method: top-N heapsort 
               ->  Custom Scan (ChunkAppend) on metrics_compressed o (actual rows=3600 loops=3)
                     Chunks excluded during startup: 0
                     Chunks excluded during runtime: 2
                     ->  Custom Scan (DecompressChunk) on _hyper_3_15_chunk o_1 (never executed)
                           Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)) AND ("time" < now()))
                           ->  Seq Scan on compress_hyper_4_16_chunk (never executed)
                                 Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                     ->  Custom Scan (DecompressChunk) on _hyper_3_14_chunk o_2 (never executed)
                           Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)) AND ("time" < now()))
                           ->  Seq Scan on compress_hyper_4_17_chunk (never executed)
                                 Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                     ->  Custom Scan (DecompressChunk) on _hyper_3_13_chunk o_3 (actual rows=3600 loops=3)
                           Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)) AND ("time" < now()))
                           Rows Removed by Filter: 4063
                           ->  Seq Scan on compress_hyper_4_18_chunk (actual rows=8 loops=3)
                                 Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                                 Rows Removed by Filter: 12
(23 rows)

-- test startup and runtime exclusion together
-- all chunks should be filtered
:PREFIX
SELECT g.time,
  l.time
FROM generate_series('2000-01-01'::timestamptz, '2000-01-03', '1d') AS g (time)
  LEFT OUTER JOIN LATERAL (
  SELECT *
  FROM :TEST_TABLE o
  WHERE o.time >= g.time
    AND o.time < g.time + '1d'::interval
    AND o.time > now()
  ORDER BY time DESC
  LIMIT 1) l ON TRUE;
                                         QUERY PLAN                                          
---------------------------------------------------------------------------------------------
 Nested Loop Left Join (actual rows=3 loops=1)
   ->  Function Scan on generate_series g (actual rows=3 loops=1)
   ->  Limit (actual rows=0 loops=3)
         ->  Sort (actual rows=0 loops=3)
               Sort Key: o."time" DESC
               Sort Method: quicksort 
               ->  Custom Scan (ChunkAppend) on metrics_compressed o (actual rows=0 loops=3)
                     Chunks excluded during startup: 3
(8 rows)

-- test JOIN
-- no exclusion on joined table because quals are not propagated yet
:PREFIX
SELECT o1.time,
  o2.time
FROM :TEST_TABLE o1
  INNER JOIN :TEST_TABLE o2 ON o1.time = o2.time
WHERE o1.time < '2000-02-01'
  AND o1.device_id = 1
  AND o2.device_id = 2
ORDER BY o1.time;
                                                                                             QUERY PLAN                                                                                             
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Merge Join (actual rows=13674 loops=1)
   Merge Cond: (o1."time" = o2."time")
   ->  Custom Scan (ChunkAppend) on metrics_compressed o1 (actual rows=13674 loops=1)
         Order: o1."time"
         ->  Custom Scan (DecompressChunk) on _hyper_3_13_chunk o1_1 (actual rows=3598 loops=1)
               Filter: ("time" < 'Tue Feb 01 00:00:00 2000 PST'::timestamp with time zone)
               ->  Index Scan Backward using compress_hyper_4_18_chunk__compressed_hypertable_4_device_id__t on compress_hyper_4_18_chunk (actual rows=4 loops=1)
                     Index Cond: (device_id = 1)
                     Filter: (_ts_meta_min_1 < 'Tue Feb 01 00:00:00 2000 PST'::timestamp with time zone)
         ->  Custom Scan (DecompressChunk) on _hyper_3_14_chunk o1_2 (actual rows=5038 loops=1)
               Filter: ("time" < 'Tue Feb 01 00:00:00 2000 PST'::timestamp with time zone)
               ->  Index Scan Backward using compress_hyper_4_17_chunk__compressed_hypertable_4_device_id__t on compress_hyper_4_17_chunk (actual rows=6 loops=1)
                     Index Cond: (device_id = 1)
                     Filter: (_ts_meta_min_1 < 'Tue Feb 01 00:00:00 2000 PST'::timestamp with time zone)
         ->  Custom Scan (DecompressChunk) on _hyper_3_15_chunk o1_3 (actual rows=5038 loops=1)
               Filter: ("time" < 'Tue Feb 01 00:00:00 2000 PST'::timestamp with time zone)
               ->  Index Scan Backward using compress_hyper_4_16_chunk__compressed_hypertable_4_device_id__t on compress_hyper_4_16_chunk (actual rows=6 loops=1)
                     Index Cond: (device_id = 1)
                     Filter: (_ts_meta_min_1 < 'Tue Feb 01 00:00:00 2000 PST'::timestamp with time zone)
   ->  Materialize (actual rows=13674 loops=1)
         ->  Custom Scan (ChunkAppend) on metrics_compressed o2 (actual rows=13674 loops=1)
               Order: o2."time"
               ->  Custom Scan (DecompressChunk) on _hyper_3_13_chunk o2_1 (actual rows=3598 loops=1)
                     Filter: ("time" < 'Tue Feb 01 00:00:00 2000 PST'::timestamp with time zone)
                     ->  Index Scan Backward using compress_hyper_4_18_chunk__compressed_hypertable_4_device_id__t on compress_hyper_4_18_chunk compress_hyper_4_18_chunk_1 (actual rows=4 loops=1)
                           Index Cond: (device_id = 2)
                           Filter: (_ts_meta_min_1 < 'Tue Feb 01 00:00:00 2000 PST'::timestamp with time zone)
               ->  Custom Scan (DecompressChunk) on _hyper_3_14_chunk o2_2 (actual rows=5038 loops=1)
                     Filter: ("time" < 'Tue Feb 01 00:00:00 2000 PST'::timestamp with time zone)
                     ->  Index Scan Backward using compress_hyper_4_17_chunk__compressed_hypertable_4_device_id__t on compress_hyper_4_17_chunk compress_hyper_4_17_chunk_1 (actual rows=6 loops=1)
                           Index Cond: (device_id = 2)
                           Filter: (_ts_meta_min_1 < 'Tue Feb 01 00:00:00 2000 PST'::timestamp with time zone)
               ->  Custom Scan (DecompressChunk) on _hyper_3_15_chunk o2_3 (actual rows=5038 loops=1)
                     Filter: ("time" < 'Tue Feb 01 00:00:00 2000 PST'::timestamp with time zone)
                     ->  Index Scan Backward using compress_hyper_4_16_chunk__compressed_hypertable_4_device_id__t on compress_hyper_4_16_chunk compress_hyper_4_16_chunk_1 (actual rows=6 loops=1)
                           Index Cond: (device_id = 2)
                           Filter: (_ts_meta_min_1 < 'Tue Feb 01 00:00:00 2000 PST'::timestamp with time zone)
(37 rows)

-- test JOIN
-- last chunk of o2 should not be executed
:PREFIX
SELECT o1.time,
  o2.time
FROM :TEST_TABLE o1
  INNER JOIN (
    SELECT *
    FROM :TEST_TABLE o2
    ORDER BY time) o2 ON o1.time = o2.time
WHERE o1.time < '2000-01-08'
ORDER BY o1.time
LIMIT 10;
                                                              QUERY PLAN                                                              
--------------------------------------------------------------------------------------------------------------------------------------
 Limit (actual rows=10 loops=1)
   ->  Merge Join (actual rows=10 loops=1)
         Merge Cond: (o1."time" = o2."time")
         ->  Sort (actual rows=2 loops=1)
               Sort Key: o1."time"
               Sort Method: quicksort 
               ->  Append (actual rows=26390 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_3_13_chunk o1 (actual rows=17990 loops=1)
                           Filter: ("time" < 'Sat Jan 08 00:00:00 2000 PST'::timestamp with time zone)
                           ->  Seq Scan on compress_hyper_4_18_chunk (actual rows=20 loops=1)
                                 Filter: (_ts_meta_min_1 < 'Sat Jan 08 00:00:00 2000 PST'::timestamp with time zone)
                     ->  Custom Scan (DecompressChunk) on _hyper_3_14_chunk o1_1 (actual rows=8400 loops=1)
                           Filter: ("time" < 'Sat Jan 08 00:00:00 2000 PST'::timestamp with time zone)
                           Rows Removed by Filter: 1790
                           ->  Seq Scan on compress_hyper_4_17_chunk (actual rows=15 loops=1)
                                 Filter: (_ts_meta_min_1 < 'Sat Jan 08 00:00:00 2000 PST'::timestamp with time zone)
                                 Rows Removed by Filter: 15
         ->  Materialize (actual rows=10 loops=1)
               ->  Sort (actual rows=6 loops=1)
                     Sort Key: o2."time"
                     Sort Method: quicksort 
                     ->  Result (actual rows=68370 loops=1)
                           ->  Append (actual rows=68370 loops=1)
                                 ->  Custom Scan (DecompressChunk) on _hyper_3_13_chunk o2 (actual rows=17990 loops=1)
                                       ->  Seq Scan on compress_hyper_4_18_chunk compress_hyper_4_18_chunk_1 (actual rows=20 loops=1)
                                 ->  Custom Scan (DecompressChunk) on _hyper_3_14_chunk o2_1 (actual rows=25190 loops=1)
                                       ->  Seq Scan on compress_hyper_4_17_chunk compress_hyper_4_17_chunk_1 (actual rows=30 loops=1)
                                 ->  Custom Scan (DecompressChunk) on _hyper_3_15_chunk o2_2 (actual rows=25190 loops=1)
                                       ->  Seq Scan on compress_hyper_4_16_chunk (actual rows=30 loops=1)
(29 rows)

-- test join against max query
-- not ChunkAppend so no chunk exclusion
SET enable_hashjoin = FALSE;
:PREFIX
SELECT o1.time,
  o2.*
FROM :TEST_TABLE o1
  INNER JOIN (
    SELECT max(time) AS max_time
    FROM :TEST_TABLE) o2 ON o1.time = o2.max_time
WHERE o1.device_id = 1
ORDER BY time;
                                                                            QUERY PLAN                                                                            
------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Merge Join (actual rows=1 loops=1)
   Merge Cond: (o1."time" = (max(_hyper_3_13_chunk."time")))
   ->  Custom Scan (ChunkAppend) on metrics_compressed o1 (actual rows=13674 loops=1)
         Order: o1."time"
         ->  Custom Scan (DecompressChunk) on _hyper_3_13_chunk o1_1 (actual rows=3598 loops=1)
               ->  Index Scan Backward using compress_hyper_4_18_chunk__compressed_hypertable_4_device_id__t on compress_hyper_4_18_chunk (actual rows=4 loops=1)
                     Index Cond: (device_id = 1)
         ->  Custom Scan (DecompressChunk) on _hyper_3_14_chunk o1_2 (actual rows=5038 loops=1)
               ->  Index Scan Backward using compress_hyper_4_17_chunk__compressed_hypertable_4_device_id__t on compress_hyper_4_17_chunk (actual rows=6 loops=1)
                     Index Cond: (device_id = 1)
         ->  Custom Scan (DecompressChunk) on _hyper_3_15_chunk o1_3 (actual rows=5038 loops=1)
               ->  Index Scan Backward using compress_hyper_4_16_chunk__compressed_hypertable_4_device_id__t on compress_hyper_4_16_chunk (actual rows=6 loops=1)
                     Index Cond: (device_id = 1)
   ->  Sort (actual rows=1 loops=1)
         Sort Key: (max(_hyper_3_13_chunk."time"))
         Sort Method: quicksort 
         ->  Aggregate (actual rows=1 loops=1)
               ->  Append (actual rows=68370 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_3_13_chunk (actual rows=17990 loops=1)
                           ->  Seq Scan on compress_hyper_4_18_chunk compress_hyper_4_18_chunk_1 (actual rows=20 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_3_14_chunk (actual rows=25190 loops=1)
                           ->  Seq Scan on compress_hyper_4_17_chunk compress_hyper_4_17_chunk_1 (actual rows=30 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_3_15_chunk (actual rows=25190 loops=1)
                           ->  Seq Scan on compress_hyper_4_16_chunk compress_hyper_4_16_chunk_1 (actual rows=30 loops=1)
(24 rows)

RESET enable_hashjoin;
SET enable_seqscan TO false;
-- test JOIN on time column
-- should use 2 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  INNER JOIN :TEST_TABLE o2 ON o1.time = o2.time
WHERE o1.device_id = 1
  AND o2.device_id = 2
ORDER BY o1.time
LIMIT 100;
                                                                                                QUERY PLAN                                                                                                
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit (actual rows=100 loops=1)
   ->  Merge Join (actual rows=100 loops=1)
         Merge Cond: (o1."time" = o2."time")
         ->  Custom Scan (ChunkAppend) on metrics_compressed o1 (actual rows=100 loops=1)
               Order: o1."time"
               ->  Custom Scan (DecompressChunk) on _hyper_3_13_chunk o1_1 (actual rows=100 loops=1)
                     ->  Index Scan Backward using compress_hyper_4_18_chunk__compressed_hypertable_4_device_id__t on compress_hyper_4_18_chunk (actual rows=1 loops=1)
                           Index Cond: (device_id = 1)
               ->  Custom Scan (DecompressChunk) on _hyper_3_14_chunk o1_2 (never executed)
                     ->  Index Scan Backward using compress_hyper_4_17_chunk__compressed_hypertable_4_device_id__t on compress_hyper_4_17_chunk (never executed)
                           Index Cond: (device_id = 1)
               ->  Custom Scan (DecompressChunk) on _hyper_3_15_chunk o1_3 (never executed)
                     ->  Index Scan Backward using compress_hyper_4_16_chunk__compressed_hypertable_4_device_id__t on compress_hyper_4_16_chunk (never executed)
                           Index Cond: (device_id = 1)
         ->  Materialize (actual rows=100 loops=1)
               ->  Custom Scan (ChunkAppend) on metrics_compressed o2 (actual rows=100 loops=1)
                     Order: o2."time"
                     ->  Custom Scan (DecompressChunk) on _hyper_3_13_chunk o2_1 (actual rows=100 loops=1)
                           ->  Index Scan Backward using compress_hyper_4_18_chunk__compressed_hypertable_4_device_id__t on compress_hyper_4_18_chunk compress_hyper_4_18_chunk_1 (actual rows=1 loops=1)
                                 Index Cond: (device_id = 2)
                     ->  Custom Scan (DecompressChunk) on _hyper_3_14_chunk o2_2 (never executed)
                           ->  Index Scan Backward using compress_hyper_4_17_chunk__compressed_hypertable_4_device_id__t on compress_hyper_4_17_chunk compress_hyper_4_17_chunk_1 (never executed)
                                 Index Cond: (device_id = 2)
                     ->  Custom Scan (DecompressChunk) on _hyper_3_15_chunk o2_3 (never executed)
                           ->  Index Scan Backward using compress_hyper_4_16_chunk__compressed_hypertable_4_device_id__t on compress_hyper_4_16_chunk compress_hyper_4_16_chunk_1 (never executed)
                                 Index Cond: (device_id = 2)
(26 rows)

-- test JOIN on time column with USING
-- should use 2 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  INNER JOIN :TEST_TABLE o2 USING (time)
WHERE o1.device_id = 1
  AND o2.device_id = 2
ORDER BY o1.time
LIMIT 100;
                                                                                                QUERY PLAN                                                                                                
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit (actual rows=100 loops=1)
   ->  Merge Join (actual rows=100 loops=1)
         Merge Cond: (o1."time" = o2."time")
         ->  Custom Scan (ChunkAppend) on metrics_compressed o1 (actual rows=100 loops=1)
               Order: o1."time"
               ->  Custom Scan (DecompressChunk) on _hyper_3_13_chunk o1_1 (actual rows=100 loops=1)
                     ->  Index Scan Backward using compress_hyper_4_18_chunk__compressed_hypertable_4_device_id__t on compress_hyper_4_18_chunk (actual rows=1 loops=1)
                           Index Cond: (device_id = 1)
               ->  Custom Scan (DecompressChunk) on _hyper_3_14_chunk o1_2 (never executed)
                     ->  Index Scan Backward using compress_hyper_4_17_chunk__compressed_hypertable_4_device_id__t on compress_hyper_4_17_chunk (never executed)
                           Index Cond: (device_id = 1)
               ->  Custom Scan (DecompressChunk) on _hyper_3_15_chunk o1_3 (never executed)
                     ->  Index Scan Backward using compress_hyper_4_16_chunk__compressed_hypertable_4_device_id__t on compress_hyper_4_16_chunk (never executed)
                           Index Cond: (device_id = 1)
         ->  Materialize (actual rows=100 loops=1)
               ->  Custom Scan (ChunkAppend) on metrics_compressed o2 (actual rows=100 loops=1)
                     Order: o2."time"
                     ->  Custom Scan (DecompressChunk) on _hyper_3_13_chunk o2_1 (actual rows=100 loops=1)
                           ->  Index Scan Backward using compress_hyper_4_18_chunk__compressed_hypertable_4_device_id__t on compress_hyper_4_18_chunk compress_hyper_4_18_chunk_1 (actual rows=1 loops=1)
                                 Index Cond: (device_id = 2)
                     ->  Custom Scan (DecompressChunk) on _hyper_3_14_chunk o2_2 (never executed)
                           ->  Index Scan Backward using compress_hyper_4_17_chunk__compressed_hypertable_4_device_id__t on compress_hyper_4_17_chunk compress_hyper_4_17_chunk_1 (never executed)
                                 Index Cond: (device_id = 2)
                     ->  Custom Scan (DecompressChunk) on _hyper_3_15_chunk o2_3 (never executed)
                           ->  Index Scan Backward using compress_hyper_4_16_chunk__compressed_hypertable_4_device_id__t on compress_hyper_4_16_chunk compress_hyper_4_16_chunk_1 (never executed)
                                 Index Cond: (device_id = 2)
(26 rows)

-- test NATURAL JOIN on time column
-- should use 2 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  NATURAL INNER JOIN :TEST_TABLE o2
WHERE o1.device_id = 1
  AND o2.device_id = 2
ORDER BY o1.time
LIMIT 100;
                  QUERY PLAN                  
----------------------------------------------
 Limit (actual rows=0 loops=1)
   ->  Sort (actual rows=0 loops=1)
         Sort Key: o1."time"
         Sort Method: quicksort 
         ->  Result (actual rows=0 loops=1)
               One-Time Filter: false
(6 rows)

-- test LEFT JOIN on time column
-- should use 2 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  LEFT JOIN :TEST_TABLE o2 ON o1.time = o2.time
WHERE o1.device_id = 1
  AND o2.device_id = 2
ORDER BY o1.time
LIMIT 100;
                                                                                                QUERY PLAN                                                                                                
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit (actual rows=100 loops=1)
   ->  Merge Join (actual rows=100 loops=1)
         Merge Cond: (o1."time" = o2."time")
         ->  Custom Scan (ChunkAppend) on metrics_compressed o1 (actual rows=100 loops=1)
               Order: o1."time"
               ->  Custom Scan (DecompressChunk) on _hyper_3_13_chunk o1_1 (actual rows=100 loops=1)
                     ->  Index Scan Backward using compress_hyper_4_18_chunk__compressed_hypertable_4_device_id__t on compress_hyper_4_18_chunk (actual rows=1 loops=1)
                           Index Cond: (device_id = 1)
               ->  Custom Scan (DecompressChunk) on _hyper_3_14_chunk o1_2 (never executed)
                     ->  Index Scan Backward using compress_hyper_4_17_chunk__compressed_hypertable_4_device_id__t on compress_hyper_4_17_chunk (never executed)
                           Index Cond: (device_id = 1)
               ->  Custom Scan (DecompressChunk) on _hyper_3_15_chunk o1_3 (never executed)
                     ->  Index Scan Backward using compress_hyper_4_16_chunk__compressed_hypertable_4_device_id__t on compress_hyper_4_16_chunk (never executed)
                           Index Cond: (device_id = 1)
         ->  Materialize (actual rows=100 loops=1)
               ->  Custom Scan (ChunkAppend) on metrics_compressed o2 (actual rows=100 loops=1)
                     Order: o2."time"
                     ->  Custom Scan (DecompressChunk) on _hyper_3_13_chunk o2_1 (actual rows=100 loops=1)
                           ->  Index Scan Backward using compress_hyper_4_18_chunk__compressed_hypertable_4_device_id__t on compress_hyper_4_18_chunk compress_hyper_4_18_chunk_1 (actual rows=1 loops=1)
                                 Index Cond: (device_id = 2)
                     ->  Custom Scan (DecompressChunk) on _hyper_3_14_chunk o2_2 (never executed)
                           ->  Index Scan Backward using compress_hyper_4_17_chunk__compressed_hypertable_4_device_id__t on compress_hyper_4_17_chunk compress_hyper_4_17_chunk_1 (never executed)
                                 Index Cond: (device_id = 2)
                     ->  Custom Scan (DecompressChunk) on _hyper_3_15_chunk o2_3 (never executed)
                           ->  Index Scan Backward using compress_hyper_4_16_chunk__compressed_hypertable_4_device_id__t on compress_hyper_4_16_chunk compress_hyper_4_16_chunk_1 (never executed)
                                 Index Cond: (device_id = 2)
(26 rows)

-- test RIGHT JOIN on time column
-- should use 2 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  RIGHT JOIN :TEST_TABLE o2 ON o1.time = o2.time
WHERE o1.device_id = 1
  AND o2.device_id = 2
ORDER BY o2.time
LIMIT 100;
                                                                                                QUERY PLAN                                                                                                
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit (actual rows=100 loops=1)
   ->  Merge Join (actual rows=100 loops=1)
         Merge Cond: (o1."time" = o2."time")
         ->  Custom Scan (ChunkAppend) on metrics_compressed o1 (actual rows=100 loops=1)
               Order: o1."time"
               ->  Custom Scan (DecompressChunk) on _hyper_3_13_chunk o1_1 (actual rows=100 loops=1)
                     ->  Index Scan Backward using compress_hyper_4_18_chunk__compressed_hypertable_4_device_id__t on compress_hyper_4_18_chunk (actual rows=1 loops=1)
                           Index Cond: (device_id = 1)
               ->  Custom Scan (DecompressChunk) on _hyper_3_14_chunk o1_2 (never executed)
                     ->  Index Scan Backward using compress_hyper_4_17_chunk__compressed_hypertable_4_device_id__t on compress_hyper_4_17_chunk (never executed)
                           Index Cond: (device_id = 1)
               ->  Custom Scan (DecompressChunk) on _hyper_3_15_chunk o1_3 (never executed)
                     ->  Index Scan Backward using compress_hyper_4_16_chunk__compressed_hypertable_4_device_id__t on compress_hyper_4_16_chunk (never executed)
                           Index Cond: (device_id = 1)
         ->  Materialize (actual rows=100 loops=1)
               ->  Custom Scan (ChunkAppend) on metrics_compressed o2 (actual rows=100 loops=1)
                     Order: o2."time"
                     ->  Custom Scan (DecompressChunk) on _hyper_3_13_chunk o2_1 (actual rows=100 loops=1)
                           ->  Index Scan Backward using compress_hyper_4_18_chunk__compressed_hypertable_4_device_id__t on compress_hyper_4_18_chunk compress_hyper_4_18_chunk_1 (actual rows=1 loops=1)
                                 Index Cond: (device_id = 2)
                     ->  Custom Scan (DecompressChunk) on _hyper_3_14_chunk o2_2 (never executed)
                           ->  Index Scan Backward using compress_hyper_4_17_chunk__compressed_hypertable_4_device_id__t on compress_hyper_4_17_chunk compress_hyper_4_17_chunk_1 (never executed)
                                 Index Cond: (device_id = 2)
                     ->  Custom Scan (DecompressChunk) on _hyper_3_15_chunk o2_3 (never executed)
                           ->  Index Scan Backward using compress_hyper_4_16_chunk__compressed_hypertable_4_device_id__t on compress_hyper_4_16_chunk compress_hyper_4_16_chunk_1 (never executed)
                                 Index Cond: (device_id = 2)
(26 rows)

-- test JOIN on time column with ON clause expression order switched
-- should use 2 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  INNER JOIN :TEST_TABLE o2 ON o2.time = o1.time
WHERE o1.device_id = 1
  AND o2.device_id = 2
ORDER BY o1.time
LIMIT 100;
                                                                                                QUERY PLAN                                                                                                
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit (actual rows=100 loops=1)
   ->  Merge Join (actual rows=100 loops=1)
         Merge Cond: (o1."time" = o2."time")
         ->  Custom Scan (ChunkAppend) on metrics_compressed o1 (actual rows=100 loops=1)
               Order: o1."time"
               ->  Custom Scan (DecompressChunk) on _hyper_3_13_chunk o1_1 (actual rows=100 loops=1)
                     ->  Index Scan Backward using compress_hyper_4_18_chunk__compressed_hypertable_4_device_id__t on compress_hyper_4_18_chunk (actual rows=1 loops=1)
                           Index Cond: (device_id = 1)
               ->  Custom Scan (DecompressChunk) on _hyper_3_14_chunk o1_2 (never executed)
                     ->  Index Scan Backward using compress_hyper_4_17_chunk__compressed_hypertable_4_device_id__t on compress_hyper_4_17_chunk (never executed)
                           Index Cond: (device_id = 1)
               ->  Custom Scan (DecompressChunk) on _hyper_3_15_chunk o1_3 (never executed)
                     ->  Index Scan Backward using compress_hyper_4_16_chunk__compressed_hypertable_4_device_id__t on compress_hyper_4_16_chunk (never executed)
                           Index Cond: (device_id = 1)
         ->  Materialize (actual rows=100 loops=1)
               ->  Custom Scan (ChunkAppend) on metrics_compressed o2 (actual rows=100 loops=1)
                     Order: o2."time"
                     ->  Custom Scan (DecompressChunk) on _hyper_3_13_chunk o2_1 (actual rows=100 loops=1)
                           ->  Index Scan Backward using compress_hyper_4_18_chunk__compressed_hypertable_4_device_id__t on compress_hyper_4_18_chunk compress_hyper_4_18_chunk_1 (actual rows=1 loops=1)
                                 Index Cond: (device_id = 2)
                     ->  Custom Scan (DecompressChunk) on _hyper_3_14_chunk o2_2 (never executed)
                           ->  Index Scan Backward using compress_hyper_4_17_chunk__compressed_hypertable_4_device_id__t on compress_hyper_4_17_chunk compress_hyper_4_17_chunk_1 (never executed)
                                 Index Cond: (device_id = 2)
                     ->  Custom Scan (DecompressChunk) on _hyper_3_15_chunk o2_3 (never executed)
                           ->  Index Scan Backward using compress_hyper_4_16_chunk__compressed_hypertable_4_device_id__t on compress_hyper_4_16_chunk compress_hyper_4_16_chunk_1 (never executed)
                                 Index Cond: (device_id = 2)
(26 rows)

-- test JOIN on time column with equality condition in WHERE clause
-- should use 2 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  INNER JOIN :TEST_TABLE o2 ON TRUE
WHERE o1.time = o2.time
  AND o1.device_id = 1
  AND o2.device_id = 2
ORDER BY o1.time
LIMIT 100;
                                                                                                QUERY PLAN                                                                                                
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit (actual rows=100 loops=1)
   ->  Merge Join (actual rows=100 loops=1)
         Merge Cond: (o1."time" = o2."time")
         ->  Custom Scan (ChunkAppend) on metrics_compressed o1 (actual rows=100 loops=1)
               Order: o1."time"
               ->  Custom Scan (DecompressChunk) on _hyper_3_13_chunk o1_1 (actual rows=100 loops=1)
                     ->  Index Scan Backward using compress_hyper_4_18_chunk__compressed_hypertable_4_device_id__t on compress_hyper_4_18_chunk (actual rows=1 loops=1)
                           Index Cond: (device_id = 1)
               ->  Custom Scan (DecompressChunk) on _hyper_3_14_chunk o1_2 (never executed)
                     ->  Index Scan Backward using compress_hyper_4_17_chunk__compressed_hypertable_4_device_id__t on compress_hyper_4_17_chunk (never executed)
                           Index Cond: (device_id = 1)
               ->  Custom Scan (DecompressChunk) on _hyper_3_15_chunk o1_3 (never executed)
                     ->  Index Scan Backward using compress_hyper_4_16_chunk__compressed_hypertable_4_device_id__t on compress_hyper_4_16_chunk (never executed)
                           Index Cond: (device_id = 1)
         ->  Materialize (actual rows=100 loops=1)
               ->  Custom Scan (ChunkAppend) on metrics_compressed o2 (actual rows=100 loops=1)
                     Order: o2."time"
                     ->  Custom Scan (DecompressChunk) on _hyper_3_13_chunk o2_1 (actual rows=100 loops=1)
                           ->  Index Scan Backward using compress_hyper_4_18_chunk__compressed_hypertable_4_device_id__t on compress_hyper_4_18_chunk compress_hyper_4_18_chunk_1 (actual rows=1 loops=1)
                                 Index Cond: (device_id = 2)
                     ->  Custom Scan (DecompressChunk) on _hyper_3_14_chunk o2_2 (never executed)
                           ->  Index Scan Backward using compress_hyper_4_17_chunk__compressed_hypertable_4_device_id__t on compress_hyper_4_17_chunk compress_hyper_4_17_chunk_1 (never executed)
                                 Index Cond: (device_id = 2)
                     ->  Custom Scan (DecompressChunk) on _hyper_3_15_chunk o2_3 (never executed)
                           ->  Index Scan Backward using compress_hyper_4_16_chunk__compressed_hypertable_4_device_id__t on compress_hyper_4_16_chunk compress_hyper_4_16_chunk_1 (never executed)
                                 Index Cond: (device_id = 2)
(26 rows)

-- test JOIN on time column with ORDER BY 2nd hypertable
-- should use 2 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  INNER JOIN :TEST_TABLE o2 ON o1.time = o2.time
WHERE o1.device_id = 1
  AND o2.device_id = 2
ORDER BY o2.time
LIMIT 100;
                                                                                                QUERY PLAN                                                                                                
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit (actual rows=100 loops=1)
   ->  Merge Join (actual rows=100 loops=1)
         Merge Cond: (o1."time" = o2."time")
         ->  Custom Scan (ChunkAppend) on metrics_compressed o1 (actual rows=100 loops=1)
               Order: o1."time"
               ->  Custom Scan (DecompressChunk) on _hyper_3_13_chunk o1_1 (actual rows=100 loops=1)
                     ->  Index Scan Backward using compress_hyper_4_18_chunk__compressed_hypertable_4_device_id__t on compress_hyper_4_18_chunk (actual rows=1 loops=1)
                           Index Cond: (device_id = 1)
               ->  Custom Scan (DecompressChunk) on _hyper_3_14_chunk o1_2 (never executed)
                     ->  Index Scan Backward using compress_hyper_4_17_chunk__compressed_hypertable_4_device_id__t on compress_hyper_4_17_chunk (never executed)
                           Index Cond: (device_id = 1)
               ->  Custom Scan (DecompressChunk) on _hyper_3_15_chunk o1_3 (never executed)
                     ->  Index Scan Backward using compress_hyper_4_16_chunk__compressed_hypertable_4_device_id__t on compress_hyper_4_16_chunk (never executed)
                           Index Cond: (device_id = 1)
         ->  Materialize (actual rows=100 loops=1)
               ->  Custom Scan (ChunkAppend) on metrics_compressed o2 (actual rows=100 loops=1)
                     Order: o2."time"
                     ->  Custom Scan (DecompressChunk) on _hyper_3_13_chunk o2_1 (actual rows=100 loops=1)
                           ->  Index Scan Backward using compress_hyper_4_18_chunk__compressed_hypertable_4_device_id__t on compress_hyper_4_18_chunk compress_hyper_4_18_chunk_1 (actual rows=1 loops=1)
                                 Index Cond: (device_id = 2)
                     ->  Custom Scan (DecompressChunk) on _hyper_3_14_chunk o2_2 (never executed)
                           ->  Index Scan Backward using compress_hyper_4_17_chunk__compressed_hypertable_4_device_id__t on compress_hyper_4_17_chunk compress_hyper_4_17_chunk_1 (never executed)
                                 Index Cond: (device_id = 2)
                     ->  Custom Scan (DecompressChunk) on _hyper_3_15_chunk o2_3 (never executed)
                           ->  Index Scan Backward using compress_hyper_4_16_chunk__compressed_hypertable_4_device_id__t on compress_hyper_4_16_chunk compress_hyper_4_16_chunk_1 (never executed)
                                 Index Cond: (device_id = 2)
(26 rows)

-- test JOIN on time column and device_id
-- should use 2 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  INNER JOIN :TEST_TABLE o2 ON o1.device_id = o2.device_id
    AND o1.time = o2.time
  ORDER BY o1.time
  LIMIT 100;
                                                                                               QUERY PLAN                                                                                               
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit (actual rows=100 loops=1)
   ->  Sort (actual rows=100 loops=1)
         Sort Key: o1."time"
         Sort Method: top-N heapsort 
         ->  Hash Join (actual rows=68370 loops=1)
               Hash Cond: ((o1.device_id = o2.device_id) AND (o1."time" = o2."time"))
               ->  Append (actual rows=68370 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_3_13_chunk o1 (actual rows=17990 loops=1)
                           ->  Index Scan using compress_hyper_4_18_chunk__compressed_hypertable_4_device_id__t on compress_hyper_4_18_chunk (actual rows=20 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_3_14_chunk o1_1 (actual rows=25190 loops=1)
                           ->  Index Scan using compress_hyper_4_17_chunk__compressed_hypertable_4_device_id__t on compress_hyper_4_17_chunk (actual rows=30 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_3_15_chunk o1_2 (actual rows=25190 loops=1)
                           ->  Index Scan using compress_hyper_4_16_chunk__compressed_hypertable_4_device_id__t on compress_hyper_4_16_chunk (actual rows=30 loops=1)
               ->  Hash (actual rows=68370 loops=1)
                     Buckets: 131072  Batches: 1 
                     ->  Append (actual rows=68370 loops=1)
                           ->  Custom Scan (DecompressChunk) on _hyper_3_13_chunk o2 (actual rows=17990 loops=1)
                                 ->  Index Scan using compress_hyper_4_18_chunk__compressed_hypertable_4_device_id__t on compress_hyper_4_18_chunk compress_hyper_4_18_chunk_1 (actual rows=20 loops=1)
                           ->  Custom Scan (DecompressChunk) on _hyper_3_14_chunk o2_1 (actual rows=25190 loops=1)
                                 ->  Index Scan using compress_hyper_4_17_chunk__compressed_hypertable_4_device_id__t on compress_hyper_4_17_chunk compress_hyper_4_17_chunk_1 (actual rows=30 loops=1)
                           ->  Custom Scan (DecompressChunk) on _hyper_3_15_chunk o2_2 (actual rows=25190 loops=1)
                                 ->  Index Scan using compress_hyper_4_16_chunk__compressed_hypertable_4_device_id__t on compress_hyper_4_16_chunk compress_hyper_4_16_chunk_1 (actual rows=30 loops=1)
(22 rows)

-- test JOIN on device_id
-- should not use ordered append for 2nd hypertable
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  INNER JOIN :TEST_TABLE o2 ON o1.device_id = o2.device_id
WHERE o1.device_id = 1
ORDER BY o1.time
LIMIT 100;
                                                                                           QUERY PLAN                                                                                            
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit (actual rows=100 loops=1)
   ->  Nested Loop (actual rows=100 loops=1)
         ->  Custom Scan (ChunkAppend) on metrics_compressed o1 (actual rows=1 loops=1)
               Order: o1."time"
               ->  Custom Scan (DecompressChunk) on _hyper_3_13_chunk o1_1 (actual rows=1 loops=1)
                     ->  Index Scan Backward using compress_hyper_4_18_chunk__compressed_hypertable_4_device_id__t on compress_hyper_4_18_chunk (actual rows=1 loops=1)
                           Index Cond: (device_id = 1)
               ->  Custom Scan (DecompressChunk) on _hyper_3_14_chunk o1_2 (never executed)
                     ->  Index Scan Backward using compress_hyper_4_17_chunk__compressed_hypertable_4_device_id__t on compress_hyper_4_17_chunk (never executed)
                           Index Cond: (device_id = 1)
               ->  Custom Scan (DecompressChunk) on _hyper_3_15_chunk o1_3 (never executed)
                     ->  Index Scan Backward using compress_hyper_4_16_chunk__compressed_hypertable_4_device_id__t on compress_hyper_4_16_chunk (never executed)
                           Index Cond: (device_id = 1)
         ->  Materialize (actual rows=100 loops=1)
               ->  Append (actual rows=100 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_3_13_chunk o2 (actual rows=100 loops=1)
                           ->  Index Scan using compress_hyper_4_18_chunk__compressed_hypertable_4_device_id__t on compress_hyper_4_18_chunk compress_hyper_4_18_chunk_1 (actual rows=1 loops=1)
                                 Index Cond: (device_id = 1)
                     ->  Custom Scan (DecompressChunk) on _hyper_3_14_chunk o2_1 (never executed)
                           ->  Index Scan using compress_hyper_4_17_chunk__compressed_hypertable_4_device_id__t on compress_hyper_4_17_chunk compress_hyper_4_17_chunk_1 (never executed)
                                 Index Cond: (device_id = 1)
                     ->  Custom Scan (DecompressChunk) on _hyper_3_15_chunk o2_2 (never executed)
                           ->  Index Scan using compress_hyper_4_16_chunk__compressed_hypertable_4_device_id__t on compress_hyper_4_16_chunk compress_hyper_4_16_chunk_1 (never executed)
                                 Index Cond: (device_id = 1)
(24 rows)

-- test JOIN on time column with implicit join
-- should use 2 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1,
  :TEST_TABLE o2
WHERE o1.time = o2.time
  AND o1.device_id = 1
  AND o2.device_id = 2
ORDER BY o1.time
LIMIT 100;
                                                                                                QUERY PLAN                                                                                                
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit (actual rows=100 loops=1)
   ->  Merge Join (actual rows=100 loops=1)
         Merge Cond: (o1."time" = o2."time")
         ->  Custom Scan (ChunkAppend) on metrics_compressed o1 (actual rows=100 loops=1)
               Order: o1."time"
               ->  Custom Scan (DecompressChunk) on _hyper_3_13_chunk o1_1 (actual rows=100 loops=1)
                     ->  Index Scan Backward using compress_hyper_4_18_chunk__compressed_hypertable_4_device_id__t on compress_hyper_4_18_chunk (actual rows=1 loops=1)
                           Index Cond: (device_id = 1)
               ->  Custom Scan (DecompressChunk) on _hyper_3_14_chunk o1_2 (never executed)
                     ->  Index Scan Backward using compress_hyper_4_17_chunk__compressed_hypertable_4_device_id__t on compress_hyper_4_17_chunk (never executed)
                           Index Cond: (device_id = 1)
               ->  Custom Scan (DecompressChunk) on _hyper_3_15_chunk o1_3 (never executed)
                     ->  Index Scan Backward using compress_hyper_4_16_chunk__compressed_hypertable_4_device_id__t on compress_hyper_4_16_chunk (never executed)
                           Index Cond: (device_id = 1)
         ->  Materialize (actual rows=100 loops=1)
               ->  Custom Scan (ChunkAppend) on metrics_compressed o2 (actual rows=100 loops=1)
                     Order: o2."time"
                     ->  Custom Scan (DecompressChunk) on _hyper_3_13_chunk o2_1 (actual rows=100 loops=1)
                           ->  Index Scan Backward using compress_hyper_4_18_chunk__compressed_hypertable_4_device_id__t on compress_hyper_4_18_chunk compress_hyper_4_18_chunk_1 (actual rows=1 loops=1)
                                 Index Cond: (device_id = 2)
                     ->  Custom Scan (DecompressChunk) on _hyper_3_14_chunk o2_2 (never executed)
                           ->  Index Scan Backward using compress_hyper_4_17_chunk__compressed_hypertable_4_device_id__t on compress_hyper_4_17_chunk compress_hyper_4_17_chunk_1 (never executed)
                                 Index Cond: (device_id = 2)
                     ->  Custom Scan (DecompressChunk) on _hyper_3_15_chunk o2_3 (never executed)
                           ->  Index Scan Backward using compress_hyper_4_16_chunk__compressed_hypertable_4_device_id__t on compress_hyper_4_16_chunk compress_hyper_4_16_chunk_1 (never executed)
                                 Index Cond: (device_id = 2)
(26 rows)

-- test JOIN on time column with 3 hypertables
-- should use 3 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  INNER JOIN :TEST_TABLE o2 ON o1.time = o2.time
  INNER JOIN :TEST_TABLE o3 ON o1.time = o3.time
WHERE o1.device_id = 1
  AND o2.device_id = 2
  AND o3.device_id = 3
ORDER BY o1.time
LIMIT 100;
                                                                                                      QUERY PLAN                                                                                                      
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit (actual rows=100 loops=1)
   ->  Merge Join (actual rows=100 loops=1)
         Merge Cond: (o3."time" = o1."time")
         ->  Custom Scan (ChunkAppend) on metrics_compressed o3 (actual rows=100 loops=1)
               Order: o3."time"
               ->  Custom Scan (DecompressChunk) on _hyper_3_13_chunk o3_1 (actual rows=100 loops=1)
                     ->  Index Scan Backward using compress_hyper_4_18_chunk__compressed_hypertable_4_device_id__t on compress_hyper_4_18_chunk compress_hyper_4_18_chunk_2 (actual rows=1 loops=1)
                           Index Cond: (device_id = 3)
               ->  Custom Scan (DecompressChunk) on _hyper_3_14_chunk o3_2 (never executed)
                     ->  Index Scan Backward using compress_hyper_4_17_chunk__compressed_hypertable_4_device_id__t on compress_hyper_4_17_chunk compress_hyper_4_17_chunk_2 (never executed)
                           Index Cond: (device_id = 3)
               ->  Custom Scan (DecompressChunk) on _hyper_3_15_chunk o3_3 (never executed)
                     ->  Index Scan Backward using compress_hyper_4_16_chunk__compressed_hypertable_4_device_id__t on compress_hyper_4_16_chunk compress_hyper_4_16_chunk_2 (never executed)
                           Index Cond: (device_id = 3)
         ->  Materialize (actual rows=100 loops=1)
               ->  Merge Join (actual rows=100 loops=1)
                     Merge Cond: (o1."time" = o2."time")
                     ->  Custom Scan (ChunkAppend) on metrics_compressed o1 (actual rows=100 loops=1)
                           Order: o1."time"
                           ->  Custom Scan (DecompressChunk) on _hyper_3_13_chunk o1_1 (actual rows=100 loops=1)
                                 ->  Index Scan Backward using compress_hyper_4_18_chunk__compressed_hypertable_4_device_id__t on compress_hyper_4_18_chunk (actual rows=1 loops=1)
                                       Index Cond: (device_id = 1)
                           ->  Custom Scan (DecompressChunk) on _hyper_3_14_chunk o1_2 (never executed)
                                 ->  Index Scan Backward using compress_hyper_4_17_chunk__compressed_hypertable_4_device_id__t on compress_hyper_4_17_chunk (never executed)
                                       Index Cond: (device_id = 1)
                           ->  Custom Scan (DecompressChunk) on _hyper_3_15_chunk o1_3 (never executed)
                                 ->  Index Scan Backward using compress_hyper_4_16_chunk__compressed_hypertable_4_device_id__t on compress_hyper_4_16_chunk (never executed)
                                       Index Cond: (device_id = 1)
                     ->  Materialize (actual rows=100 loops=1)
                           ->  Custom Scan (ChunkAppend) on metrics_compressed o2 (actual rows=100 loops=1)
                                 Order: o2."time"
                                 ->  Custom Scan (DecompressChunk) on _hyper_3_13_chunk o2_1 (actual rows=100 loops=1)
                                       ->  Index Scan Backward using compress_hyper_4_18_chunk__compressed_hypertable_4_device_id__t on compress_hyper_4_18_chunk compress_hyper_4_18_chunk_1 (actual rows=1 loops=1)
                                             Index Cond: (device_id = 2)
                                 ->  Custom Scan (DecompressChunk) on _hyper_3_14_chunk o2_2 (never executed)
                                       ->  Index Scan Backward using compress_hyper_4_17_chunk__compressed_hypertable_4_device_id__t on compress_hyper_4_17_chunk compress_hyper_4_17_chunk_1 (never executed)
                                             Index Cond: (device_id = 2)
                                 ->  Custom Scan (DecompressChunk) on _hyper_3_15_chunk o2_3 (never executed)
                                       ->  Index Scan Backward using compress_hyper_4_16_chunk__compressed_hypertable_4_device_id__t on compress_hyper_4_16_chunk compress_hyper_4_16_chunk_1 (never executed)
                                             Index Cond: (device_id = 2)
(40 rows)

RESET enable_seqscan;
\set TEST_TABLE 'metrics_space_compressed'
\ir :TEST_QUERY_NAME
-- This file and its contents are licensed under the Timescale License.
-- Please see the included NOTICE for copyright information and
-- LICENSE-TIMESCALE for a copy of the license.
-- test LATERAL with ordered append in the outer query
:PREFIX
SELECT time,
  pg_typeof(l)
FROM :TEST_TABLE,
  LATERAL (
    SELECT *
    FROM (
      VALUES (1),
        (2)) v) l
ORDER BY time DESC
LIMIT 2;
                                               QUERY PLAN                                               
--------------------------------------------------------------------------------------------------------
 Limit (actual rows=2 loops=1)
   ->  Sort (actual rows=2 loops=1)
         Sort Key: _hyper_5_27_chunk."time" DESC
         Sort Method: top-N heapsort 
         ->  Nested Loop (actual rows=136740 loops=1)
               ->  Append (actual rows=68370 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_5_27_chunk (actual rows=5038 loops=1)
                           ->  Seq Scan on compress_hyper_6_28_chunk (actual rows=6 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_5_26_chunk (actual rows=15114 loops=1)
                           ->  Seq Scan on compress_hyper_6_29_chunk (actual rows=18 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_5_25_chunk (actual rows=5038 loops=1)
                           ->  Seq Scan on compress_hyper_6_30_chunk (actual rows=6 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_5_24_chunk (actual rows=5038 loops=1)
                           ->  Seq Scan on compress_hyper_6_31_chunk (actual rows=6 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_5_23_chunk (actual rows=15114 loops=1)
                           ->  Seq Scan on compress_hyper_6_32_chunk (actual rows=18 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_5_22_chunk (actual rows=5038 loops=1)
                           ->  Seq Scan on compress_hyper_6_33_chunk (actual rows=6 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_5_21_chunk (actual rows=3598 loops=1)
                           ->  Seq Scan on compress_hyper_6_34_chunk (actual rows=4 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_5_20_chunk (actual rows=10794 loops=1)
                           ->  Seq Scan on compress_hyper_6_35_chunk (actual rows=12 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_5_19_chunk (actual rows=3598 loops=1)
                           ->  Seq Scan on compress_hyper_6_36_chunk (actual rows=4 loops=1)
               ->  Materialize (actual rows=2 loops=68370)
                     ->  Values Scan on "*VALUES*" (actual rows=2 loops=1)
(26 rows)

-- test LATERAL with ordered append in the lateral query
:PREFIX
SELECT time,
  pg_typeof(v)
FROM (
  VALUES (1),
    (2)) v,
  LATERAL (
    SELECT *
    FROM :TEST_TABLE
    ORDER BY time DESC
    LIMIT 2) l;
                                                        QUERY PLAN                                                        
--------------------------------------------------------------------------------------------------------------------------
 Nested Loop (actual rows=4 loops=1)
   ->  Values Scan on "*VALUES*" (actual rows=2 loops=1)
   ->  Materialize (actual rows=2 loops=2)
         ->  Subquery Scan on l (actual rows=2 loops=1)
               ->  Limit (actual rows=2 loops=1)
                     ->  Sort (actual rows=2 loops=1)
                           Sort Key: _hyper_5_27_chunk."time" DESC
                           Sort Method: top-N heapsort 
                           ->  Result (actual rows=68370 loops=1)
                                 ->  Append (actual rows=68370 loops=1)
                                       ->  Custom Scan (DecompressChunk) on _hyper_5_27_chunk (actual rows=5038 loops=1)
                                             ->  Seq Scan on compress_hyper_6_28_chunk (actual rows=6 loops=1)
                                       ->  Custom Scan (DecompressChunk) on _hyper_5_26_chunk (actual rows=15114 loops=1)
                                             ->  Seq Scan on compress_hyper_6_29_chunk (actual rows=18 loops=1)
                                       ->  Custom Scan (DecompressChunk) on _hyper_5_25_chunk (actual rows=5038 loops=1)
                                             ->  Seq Scan on compress_hyper_6_30_chunk (actual rows=6 loops=1)
                                       ->  Custom Scan (DecompressChunk) on _hyper_5_24_chunk (actual rows=5038 loops=1)
                                             ->  Seq Scan on compress_hyper_6_31_chunk (actual rows=6 loops=1)
                                       ->  Custom Scan (DecompressChunk) on _hyper_5_23_chunk (actual rows=15114 loops=1)
                                             ->  Seq Scan on compress_hyper_6_32_chunk (actual rows=18 loops=1)
                                       ->  Custom Scan (DecompressChunk) on _hyper_5_22_chunk (actual rows=5038 loops=1)
                                             ->  Seq Scan on compress_hyper_6_33_chunk (actual rows=6 loops=1)
                                       ->  Custom Scan (DecompressChunk) on _hyper_5_21_chunk (actual rows=3598 loops=1)
                                             ->  Seq Scan on compress_hyper_6_34_chunk (actual rows=4 loops=1)
                                       ->  Custom Scan (DecompressChunk) on _hyper_5_20_chunk (actual rows=10794 loops=1)
                                             ->  Seq Scan on compress_hyper_6_35_chunk (actual rows=12 loops=1)
                                       ->  Custom Scan (DecompressChunk) on _hyper_5_19_chunk (actual rows=3598 loops=1)
                                             ->  Seq Scan on compress_hyper_6_36_chunk (actual rows=4 loops=1)
(28 rows)

-- test plan with best index is chosen
-- this should use device_id, time index
:PREFIX
SELECT time,
  device_id
FROM :TEST_TABLE
WHERE device_id = 1
ORDER BY time DESC
LIMIT 1;
                                       QUERY PLAN                                       
----------------------------------------------------------------------------------------
 Limit (actual rows=1 loops=1)
   ->  Custom Scan (ChunkAppend) on metrics_space_compressed (actual rows=1 loops=1)
         Order: metrics_space_compressed."time" DESC
         ->  Custom Scan (DecompressChunk) on _hyper_5_25_chunk (actual rows=1 loops=1)
               ->  Sort (actual rows=1 loops=1)
                     Sort Key: compress_hyper_6_30_chunk._ts_meta_sequence_num
                     Sort Method: quicksort 
                     ->  Seq Scan on compress_hyper_6_30_chunk (actual rows=6 loops=1)
                           Filter: (device_id = 1)
         ->  Custom Scan (DecompressChunk) on _hyper_5_22_chunk (never executed)
               ->  Sort (never executed)
                     Sort Key: compress_hyper_6_33_chunk._ts_meta_sequence_num
                     ->  Seq Scan on compress_hyper_6_33_chunk (never executed)
                           Filter: (device_id = 1)
         ->  Custom Scan (DecompressChunk) on _hyper_5_19_chunk (never executed)
               ->  Sort (never executed)
                     Sort Key: compress_hyper_6_36_chunk._ts_meta_sequence_num
                     ->  Seq Scan on compress_hyper_6_36_chunk (never executed)
                           Filter: (device_id = 1)
(19 rows)

-- test plan with best index is chosen
-- this should use time index
:PREFIX
SELECT time
FROM :TEST_TABLE
ORDER BY time DESC
LIMIT 1;
                                            QUERY PLAN                                            
--------------------------------------------------------------------------------------------------
 Limit (actual rows=1 loops=1)
   ->  Sort (actual rows=1 loops=1)
         Sort Key: _hyper_5_27_chunk."time" DESC
         Sort Method: top-N heapsort 
         ->  Append (actual rows=68370 loops=1)
               ->  Custom Scan (DecompressChunk) on _hyper_5_27_chunk (actual rows=5038 loops=1)
                     ->  Seq Scan on compress_hyper_6_28_chunk (actual rows=6 loops=1)
               ->  Custom Scan (DecompressChunk) on _hyper_5_26_chunk (actual rows=15114 loops=1)
                     ->  Seq Scan on compress_hyper_6_29_chunk (actual rows=18 loops=1)
               ->  Custom Scan (DecompressChunk) on _hyper_5_25_chunk (actual rows=5038 loops=1)
                     ->  Seq Scan on compress_hyper_6_30_chunk (actual rows=6 loops=1)
               ->  Custom Scan (DecompressChunk) on _hyper_5_24_chunk (actual rows=5038 loops=1)
                     ->  Seq Scan on compress_hyper_6_31_chunk (actual rows=6 loops=1)
               ->  Custom Scan (DecompressChunk) on _hyper_5_23_chunk (actual rows=15114 loops=1)
                     ->  Seq Scan on compress_hyper_6_32_chunk (actual rows=18 loops=1)
               ->  Custom Scan (DecompressChunk) on _hyper_5_22_chunk (actual rows=5038 loops=1)
                     ->  Seq Scan on compress_hyper_6_33_chunk (actual rows=6 loops=1)
               ->  Custom Scan (DecompressChunk) on _hyper_5_21_chunk (actual rows=3598 loops=1)
                     ->  Seq Scan on compress_hyper_6_34_chunk (actual rows=4 loops=1)
               ->  Custom Scan (DecompressChunk) on _hyper_5_20_chunk (actual rows=10794 loops=1)
                     ->  Seq Scan on compress_hyper_6_35_chunk (actual rows=12 loops=1)
               ->  Custom Scan (DecompressChunk) on _hyper_5_19_chunk (actual rows=3598 loops=1)
                     ->  Seq Scan on compress_hyper_6_36_chunk (actual rows=4 loops=1)
(23 rows)

-- test LATERAL with correlated query
-- only last chunk should be executed
:PREFIX
SELECT g.time,
  l.time
FROM generate_series('2000-01-01'::timestamptz, '2000-01-03', '1d') AS g (time)
  LEFT OUTER JOIN LATERAL (
  SELECT *
  FROM :TEST_TABLE o
  WHERE o.time >= g.time
    AND o.time < g.time + '1d'::interval
  ORDER BY time DESC
  LIMIT 1) l ON TRUE;
                                                              QUERY PLAN                                                              
--------------------------------------------------------------------------------------------------------------------------------------
 Nested Loop Left Join (actual rows=3 loops=1)
   ->  Function Scan on generate_series g (actual rows=3 loops=1)
   ->  Limit (actual rows=1 loops=3)
         ->  Sort (actual rows=1 loops=3)
               Sort Key: o."time" DESC
               Sort Method: top-N heapsort 
               ->  Custom Scan (ChunkAppend) on metrics_space_compressed o (actual rows=3600 loops=3)
                     ->  Merge Append (actual rows=0 loops=3)
                           ->  Custom Scan (DecompressChunk) on _hyper_5_27_chunk o_1 (actual rows=0 loops=3)
                                 Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                                 ->  Seq Scan on compress_hyper_6_28_chunk (actual rows=0 loops=3)
                                       Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                                       Rows Removed by Filter: 6
                           ->  Custom Scan (DecompressChunk) on _hyper_5_26_chunk o_2 (actual rows=0 loops=3)
                                 Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                                 ->  Seq Scan on compress_hyper_6_29_chunk (actual rows=0 loops=3)
                                       Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                                       Rows Removed by Filter: 18
                           ->  Custom Scan (DecompressChunk) on _hyper_5_25_chunk o_3 (actual rows=0 loops=3)
                                 Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                                 ->  Seq Scan on compress_hyper_6_30_chunk (actual rows=0 loops=3)
                                       Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                                       Rows Removed by Filter: 6
                     ->  Merge Append (actual rows=0 loops=3)
                           ->  Custom Scan (DecompressChunk) on _hyper_5_24_chunk o_4 (actual rows=0 loops=3)
                                 Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                                 ->  Seq Scan on compress_hyper_6_31_chunk (actual rows=0 loops=3)
                                       Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                                       Rows Removed by Filter: 6
                           ->  Custom Scan (DecompressChunk) on _hyper_5_23_chunk o_5 (actual rows=0 loops=3)
                                 Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                                 ->  Seq Scan on compress_hyper_6_32_chunk (actual rows=0 loops=3)
                                       Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                                       Rows Removed by Filter: 18
                           ->  Custom Scan (DecompressChunk) on _hyper_5_22_chunk o_6 (actual rows=0 loops=3)
                                 Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                                 ->  Seq Scan on compress_hyper_6_33_chunk (actual rows=0 loops=3)
                                       Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                                       Rows Removed by Filter: 6
                     ->  Merge Append (actual rows=3600 loops=3)
                           ->  Custom Scan (DecompressChunk) on _hyper_5_21_chunk o_7 (actual rows=720 loops=3)
                                 Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                                 Rows Removed by Filter: 813
                                 ->  Seq Scan on compress_hyper_6_34_chunk (actual rows=2 loops=3)
                                       Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                                       Rows Removed by Filter: 2
                           ->  Custom Scan (DecompressChunk) on _hyper_5_20_chunk o_8 (actual rows=2160 loops=3)
                                 Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                                 Rows Removed by Filter: 2438
                                 ->  Seq Scan on compress_hyper_6_35_chunk (actual rows=5 loops=3)
                                       Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                                       Rows Removed by Filter: 7
                           ->  Custom Scan (DecompressChunk) on _hyper_5_19_chunk o_9 (actual rows=720 loops=3)
                                 Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                                 Rows Removed by Filter: 813
                                 ->  Seq Scan on compress_hyper_6_36_chunk (actual rows=2 loops=3)
                                       Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                                       Rows Removed by Filter: 2
(58 rows)

-- test LATERAL with correlated query
-- only 2nd chunk should be executed
:PREFIX
SELECT g.time,
  l.time
FROM generate_series('2000-01-10'::timestamptz, '2000-01-11', '1d') AS g (time)
  LEFT OUTER JOIN LATERAL (
  SELECT *
  FROM :TEST_TABLE o
  WHERE o.time >= g.time
    AND o.time < g.time + '1d'::interval
  ORDER BY time
  LIMIT 1) l ON TRUE;
                                                              QUERY PLAN                                                              
--------------------------------------------------------------------------------------------------------------------------------------
 Nested Loop Left Join (actual rows=2 loops=1)
   ->  Function Scan on generate_series g (actual rows=2 loops=1)
   ->  Limit (actual rows=1 loops=2)
         ->  Sort (actual rows=1 loops=2)
               Sort Key: o."time"
               Sort Method: top-N heapsort 
               ->  Custom Scan (ChunkAppend) on metrics_space_compressed o (actual rows=3600 loops=2)
                     ->  Merge Append (actual rows=0 loops=2)
                           ->  Custom Scan (DecompressChunk) on _hyper_5_19_chunk o_1 (actual rows=0 loops=2)
                                 Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                                 ->  Seq Scan on compress_hyper_6_36_chunk (actual rows=0 loops=2)
                                       Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                                       Rows Removed by Filter: 4
                           ->  Custom Scan (DecompressChunk) on _hyper_5_20_chunk o_2 (actual rows=0 loops=2)
                                 Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                                 ->  Seq Scan on compress_hyper_6_35_chunk (actual rows=0 loops=2)
                                       Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                                       Rows Removed by Filter: 12
                           ->  Custom Scan (DecompressChunk) on _hyper_5_21_chunk o_3 (actual rows=0 loops=2)
                                 Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                                 ->  Seq Scan on compress_hyper_6_34_chunk (actual rows=0 loops=2)
                                       Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                                       Rows Removed by Filter: 4
                     ->  Merge Append (actual rows=3600 loops=2)
                           ->  Custom Scan (DecompressChunk) on _hyper_5_22_chunk o_4 (actual rows=720 loops=2)
                                 Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                                 Rows Removed by Filter: 780
                                 ->  Seq Scan on compress_hyper_6_33_chunk (actual rows=2 loops=2)
                                       Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                                       Rows Removed by Filter: 4
                           ->  Custom Scan (DecompressChunk) on _hyper_5_23_chunk o_5 (actual rows=2160 loops=2)
                                 Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                                 Rows Removed by Filter: 2340
                                 ->  Seq Scan on compress_hyper_6_32_chunk (actual rows=4 loops=2)
                                       Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                                       Rows Removed by Filter: 14
                           ->  Custom Scan (DecompressChunk) on _hyper_5_24_chunk o_6 (actual rows=720 loops=2)
                                 Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                                 Rows Removed by Filter: 780
                                 ->  Seq Scan on compress_hyper_6_31_chunk (actual rows=2 loops=2)
                                       Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                                       Rows Removed by Filter: 4
                     ->  Merge Append (actual rows=0 loops=2)
                           ->  Custom Scan (DecompressChunk) on _hyper_5_25_chunk o_7 (actual rows=0 loops=2)
                                 Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                                 ->  Seq Scan on compress_hyper_6_30_chunk (actual rows=0 loops=2)
                                       Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                                       Rows Removed by Filter: 6
                           ->  Custom Scan (DecompressChunk) on _hyper_5_26_chunk o_8 (actual rows=0 loops=2)
                                 Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                                 ->  Seq Scan on compress_hyper_6_29_chunk (actual rows=0 loops=2)
                                       Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                                       Rows Removed by Filter: 18
                           ->  Custom Scan (DecompressChunk) on _hyper_5_27_chunk o_9 (actual rows=0 loops=2)
                                 Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)))
                                 ->  Seq Scan on compress_hyper_6_28_chunk (actual rows=0 loops=2)
                                       Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                                       Rows Removed by Filter: 6
(58 rows)

-- test startup and runtime exclusion together
:PREFIX
SELECT g.time,
  l.time
FROM generate_series('2000-01-01'::timestamptz, '2000-01-03', '1d') AS g (time)
  LEFT OUTER JOIN LATERAL (
  SELECT *
  FROM :TEST_TABLE o
  WHERE o.time >= g.time
    AND o.time < g.time + '1d'::interval
    AND o.time < now()
  ORDER BY time DESC
  LIMIT 1) l ON TRUE;
                                                              QUERY PLAN                                                              
--------------------------------------------------------------------------------------------------------------------------------------
 Nested Loop Left Join (actual rows=3 loops=1)
   ->  Function Scan on generate_series g (actual rows=3 loops=1)
   ->  Limit (actual rows=1 loops=3)
         ->  Sort (actual rows=1 loops=3)
               Sort Key: o."time" DESC
               Sort Method: top-N heapsort 
               ->  Custom Scan (ChunkAppend) on metrics_space_compressed o (actual rows=3600 loops=3)
                     ->  Merge Append (actual rows=0 loops=3)
                           ->  Custom Scan (DecompressChunk) on _hyper_5_27_chunk o_1 (actual rows=0 loops=3)
                                 Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)) AND ("time" < now()))
                                 ->  Seq Scan on compress_hyper_6_28_chunk (actual rows=0 loops=3)
                                       Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                                       Rows Removed by Filter: 6
                           ->  Custom Scan (DecompressChunk) on _hyper_5_26_chunk o_2 (actual rows=0 loops=3)
                                 Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)) AND ("time" < now()))
                                 ->  Seq Scan on compress_hyper_6_29_chunk (actual rows=0 loops=3)
                                       Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                                       Rows Removed by Filter: 18
                           ->  Custom Scan (DecompressChunk) on _hyper_5_25_chunk o_3 (actual rows=0 loops=3)
                                 Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)) AND ("time" < now()))
                                 ->  Seq Scan on compress_hyper_6_30_chunk (actual rows=0 loops=3)
                                       Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                                       Rows Removed by Filter: 6
                     ->  Merge Append (actual rows=0 loops=3)
                           ->  Custom Scan (DecompressChunk) on _hyper_5_24_chunk o_4 (actual rows=0 loops=3)
                                 Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)) AND ("time" < now()))
                                 ->  Seq Scan on compress_hyper_6_31_chunk (actual rows=0 loops=3)
                                       Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                                       Rows Removed by Filter: 6
                           ->  Custom Scan (DecompressChunk) on _hyper_5_23_chunk o_5 (actual rows=0 loops=3)
                                 Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)) AND ("time" < now()))
                                 ->  Seq Scan on compress_hyper_6_32_chunk (actual rows=0 loops=3)
                                       Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                                       Rows Removed by Filter: 18
                           ->  Custom Scan (DecompressChunk) on _hyper_5_22_chunk o_6 (actual rows=0 loops=3)
                                 Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)) AND ("time" < now()))
                                 ->  Seq Scan on compress_hyper_6_33_chunk (actual rows=0 loops=3)
                                       Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                                       Rows Removed by Filter: 6
                     ->  Merge Append (actual rows=3600 loops=3)
                           ->  Custom Scan (DecompressChunk) on _hyper_5_21_chunk o_7 (actual rows=720 loops=3)
                                 Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)) AND ("time" < now()))
                                 Rows Removed by Filter: 813
                                 ->  Seq Scan on compress_hyper_6_34_chunk (actual rows=2 loops=3)
                                       Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                                       Rows Removed by Filter: 2
                           ->  Custom Scan (DecompressChunk) on _hyper_5_20_chunk o_8 (actual rows=2160 loops=3)
                                 Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)) AND ("time" < now()))
                                 Rows Removed by Filter: 2438
                                 ->  Seq Scan on compress_hyper_6_35_chunk (actual rows=5 loops=3)
                                       Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                                       Rows Removed by Filter: 7
                           ->  Custom Scan (DecompressChunk) on _hyper_5_19_chunk o_9 (actual rows=720 loops=3)
                                 Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)) AND ("time" < now()))
                                 Rows Removed by Filter: 813
                                 ->  Seq Scan on compress_hyper_6_36_chunk (actual rows=2 loops=3)
                                       Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                                       Rows Removed by Filter: 2
(58 rows)

-- test startup and runtime exclusion together
-- all chunks should be filtered
:PREFIX
SELECT g.time,
  l.time
FROM generate_series('2000-01-01'::timestamptz, '2000-01-03', '1d') AS g (time)
  LEFT OUTER JOIN LATERAL (
  SELECT *
  FROM :TEST_TABLE o
  WHERE o.time >= g.time
    AND o.time < g.time + '1d'::interval
    AND o.time > now()
  ORDER BY time DESC
  LIMIT 1) l ON TRUE;
                                                              QUERY PLAN                                                              
--------------------------------------------------------------------------------------------------------------------------------------
 Nested Loop Left Join (actual rows=3 loops=1)
   ->  Function Scan on generate_series g (actual rows=3 loops=1)
   ->  Limit (actual rows=0 loops=3)
         ->  Sort (actual rows=0 loops=3)
               Sort Key: o."time" DESC
               Sort Method: quicksort 
               ->  Custom Scan (ChunkAppend) on metrics_space_compressed o (actual rows=0 loops=3)
                     ->  Merge Append (actual rows=0 loops=3)
                           ->  Custom Scan (DecompressChunk) on _hyper_5_27_chunk o_1 (actual rows=0 loops=3)
                                 Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)) AND ("time" > now()))
                                 ->  Seq Scan on compress_hyper_6_28_chunk (actual rows=0 loops=3)
                                       Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                                       Rows Removed by Filter: 6
                           ->  Custom Scan (DecompressChunk) on _hyper_5_26_chunk o_2 (actual rows=0 loops=3)
                                 Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)) AND ("time" > now()))
                                 ->  Seq Scan on compress_hyper_6_29_chunk (actual rows=0 loops=3)
                                       Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                                       Rows Removed by Filter: 18
                           ->  Custom Scan (DecompressChunk) on _hyper_5_25_chunk o_3 (actual rows=0 loops=3)
                                 Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)) AND ("time" > now()))
                                 ->  Seq Scan on compress_hyper_6_30_chunk (actual rows=0 loops=3)
                                       Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                                       Rows Removed by Filter: 6
                     ->  Merge Append (actual rows=0 loops=3)
                           ->  Custom Scan (DecompressChunk) on _hyper_5_24_chunk o_4 (actual rows=0 loops=3)
                                 Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)) AND ("time" > now()))
                                 ->  Seq Scan on compress_hyper_6_31_chunk (actual rows=0 loops=3)
                                       Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                                       Rows Removed by Filter: 6
                           ->  Custom Scan (DecompressChunk) on _hyper_5_23_chunk o_5 (actual rows=0 loops=3)
                                 Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)) AND ("time" > now()))
                                 ->  Seq Scan on compress_hyper_6_32_chunk (actual rows=0 loops=3)
                                       Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                                       Rows Removed by Filter: 18
                           ->  Custom Scan (DecompressChunk) on _hyper_5_22_chunk o_6 (actual rows=0 loops=3)
                                 Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)) AND ("time" > now()))
                                 ->  Seq Scan on compress_hyper_6_33_chunk (actual rows=0 loops=3)
                                       Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                                       Rows Removed by Filter: 6
                     ->  Merge Append (actual rows=0 loops=3)
                           ->  Custom Scan (DecompressChunk) on _hyper_5_21_chunk o_7 (actual rows=0 loops=3)
                                 Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)) AND ("time" > now()))
                                 Rows Removed by Filter: 1533
                                 ->  Seq Scan on compress_hyper_6_34_chunk (actual rows=2 loops=3)
                                       Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                                       Rows Removed by Filter: 2
                           ->  Custom Scan (DecompressChunk) on _hyper_5_20_chunk o_8 (actual rows=0 loops=3)
                                 Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)) AND ("time" > now()))
                                 Rows Removed by Filter: 4598
                                 ->  Seq Scan on compress_hyper_6_35_chunk (actual rows=5 loops=3)
                                       Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                                       Rows Removed by Filter: 7
                           ->  Custom Scan (DecompressChunk) on _hyper_5_19_chunk o_9 (actual rows=0 loops=3)
                                 Filter: (("time" >= g."time") AND ("time" < (g."time" + '@ 1 day'::interval)) AND ("time" > now()))
                                 Rows Removed by Filter: 1533
                                 ->  Seq Scan on compress_hyper_6_36_chunk (actual rows=2 loops=3)
                                       Filter: ((_ts_meta_max_1 >= g."time") AND (_ts_meta_min_1 < (g."time" + '@ 1 day'::interval)))
                                       Rows Removed by Filter: 2
(58 rows)

-- test JOIN
-- no exclusion on joined table because quals are not propagated yet
:PREFIX
SELECT o1.time,
  o2.time
FROM :TEST_TABLE o1
  INNER JOIN :TEST_TABLE o2 ON o1.time = o2.time
WHERE o1.time < '2000-02-01'
  AND o1.device_id = 1
  AND o2.device_id = 2
ORDER BY o1.time;
                                                                               QUERY PLAN                                                                               
------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Merge Join (actual rows=13674 loops=1)
   Merge Cond: (o1."time" = o2."time")
   ->  Custom Scan (ChunkAppend) on metrics_space_compressed o1 (actual rows=13674 loops=1)
         Order: o1."time"
         ->  Custom Scan (DecompressChunk) on _hyper_5_19_chunk o1_1 (actual rows=3598 loops=1)
               Filter: ("time" < 'Tue Feb 01 00:00:00 2000 PST'::timestamp with time zone)
               ->  Index Scan Backward using compress_hyper_6_36_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_36_chunk (actual rows=4 loops=1)
                     Index Cond: (device_id = 1)
                     Filter: (_ts_meta_min_1 < 'Tue Feb 01 00:00:00 2000 PST'::timestamp with time zone)
         ->  Custom Scan (DecompressChunk) on _hyper_5_22_chunk o1_2 (actual rows=5038 loops=1)
               Filter: ("time" < 'Tue Feb 01 00:00:00 2000 PST'::timestamp with time zone)
               ->  Index Scan Backward using compress_hyper_6_33_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_33_chunk (actual rows=6 loops=1)
                     Index Cond: (device_id = 1)
                     Filter: (_ts_meta_min_1 < 'Tue Feb 01 00:00:00 2000 PST'::timestamp with time zone)
         ->  Custom Scan (DecompressChunk) on _hyper_5_25_chunk o1_3 (actual rows=5038 loops=1)
               Filter: ("time" < 'Tue Feb 01 00:00:00 2000 PST'::timestamp with time zone)
               ->  Index Scan Backward using compress_hyper_6_30_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_30_chunk (actual rows=6 loops=1)
                     Index Cond: (device_id = 1)
                     Filter: (_ts_meta_min_1 < 'Tue Feb 01 00:00:00 2000 PST'::timestamp with time zone)
   ->  Materialize (actual rows=13674 loops=1)
         ->  Custom Scan (ChunkAppend) on metrics_space_compressed o2 (actual rows=13674 loops=1)
               Order: o2."time"
               ->  Custom Scan (DecompressChunk) on _hyper_5_20_chunk o2_1 (actual rows=3598 loops=1)
                     Filter: ("time" < 'Tue Feb 01 00:00:00 2000 PST'::timestamp with time zone)
                     ->  Index Scan Backward using compress_hyper_6_35_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_35_chunk (actual rows=4 loops=1)
                           Index Cond: (device_id = 2)
                           Filter: (_ts_meta_min_1 < 'Tue Feb 01 00:00:00 2000 PST'::timestamp with time zone)
               ->  Custom Scan (DecompressChunk) on _hyper_5_23_chunk o2_2 (actual rows=5038 loops=1)
                     Filter: ("time" < 'Tue Feb 01 00:00:00 2000 PST'::timestamp with time zone)
                     ->  Index Scan Backward using compress_hyper_6_32_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_32_chunk (actual rows=6 loops=1)
                           Index Cond: (device_id = 2)
                           Filter: (_ts_meta_min_1 < 'Tue Feb 01 00:00:00 2000 PST'::timestamp with time zone)
               ->  Custom Scan (DecompressChunk) on _hyper_5_26_chunk o2_3 (actual rows=5038 loops=1)
                     Filter: ("time" < 'Tue Feb 01 00:00:00 2000 PST'::timestamp with time zone)
                     ->  Index Scan Backward using compress_hyper_6_29_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_29_chunk (actual rows=6 loops=1)
                           Index Cond: (device_id = 2)
                           Filter: (_ts_meta_min_1 < 'Tue Feb 01 00:00:00 2000 PST'::timestamp with time zone)
(37 rows)

-- test JOIN
-- last chunk of o2 should not be executed
:PREFIX
SELECT o1.time,
  o2.time
FROM :TEST_TABLE o1
  INNER JOIN (
    SELECT *
    FROM :TEST_TABLE o2
    ORDER BY time) o2 ON o1.time = o2.time
WHERE o1.time < '2000-01-08'
ORDER BY o1.time
LIMIT 10;
                                                              QUERY PLAN                                                              
--------------------------------------------------------------------------------------------------------------------------------------
 Limit (actual rows=10 loops=1)
   ->  Merge Join (actual rows=10 loops=1)
         Merge Cond: (o1."time" = o2."time")
         ->  Sort (actual rows=2 loops=1)
               Sort Key: o1."time"
               Sort Method: quicksort 
               ->  Append (actual rows=26390 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_5_19_chunk o1 (actual rows=3598 loops=1)
                           Filter: ("time" < 'Sat Jan 08 00:00:00 2000 PST'::timestamp with time zone)
                           ->  Seq Scan on compress_hyper_6_36_chunk (actual rows=4 loops=1)
                                 Filter: (_ts_meta_min_1 < 'Sat Jan 08 00:00:00 2000 PST'::timestamp with time zone)
                     ->  Custom Scan (DecompressChunk) on _hyper_5_20_chunk o1_1 (actual rows=10794 loops=1)
                           Filter: ("time" < 'Sat Jan 08 00:00:00 2000 PST'::timestamp with time zone)
                           ->  Seq Scan on compress_hyper_6_35_chunk (actual rows=12 loops=1)
                                 Filter: (_ts_meta_min_1 < 'Sat Jan 08 00:00:00 2000 PST'::timestamp with time zone)
                     ->  Custom Scan (DecompressChunk) on _hyper_5_21_chunk o1_2 (actual rows=3598 loops=1)
                           Filter: ("time" < 'Sat Jan 08 00:00:00 2000 PST'::timestamp with time zone)
                           ->  Seq Scan on compress_hyper_6_34_chunk (actual rows=4 loops=1)
                                 Filter: (_ts_meta_min_1 < 'Sat Jan 08 00:00:00 2000 PST'::timestamp with time zone)
                     ->  Custom Scan (DecompressChunk) on _hyper_5_22_chunk o1_3 (actual rows=1680 loops=1)
                           Filter: ("time" < 'Sat Jan 08 00:00:00 2000 PST'::timestamp with time zone)
                           Rows Removed by Filter: 358
                           ->  Seq Scan on compress_hyper_6_33_chunk (actual rows=3 loops=1)
                                 Filter: (_ts_meta_min_1 < 'Sat Jan 08 00:00:00 2000 PST'::timestamp with time zone)
                                 Rows Removed by Filter: 3
                     ->  Custom Scan (DecompressChunk) on _hyper_5_23_chunk o1_4 (actual rows=5040 loops=1)
                           Filter: ("time" < 'Sat Jan 08 00:00:00 2000 PST'::timestamp with time zone)
                           Rows Removed by Filter: 1074
                           ->  Seq Scan on compress_hyper_6_32_chunk (actual rows=9 loops=1)
                                 Filter: (_ts_meta_min_1 < 'Sat Jan 08 00:00:00 2000 PST'::timestamp with time zone)
                                 Rows Removed by Filter: 9
                     ->  Custom Scan (DecompressChunk) on _hyper_5_24_chunk o1_5 (actual rows=1680 loops=1)
                           Filter: ("time" < 'Sat Jan 08 00:00:00 2000 PST'::timestamp with time zone)
                           Rows Removed by Filter: 358
                           ->  Seq Scan on compress_hyper_6_31_chunk (actual rows=3 loops=1)
                                 Filter: (_ts_meta_min_1 < 'Sat Jan 08 00:00:00 2000 PST'::timestamp with time zone)
                                 Rows Removed by Filter: 3
         ->  Materialize (actual rows=10 loops=1)
               ->  Sort (actual rows=6 loops=1)
                     Sort Key: o2."time"
                     Sort Method: quicksort 
                     ->  Result (actual rows=68370 loops=1)
                           ->  Append (actual rows=68370 loops=1)
                                 ->  Custom Scan (DecompressChunk) on _hyper_5_19_chunk o2 (actual rows=3598 loops=1)
                                       ->  Seq Scan on compress_hyper_6_36_chunk compress_hyper_6_36_chunk_1 (actual rows=4 loops=1)
                                 ->  Custom Scan (DecompressChunk) on _hyper_5_20_chunk o2_1 (actual rows=10794 loops=1)
                                       ->  Seq Scan on compress_hyper_6_35_chunk compress_hyper_6_35_chunk_1 (actual rows=12 loops=1)
                                 ->  Custom Scan (DecompressChunk) on _hyper_5_21_chunk o2_2 (actual rows=3598 loops=1)
                                       ->  Seq Scan on compress_hyper_6_34_chunk compress_hyper_6_34_chunk_1 (actual rows=4 loops=1)
                                 ->  Custom Scan (DecompressChunk) on _hyper_5_22_chunk o2_3 (actual rows=5038 loops=1)
                                       ->  Seq Scan on compress_hyper_6_33_chunk compress_hyper_6_33_chunk_1 (actual rows=6 loops=1)
                                 ->  Custom Scan (DecompressChunk) on _hyper_5_23_chunk o2_4 (actual rows=15114 loops=1)
                                       ->  Seq Scan on compress_hyper_6_32_chunk compress_hyper_6_32_chunk_1 (actual rows=18 loops=1)
                                 ->  Custom Scan (DecompressChunk) on _hyper_5_24_chunk o2_5 (actual rows=5038 loops=1)
                                       ->  Seq Scan on compress_hyper_6_31_chunk compress_hyper_6_31_chunk_1 (actual rows=6 loops=1)
                                 ->  Custom Scan (DecompressChunk) on _hyper_5_25_chunk o2_6 (actual rows=5038 loops=1)
                                       ->  Seq Scan on compress_hyper_6_30_chunk (actual rows=6 loops=1)
                                 ->  Custom Scan (DecompressChunk) on _hyper_5_26_chunk o2_7 (actual rows=15114 loops=1)
                                       ->  Seq Scan on compress_hyper_6_29_chunk (actual rows=18 loops=1)
                                 ->  Custom Scan (DecompressChunk) on _hyper_5_27_chunk o2_8 (actual rows=5038 loops=1)
                                       ->  Seq Scan on compress_hyper_6_28_chunk (actual rows=6 loops=1)
(61 rows)

-- test join against max query
-- not ChunkAppend so no chunk exclusion
SET enable_hashjoin = FALSE;
:PREFIX
SELECT o1.time,
  o2.*
FROM :TEST_TABLE o1
  INNER JOIN (
    SELECT max(time) AS max_time
    FROM :TEST_TABLE) o2 ON o1.time = o2.max_time
WHERE o1.device_id = 1
ORDER BY time;
                                                                            QUERY PLAN                                                                            
------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Merge Join (actual rows=1 loops=1)
   Merge Cond: (o1."time" = (max(_hyper_5_19_chunk."time")))
   ->  Custom Scan (ChunkAppend) on metrics_space_compressed o1 (actual rows=13674 loops=1)
         Order: o1."time"
         ->  Custom Scan (DecompressChunk) on _hyper_5_19_chunk o1_1 (actual rows=3598 loops=1)
               ->  Index Scan Backward using compress_hyper_6_36_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_36_chunk (actual rows=4 loops=1)
                     Index Cond: (device_id = 1)
         ->  Custom Scan (DecompressChunk) on _hyper_5_22_chunk o1_2 (actual rows=5038 loops=1)
               ->  Index Scan Backward using compress_hyper_6_33_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_33_chunk (actual rows=6 loops=1)
                     Index Cond: (device_id = 1)
         ->  Custom Scan (DecompressChunk) on _hyper_5_25_chunk o1_3 (actual rows=5038 loops=1)
               ->  Index Scan Backward using compress_hyper_6_30_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_30_chunk (actual rows=6 loops=1)
                     Index Cond: (device_id = 1)
   ->  Sort (actual rows=1 loops=1)
         Sort Key: (max(_hyper_5_19_chunk."time"))
         Sort Method: quicksort 
         ->  Aggregate (actual rows=1 loops=1)
               ->  Append (actual rows=68370 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_5_19_chunk (actual rows=3598 loops=1)
                           ->  Seq Scan on compress_hyper_6_36_chunk compress_hyper_6_36_chunk_1 (actual rows=4 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_5_20_chunk (actual rows=10794 loops=1)
                           ->  Seq Scan on compress_hyper_6_35_chunk (actual rows=12 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_5_21_chunk (actual rows=3598 loops=1)
                           ->  Seq Scan on compress_hyper_6_34_chunk (actual rows=4 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_5_22_chunk (actual rows=5038 loops=1)
                           ->  Seq Scan on compress_hyper_6_33_chunk compress_hyper_6_33_chunk_1 (actual rows=6 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_5_23_chunk (actual rows=15114 loops=1)
                           ->  Seq Scan on compress_hyper_6_32_chunk (actual rows=18 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_5_24_chunk (actual rows=5038 loops=1)
                           ->  Seq Scan on compress_hyper_6_31_chunk (actual rows=6 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_5_25_chunk (actual rows=5038 loops=1)
                           ->  Seq Scan on compress_hyper_6_30_chunk compress_hyper_6_30_chunk_1 (actual rows=6 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_5_26_chunk (actual rows=15114 loops=1)
                           ->  Seq Scan on compress_hyper_6_29_chunk (actual rows=18 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_5_27_chunk (actual rows=5038 loops=1)
                           ->  Seq Scan on compress_hyper_6_28_chunk (actual rows=6 loops=1)
(36 rows)

RESET enable_hashjoin;
SET enable_seqscan TO false;
-- test JOIN on time column
-- should use 2 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  INNER JOIN :TEST_TABLE o2 ON o1.time = o2.time
WHERE o1.device_id = 1
  AND o2.device_id = 2
ORDER BY o1.time
LIMIT 100;
                                                                                  QUERY PLAN                                                                                  
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit (actual rows=100 loops=1)
   ->  Merge Join (actual rows=100 loops=1)
         Merge Cond: (o1."time" = o2."time")
         ->  Custom Scan (ChunkAppend) on metrics_space_compressed o1 (actual rows=100 loops=1)
               Order: o1."time"
               ->  Custom Scan (DecompressChunk) on _hyper_5_19_chunk o1_1 (actual rows=100 loops=1)
                     ->  Index Scan Backward using compress_hyper_6_36_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_36_chunk (actual rows=1 loops=1)
                           Index Cond: (device_id = 1)
               ->  Custom Scan (DecompressChunk) on _hyper_5_22_chunk o1_2 (never executed)
                     ->  Index Scan Backward using compress_hyper_6_33_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_33_chunk (never executed)
                           Index Cond: (device_id = 1)
               ->  Custom Scan (DecompressChunk) on _hyper_5_25_chunk o1_3 (never executed)
                     ->  Index Scan Backward using compress_hyper_6_30_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_30_chunk (never executed)
                           Index Cond: (device_id = 1)
         ->  Materialize (actual rows=100 loops=1)
               ->  Custom Scan (ChunkAppend) on metrics_space_compressed o2 (actual rows=100 loops=1)
                     Order: o2."time"
                     ->  Custom Scan (DecompressChunk) on _hyper_5_20_chunk o2_1 (actual rows=100 loops=1)
                           ->  Index Scan Backward using compress_hyper_6_35_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_35_chunk (actual rows=1 loops=1)
                                 Index Cond: (device_id = 2)
                     ->  Custom Scan (DecompressChunk) on _hyper_5_23_chunk o2_2 (never executed)
                           ->  Index Scan Backward using compress_hyper_6_32_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_32_chunk (never executed)
                                 Index Cond: (device_id = 2)
                     ->  Custom Scan (DecompressChunk) on _hyper_5_26_chunk o2_3 (never executed)
                           ->  Index Scan Backward using compress_hyper_6_29_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_29_chunk (never executed)
                                 Index Cond: (device_id = 2)
(26 rows)

-- test JOIN on time column with USING
-- should use 2 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  INNER JOIN :TEST_TABLE o2 USING (time)
WHERE o1.device_id = 1
  AND o2.device_id = 2
ORDER BY o1.time
LIMIT 100;
                                                                                  QUERY PLAN                                                                                  
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit (actual rows=100 loops=1)
   ->  Merge Join (actual rows=100 loops=1)
         Merge Cond: (o1."time" = o2."time")
         ->  Custom Scan (ChunkAppend) on metrics_space_compressed o1 (actual rows=100 loops=1)
               Order: o1."time"
               ->  Custom Scan (DecompressChunk) on _hyper_5_19_chunk o1_1 (actual rows=100 loops=1)
                     ->  Index Scan Backward using compress_hyper_6_36_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_36_chunk (actual rows=1 loops=1)
                           Index Cond: (device_id = 1)
               ->  Custom Scan (DecompressChunk) on _hyper_5_22_chunk o1_2 (never executed)
                     ->  Index Scan Backward using compress_hyper_6_33_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_33_chunk (never executed)
                           Index Cond: (device_id = 1)
               ->  Custom Scan (DecompressChunk) on _hyper_5_25_chunk o1_3 (never executed)
                     ->  Index Scan Backward using compress_hyper_6_30_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_30_chunk (never executed)
                           Index Cond: (device_id = 1)
         ->  Materialize (actual rows=100 loops=1)
               ->  Custom Scan (ChunkAppend) on metrics_space_compressed o2 (actual rows=100 loops=1)
                     Order: o2."time"
                     ->  Custom Scan (DecompressChunk) on _hyper_5_20_chunk o2_1 (actual rows=100 loops=1)
                           ->  Index Scan Backward using compress_hyper_6_35_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_35_chunk (actual rows=1 loops=1)
                                 Index Cond: (device_id = 2)
                     ->  Custom Scan (DecompressChunk) on _hyper_5_23_chunk o2_2 (never executed)
                           ->  Index Scan Backward using compress_hyper_6_32_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_32_chunk (never executed)
                                 Index Cond: (device_id = 2)
                     ->  Custom Scan (DecompressChunk) on _hyper_5_26_chunk o2_3 (never executed)
                           ->  Index Scan Backward using compress_hyper_6_29_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_29_chunk (never executed)
                                 Index Cond: (device_id = 2)
(26 rows)

-- test NATURAL JOIN on time column
-- should use 2 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  NATURAL INNER JOIN :TEST_TABLE o2
WHERE o1.device_id = 1
  AND o2.device_id = 2
ORDER BY o1.time
LIMIT 100;
                  QUERY PLAN                  
----------------------------------------------
 Limit (actual rows=0 loops=1)
   ->  Sort (actual rows=0 loops=1)
         Sort Key: o1."time"
         Sort Method: quicksort 
         ->  Result (actual rows=0 loops=1)
               One-Time Filter: false
(6 rows)

-- test LEFT JOIN on time column
-- should use 2 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  LEFT JOIN :TEST_TABLE o2 ON o1.time = o2.time
WHERE o1.device_id = 1
  AND o2.device_id = 2
ORDER BY o1.time
LIMIT 100;
                                                                                  QUERY PLAN                                                                                  
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit (actual rows=100 loops=1)
   ->  Merge Join (actual rows=100 loops=1)
         Merge Cond: (o1."time" = o2."time")
         ->  Custom Scan (ChunkAppend) on metrics_space_compressed o1 (actual rows=100 loops=1)
               Order: o1."time"
               ->  Custom Scan (DecompressChunk) on _hyper_5_19_chunk o1_1 (actual rows=100 loops=1)
                     ->  Index Scan Backward using compress_hyper_6_36_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_36_chunk (actual rows=1 loops=1)
                           Index Cond: (device_id = 1)
               ->  Custom Scan (DecompressChunk) on _hyper_5_22_chunk o1_2 (never executed)
                     ->  Index Scan Backward using compress_hyper_6_33_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_33_chunk (never executed)
                           Index Cond: (device_id = 1)
               ->  Custom Scan (DecompressChunk) on _hyper_5_25_chunk o1_3 (never executed)
                     ->  Index Scan Backward using compress_hyper_6_30_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_30_chunk (never executed)
                           Index Cond: (device_id = 1)
         ->  Materialize (actual rows=100 loops=1)
               ->  Custom Scan (ChunkAppend) on metrics_space_compressed o2 (actual rows=100 loops=1)
                     Order: o2."time"
                     ->  Custom Scan (DecompressChunk) on _hyper_5_20_chunk o2_1 (actual rows=100 loops=1)
                           ->  Index Scan Backward using compress_hyper_6_35_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_35_chunk (actual rows=1 loops=1)
                                 Index Cond: (device_id = 2)
                     ->  Custom Scan (DecompressChunk) on _hyper_5_23_chunk o2_2 (never executed)
                           ->  Index Scan Backward using compress_hyper_6_32_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_32_chunk (never executed)
                                 Index Cond: (device_id = 2)
                     ->  Custom Scan (DecompressChunk) on _hyper_5_26_chunk o2_3 (never executed)
                           ->  Index Scan Backward using compress_hyper_6_29_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_29_chunk (never executed)
                                 Index Cond: (device_id = 2)
(26 rows)

-- test RIGHT JOIN on time column
-- should use 2 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  RIGHT JOIN :TEST_TABLE o2 ON o1.time = o2.time
WHERE o1.device_id = 1
  AND o2.device_id = 2
ORDER BY o2.time
LIMIT 100;
                                                                                  QUERY PLAN                                                                                  
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit (actual rows=100 loops=1)
   ->  Merge Join (actual rows=100 loops=1)
         Merge Cond: (o1."time" = o2."time")
         ->  Custom Scan (ChunkAppend) on metrics_space_compressed o1 (actual rows=100 loops=1)
               Order: o1."time"
               ->  Custom Scan (DecompressChunk) on _hyper_5_19_chunk o1_1 (actual rows=100 loops=1)
                     ->  Index Scan Backward using compress_hyper_6_36_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_36_chunk (actual rows=1 loops=1)
                           Index Cond: (device_id = 1)
               ->  Custom Scan (DecompressChunk) on _hyper_5_22_chunk o1_2 (never executed)
                     ->  Index Scan Backward using compress_hyper_6_33_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_33_chunk (never executed)
                           Index Cond: (device_id = 1)
               ->  Custom Scan (DecompressChunk) on _hyper_5_25_chunk o1_3 (never executed)
                     ->  Index Scan Backward using compress_hyper_6_30_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_30_chunk (never executed)
                           Index Cond: (device_id = 1)
         ->  Materialize (actual rows=100 loops=1)
               ->  Custom Scan (ChunkAppend) on metrics_space_compressed o2 (actual rows=100 loops=1)
                     Order: o2."time"
                     ->  Custom Scan (DecompressChunk) on _hyper_5_20_chunk o2_1 (actual rows=100 loops=1)
                           ->  Index Scan Backward using compress_hyper_6_35_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_35_chunk (actual rows=1 loops=1)
                                 Index Cond: (device_id = 2)
                     ->  Custom Scan (DecompressChunk) on _hyper_5_23_chunk o2_2 (never executed)
                           ->  Index Scan Backward using compress_hyper_6_32_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_32_chunk (never executed)
                                 Index Cond: (device_id = 2)
                     ->  Custom Scan (DecompressChunk) on _hyper_5_26_chunk o2_3 (never executed)
                           ->  Index Scan Backward using compress_hyper_6_29_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_29_chunk (never executed)
                                 Index Cond: (device_id = 2)
(26 rows)

-- test JOIN on time column with ON clause expression order switched
-- should use 2 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  INNER JOIN :TEST_TABLE o2 ON o2.time = o1.time
WHERE o1.device_id = 1
  AND o2.device_id = 2
ORDER BY o1.time
LIMIT 100;
                                                                                  QUERY PLAN                                                                                  
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit (actual rows=100 loops=1)
   ->  Merge Join (actual rows=100 loops=1)
         Merge Cond: (o1."time" = o2."time")
         ->  Custom Scan (ChunkAppend) on metrics_space_compressed o1 (actual rows=100 loops=1)
               Order: o1."time"
               ->  Custom Scan (DecompressChunk) on _hyper_5_19_chunk o1_1 (actual rows=100 loops=1)
                     ->  Index Scan Backward using compress_hyper_6_36_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_36_chunk (actual rows=1 loops=1)
                           Index Cond: (device_id = 1)
               ->  Custom Scan (DecompressChunk) on _hyper_5_22_chunk o1_2 (never executed)
                     ->  Index Scan Backward using compress_hyper_6_33_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_33_chunk (never executed)
                           Index Cond: (device_id = 1)
               ->  Custom Scan (DecompressChunk) on _hyper_5_25_chunk o1_3 (never executed)
                     ->  Index Scan Backward using compress_hyper_6_30_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_30_chunk (never executed)
                           Index Cond: (device_id = 1)
         ->  Materialize (actual rows=100 loops=1)
               ->  Custom Scan (ChunkAppend) on metrics_space_compressed o2 (actual rows=100 loops=1)
                     Order: o2."time"
                     ->  Custom Scan (DecompressChunk) on _hyper_5_20_chunk o2_1 (actual rows=100 loops=1)
                           ->  Index Scan Backward using compress_hyper_6_35_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_35_chunk (actual rows=1 loops=1)
                                 Index Cond: (device_id = 2)
                     ->  Custom Scan (DecompressChunk) on _hyper_5_23_chunk o2_2 (never executed)
                           ->  Index Scan Backward using compress_hyper_6_32_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_32_chunk (never executed)
                                 Index Cond: (device_id = 2)
                     ->  Custom Scan (DecompressChunk) on _hyper_5_26_chunk o2_3 (never executed)
                           ->  Index Scan Backward using compress_hyper_6_29_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_29_chunk (never executed)
                                 Index Cond: (device_id = 2)
(26 rows)

-- test JOIN on time column with equality condition in WHERE clause
-- should use 2 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  INNER JOIN :TEST_TABLE o2 ON TRUE
WHERE o1.time = o2.time
  AND o1.device_id = 1
  AND o2.device_id = 2
ORDER BY o1.time
LIMIT 100;
                                                                                  QUERY PLAN                                                                                  
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit (actual rows=100 loops=1)
   ->  Merge Join (actual rows=100 loops=1)
         Merge Cond: (o1."time" = o2."time")
         ->  Custom Scan (ChunkAppend) on metrics_space_compressed o1 (actual rows=100 loops=1)
               Order: o1."time"
               ->  Custom Scan (DecompressChunk) on _hyper_5_19_chunk o1_1 (actual rows=100 loops=1)
                     ->  Index Scan Backward using compress_hyper_6_36_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_36_chunk (actual rows=1 loops=1)
                           Index Cond: (device_id = 1)
               ->  Custom Scan (DecompressChunk) on _hyper_5_22_chunk o1_2 (never executed)
                     ->  Index Scan Backward using compress_hyper_6_33_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_33_chunk (never executed)
                           Index Cond: (device_id = 1)
               ->  Custom Scan (DecompressChunk) on _hyper_5_25_chunk o1_3 (never executed)
                     ->  Index Scan Backward using compress_hyper_6_30_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_30_chunk (never executed)
                           Index Cond: (device_id = 1)
         ->  Materialize (actual rows=100 loops=1)
               ->  Custom Scan (ChunkAppend) on metrics_space_compressed o2 (actual rows=100 loops=1)
                     Order: o2."time"
                     ->  Custom Scan (DecompressChunk) on _hyper_5_20_chunk o2_1 (actual rows=100 loops=1)
                           ->  Index Scan Backward using compress_hyper_6_35_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_35_chunk (actual rows=1 loops=1)
                                 Index Cond: (device_id = 2)
                     ->  Custom Scan (DecompressChunk) on _hyper_5_23_chunk o2_2 (never executed)
                           ->  Index Scan Backward using compress_hyper_6_32_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_32_chunk (never executed)
                                 Index Cond: (device_id = 2)
                     ->  Custom Scan (DecompressChunk) on _hyper_5_26_chunk o2_3 (never executed)
                           ->  Index Scan Backward using compress_hyper_6_29_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_29_chunk (never executed)
                                 Index Cond: (device_id = 2)
(26 rows)

-- test JOIN on time column with ORDER BY 2nd hypertable
-- should use 2 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  INNER JOIN :TEST_TABLE o2 ON o1.time = o2.time
WHERE o1.device_id = 1
  AND o2.device_id = 2
ORDER BY o2.time
LIMIT 100;
                                                                                  QUERY PLAN                                                                                  
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit (actual rows=100 loops=1)
   ->  Merge Join (actual rows=100 loops=1)
         Merge Cond: (o1."time" = o2."time")
         ->  Custom Scan (ChunkAppend) on metrics_space_compressed o1 (actual rows=100 loops=1)
               Order: o1."time"
               ->  Custom Scan (DecompressChunk) on _hyper_5_19_chunk o1_1 (actual rows=100 loops=1)
                     ->  Index Scan Backward using compress_hyper_6_36_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_36_chunk (actual rows=1 loops=1)
                           Index Cond: (device_id = 1)
               ->  Custom Scan (DecompressChunk) on _hyper_5_22_chunk o1_2 (never executed)
                     ->  Index Scan Backward using compress_hyper_6_33_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_33_chunk (never executed)
                           Index Cond: (device_id = 1)
               ->  Custom Scan (DecompressChunk) on _hyper_5_25_chunk o1_3 (never executed)
                     ->  Index Scan Backward using compress_hyper_6_30_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_30_chunk (never executed)
                           Index Cond: (device_id = 1)
         ->  Materialize (actual rows=100 loops=1)
               ->  Custom Scan (ChunkAppend) on metrics_space_compressed o2 (actual rows=100 loops=1)
                     Order: o2."time"
                     ->  Custom Scan (DecompressChunk) on _hyper_5_20_chunk o2_1 (actual rows=100 loops=1)
                           ->  Index Scan Backward using compress_hyper_6_35_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_35_chunk (actual rows=1 loops=1)
                                 Index Cond: (device_id = 2)
                     ->  Custom Scan (DecompressChunk) on _hyper_5_23_chunk o2_2 (never executed)
                           ->  Index Scan Backward using compress_hyper_6_32_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_32_chunk (never executed)
                                 Index Cond: (device_id = 2)
                     ->  Custom Scan (DecompressChunk) on _hyper_5_26_chunk o2_3 (never executed)
                           ->  Index Scan Backward using compress_hyper_6_29_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_29_chunk (never executed)
                                 Index Cond: (device_id = 2)
(26 rows)

-- test JOIN on time column and device_id
-- should use 2 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  INNER JOIN :TEST_TABLE o2 ON o1.device_id = o2.device_id
    AND o1.time = o2.time
  ORDER BY o1.time
  LIMIT 100;
                                                                                               QUERY PLAN                                                                                               
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit (actual rows=100 loops=1)
   ->  Sort (actual rows=100 loops=1)
         Sort Key: o1."time"
         Sort Method: top-N heapsort 
         ->  Hash Join (actual rows=68370 loops=1)
               Hash Cond: ((o1.device_id = o2.device_id) AND (o1."time" = o2."time"))
               ->  Append (actual rows=68370 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_5_19_chunk o1 (actual rows=3598 loops=1)
                           ->  Index Scan using compress_hyper_6_36_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_36_chunk (actual rows=4 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_5_20_chunk o1_1 (actual rows=10794 loops=1)
                           ->  Index Scan using compress_hyper_6_35_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_35_chunk (actual rows=12 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_5_21_chunk o1_2 (actual rows=3598 loops=1)
                           ->  Index Scan using compress_hyper_6_34_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_34_chunk (actual rows=4 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_5_22_chunk o1_3 (actual rows=5038 loops=1)
                           ->  Index Scan using compress_hyper_6_33_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_33_chunk (actual rows=6 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_5_23_chunk o1_4 (actual rows=15114 loops=1)
                           ->  Index Scan using compress_hyper_6_32_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_32_chunk (actual rows=18 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_5_24_chunk o1_5 (actual rows=5038 loops=1)
                           ->  Index Scan using compress_hyper_6_31_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_31_chunk (actual rows=6 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_5_25_chunk o1_6 (actual rows=5038 loops=1)
                           ->  Index Scan using compress_hyper_6_30_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_30_chunk (actual rows=6 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_5_26_chunk o1_7 (actual rows=15114 loops=1)
                           ->  Index Scan using compress_hyper_6_29_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_29_chunk (actual rows=18 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_5_27_chunk o1_8 (actual rows=5038 loops=1)
                           ->  Index Scan using compress_hyper_6_28_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_28_chunk (actual rows=6 loops=1)
               ->  Hash (actual rows=68370 loops=1)
                     Buckets: 131072  Batches: 1 
                     ->  Append (actual rows=68370 loops=1)
                           ->  Custom Scan (DecompressChunk) on _hyper_5_19_chunk o2 (actual rows=3598 loops=1)
                                 ->  Index Scan using compress_hyper_6_36_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_36_chunk compress_hyper_6_36_chunk_1 (actual rows=4 loops=1)
                           ->  Custom Scan (DecompressChunk) on _hyper_5_20_chunk o2_1 (actual rows=10794 loops=1)
                                 ->  Index Scan using compress_hyper_6_35_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_35_chunk compress_hyper_6_35_chunk_1 (actual rows=12 loops=1)
                           ->  Custom Scan (DecompressChunk) on _hyper_5_21_chunk o2_2 (actual rows=3598 loops=1)
                                 ->  Index Scan using compress_hyper_6_34_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_34_chunk compress_hyper_6_34_chunk_1 (actual rows=4 loops=1)
                           ->  Custom Scan (DecompressChunk) on _hyper_5_22_chunk o2_3 (actual rows=5038 loops=1)
                                 ->  Index Scan using compress_hyper_6_33_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_33_chunk compress_hyper_6_33_chunk_1 (actual rows=6 loops=1)
                           ->  Custom Scan (DecompressChunk) on _hyper_5_23_chunk o2_4 (actual rows=15114 loops=1)
                                 ->  Index Scan using compress_hyper_6_32_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_32_chunk compress_hyper_6_32_chunk_1 (actual rows=18 loops=1)
                           ->  Custom Scan (DecompressChunk) on _hyper_5_24_chunk o2_5 (actual rows=5038 loops=1)
                                 ->  Index Scan using compress_hyper_6_31_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_31_chunk compress_hyper_6_31_chunk_1 (actual rows=6 loops=1)
                           ->  Custom Scan (DecompressChunk) on _hyper_5_25_chunk o2_6 (actual rows=5038 loops=1)
                                 ->  Index Scan using compress_hyper_6_30_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_30_chunk compress_hyper_6_30_chunk_1 (actual rows=6 loops=1)
                           ->  Custom Scan (DecompressChunk) on _hyper_5_26_chunk o2_7 (actual rows=15114 loops=1)
                                 ->  Index Scan using compress_hyper_6_29_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_29_chunk compress_hyper_6_29_chunk_1 (actual rows=18 loops=1)
                           ->  Custom Scan (DecompressChunk) on _hyper_5_27_chunk o2_8 (actual rows=5038 loops=1)
                                 ->  Index Scan using compress_hyper_6_28_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_28_chunk compress_hyper_6_28_chunk_1 (actual rows=6 loops=1)
(46 rows)

-- test JOIN on device_id
-- should not use ordered append for 2nd hypertable
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  INNER JOIN :TEST_TABLE o2 ON o1.device_id = o2.device_id
WHERE o1.device_id = 1
ORDER BY o1.time
LIMIT 100;
                                                                                           QUERY PLAN                                                                                            
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit (actual rows=100 loops=1)
   ->  Nested Loop (actual rows=100 loops=1)
         ->  Custom Scan (ChunkAppend) on metrics_space_compressed o1 (actual rows=1 loops=1)
               Order: o1."time"
               ->  Custom Scan (DecompressChunk) on _hyper_5_19_chunk o1_1 (actual rows=1 loops=1)
                     ->  Index Scan Backward using compress_hyper_6_36_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_36_chunk (actual rows=1 loops=1)
                           Index Cond: (device_id = 1)
               ->  Custom Scan (DecompressChunk) on _hyper_5_22_chunk o1_2 (never executed)
                     ->  Index Scan Backward using compress_hyper_6_33_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_33_chunk (never executed)
                           Index Cond: (device_id = 1)
               ->  Custom Scan (DecompressChunk) on _hyper_5_25_chunk o1_3 (never executed)
                     ->  Index Scan Backward using compress_hyper_6_30_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_30_chunk (never executed)
                           Index Cond: (device_id = 1)
         ->  Materialize (actual rows=100 loops=1)
               ->  Append (actual rows=100 loops=1)
                     ->  Custom Scan (DecompressChunk) on _hyper_5_25_chunk o2 (actual rows=100 loops=1)
                           ->  Index Scan using compress_hyper_6_30_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_30_chunk compress_hyper_6_30_chunk_1 (actual rows=1 loops=1)
                                 Index Cond: (device_id = 1)
                     ->  Custom Scan (DecompressChunk) on _hyper_5_19_chunk o2_1 (never executed)
                           ->  Index Scan using compress_hyper_6_36_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_36_chunk compress_hyper_6_36_chunk_1 (never executed)
                                 Index Cond: (device_id = 1)
                     ->  Custom Scan (DecompressChunk) on _hyper_5_22_chunk o2_2 (never executed)
                           ->  Index Scan using compress_hyper_6_33_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_33_chunk compress_hyper_6_33_chunk_1 (never executed)
                                 Index Cond: (device_id = 1)
(24 rows)

-- test JOIN on time column with implicit join
-- should use 2 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1,
  :TEST_TABLE o2
WHERE o1.time = o2.time
  AND o1.device_id = 1
  AND o2.device_id = 2
ORDER BY o1.time
LIMIT 100;
                                                                                  QUERY PLAN                                                                                  
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit (actual rows=100 loops=1)
   ->  Merge Join (actual rows=100 loops=1)
         Merge Cond: (o1."time" = o2."time")
         ->  Custom Scan (ChunkAppend) on metrics_space_compressed o1 (actual rows=100 loops=1)
               Order: o1."time"
               ->  Custom Scan (DecompressChunk) on _hyper_5_19_chunk o1_1 (actual rows=100 loops=1)
                     ->  Index Scan Backward using compress_hyper_6_36_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_36_chunk (actual rows=1 loops=1)
                           Index Cond: (device_id = 1)
               ->  Custom Scan (DecompressChunk) on _hyper_5_22_chunk o1_2 (never executed)
                     ->  Index Scan Backward using compress_hyper_6_33_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_33_chunk (never executed)
                           Index Cond: (device_id = 1)
               ->  Custom Scan (DecompressChunk) on _hyper_5_25_chunk o1_3 (never executed)
                     ->  Index Scan Backward using compress_hyper_6_30_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_30_chunk (never executed)
                           Index Cond: (device_id = 1)
         ->  Materialize (actual rows=100 loops=1)
               ->  Custom Scan (ChunkAppend) on metrics_space_compressed o2 (actual rows=100 loops=1)
                     Order: o2."time"
                     ->  Custom Scan (DecompressChunk) on _hyper_5_20_chunk o2_1 (actual rows=100 loops=1)
                           ->  Index Scan Backward using compress_hyper_6_35_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_35_chunk (actual rows=1 loops=1)
                                 Index Cond: (device_id = 2)
                     ->  Custom Scan (DecompressChunk) on _hyper_5_23_chunk o2_2 (never executed)
                           ->  Index Scan Backward using compress_hyper_6_32_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_32_chunk (never executed)
                                 Index Cond: (device_id = 2)
                     ->  Custom Scan (DecompressChunk) on _hyper_5_26_chunk o2_3 (never executed)
                           ->  Index Scan Backward using compress_hyper_6_29_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_29_chunk (never executed)
                                 Index Cond: (device_id = 2)
(26 rows)

-- test JOIN on time column with 3 hypertables
-- should use 3 ChunkAppend
:PREFIX
SELECT o1.time
FROM :TEST_TABLE o1
  INNER JOIN :TEST_TABLE o2 ON o1.time = o2.time
  INNER JOIN :TEST_TABLE o3 ON o1.time = o3.time
WHERE o1.device_id = 1
  AND o2.device_id = 2
  AND o3.device_id = 3
ORDER BY o1.time
LIMIT 100;
                                                                                        QUERY PLAN                                                                                        
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit (actual rows=100 loops=1)
   ->  Merge Join (actual rows=100 loops=1)
         Merge Cond: (o3."time" = o1."time")
         ->  Custom Scan (ChunkAppend) on metrics_space_compressed o3 (actual rows=100 loops=1)
               Order: o3."time"
               ->  Custom Scan (DecompressChunk) on _hyper_5_21_chunk o3_1 (actual rows=100 loops=1)
                     ->  Index Scan Backward using compress_hyper_6_34_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_34_chunk (actual rows=1 loops=1)
                           Index Cond: (device_id = 3)
               ->  Custom Scan (DecompressChunk) on _hyper_5_24_chunk o3_2 (never executed)
                     ->  Index Scan Backward using compress_hyper_6_31_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_31_chunk (never executed)
                           Index Cond: (device_id = 3)
               ->  Custom Scan (DecompressChunk) on _hyper_5_27_chunk o3_3 (never executed)
                     ->  Index Scan Backward using compress_hyper_6_28_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_28_chunk (never executed)
                           Index Cond: (device_id = 3)
         ->  Materialize (actual rows=100 loops=1)
               ->  Merge Join (actual rows=100 loops=1)
                     Merge Cond: (o1."time" = o2."time")
                     ->  Custom Scan (ChunkAppend) on metrics_space_compressed o1 (actual rows=100 loops=1)
                           Order: o1."time"
                           ->  Custom Scan (DecompressChunk) on _hyper_5_19_chunk o1_1 (actual rows=100 loops=1)
                                 ->  Index Scan Backward using compress_hyper_6_36_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_36_chunk (actual rows=1 loops=1)
                                       Index Cond: (device_id = 1)
                           ->  Custom Scan (DecompressChunk) on _hyper_5_22_chunk o1_2 (never executed)
                                 ->  Index Scan Backward using compress_hyper_6_33_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_33_chunk (never executed)
                                       Index Cond: (device_id = 1)
                           ->  Custom Scan (DecompressChunk) on _hyper_5_25_chunk o1_3 (never executed)
                                 ->  Index Scan Backward using compress_hyper_6_30_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_30_chunk (never executed)
                                       Index Cond: (device_id = 1)
                     ->  Materialize (actual rows=100 loops=1)
                           ->  Custom Scan (ChunkAppend) on metrics_space_compressed o2 (actual rows=100 loops=1)
                                 Order: o2."time"
                                 ->  Custom Scan (DecompressChunk) on _hyper_5_20_chunk o2_1 (actual rows=100 loops=1)
                                       ->  Index Scan Backward using compress_hyper_6_35_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_35_chunk (actual rows=1 loops=1)
                                             Index Cond: (device_id = 2)
                                 ->  Custom Scan (DecompressChunk) on _hyper_5_23_chunk o2_2 (never executed)
                                       ->  Index Scan Backward using compress_hyper_6_32_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_32_chunk (never executed)
                                             Index Cond: (device_id = 2)
                                 ->  Custom Scan (DecompressChunk) on _hyper_5_26_chunk o2_3 (never executed)
                                       ->  Index Scan Backward using compress_hyper_6_29_chunk__compressed_hypertable_6_device_id__t on compress_hyper_6_29_chunk (never executed)
                                             Index Cond: (device_id = 2)
(40 rows)

RESET enable_seqscan;
-- get results for all the queries
-- run queries on uncompressed hypertable and store result
\set PREFIX ''
\set PREFIX_VERBOSE ''
\set ECHO none
